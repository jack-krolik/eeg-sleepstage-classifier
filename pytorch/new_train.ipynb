{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.io as sio\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# from sleepdetector_claude import Sleepdetector\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Load Data File\n",
    "# filepath = '../data/data.mat'\n",
    "# mat_file = sio.loadmat(filepath)\n",
    "# x = np.stack((mat_file['sig1'], mat_file['sig2'], mat_file['sig3'], mat_file['sig4']), axis=0)\n",
    "\n",
    "# # Convert numpy array to PyTorch tensor\n",
    "# x = torch.from_numpy(x).float()\n",
    "\n",
    "# # Load actual labels\n",
    "# labels_file = '../data/labels.mat'\n",
    "# y_true = sio.loadmat(labels_file)['labels'].flatten() - 1  # Subtract 1 to match 0-4 encoding\n",
    "# y = torch.from_numpy(y_true).long()\n",
    "\n",
    "# print(f\"Shape of x: {x.shape}\")\n",
    "# print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# # Ensure x and y have matching dimensions\n",
    "# assert x.shape[1] == y.shape[0], f\"Mismatch in number of examples: x has {x.shape[1]}, y has {y.shape[0]}\"\n",
    "\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: torch.Size([4, 1027, 3000, 1])\n",
      "Shape of y: torch.Size([1027])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sleepdetector_improved import ImprovedSleepdetector\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load Data File\n",
    "filepath = '../data/data.mat'\n",
    "mat_file = sio.loadmat(filepath)\n",
    "x = np.stack((mat_file['sig1'], mat_file['sig2'], mat_file['sig3'], mat_file['sig4']), axis=0)\n",
    "\n",
    "# Convert numpy array to PyTorch tensor\n",
    "x = torch.from_numpy(x).float()\n",
    "\n",
    "# Load actual labels\n",
    "labels_file = '../data/labels.mat'\n",
    "y_true = sio.loadmat(labels_file)['labels'].flatten() - 1  # Subtract 1 to match 0-4 encoding\n",
    "y = torch.from_numpy(y_true).long()\n",
    "\n",
    "print(f\"Shape of x: {x.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   4%|▍         | 1/26 [00:02<01:08,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   8%|▊         | 2/26 [00:05<01:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  12%|█▏        | 3/26 [00:07<00:56,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  15%|█▌        | 4/26 [00:09<00:52,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  19%|█▉        | 5/26 [00:12<00:49,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  23%|██▎       | 6/26 [00:14<00:46,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  27%|██▋       | 7/26 [00:16<00:45,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  31%|███       | 8/26 [00:19<00:43,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  35%|███▍      | 9/26 [00:21<00:41,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  38%|███▊      | 10/26 [00:24<00:39,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  42%|████▏     | 11/26 [00:26<00:36,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  46%|████▌     | 12/26 [00:29<00:33,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  50%|█████     | 13/26 [00:31<00:30,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  54%|█████▍    | 14/26 [00:33<00:27,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  58%|█████▊    | 15/26 [00:35<00:24,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  62%|██████▏   | 16/26 [00:37<00:22,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  65%|██████▌   | 17/26 [00:39<00:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  69%|██████▉   | 18/26 [00:42<00:17,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  73%|███████▎  | 19/26 [00:44<00:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  77%|███████▋  | 20/26 [00:47<00:14,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  81%|████████  | 21/26 [00:49<00:12,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  85%|████████▍ | 22/26 [00:52<00:09,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  88%|████████▊ | 23/26 [00:54<00:07,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  92%|█████████▏| 24/26 [00:56<00:04,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  96%|█████████▌| 25/26 [00:59<00:02,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 26/26 [01:00<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4642, Accuracy: 33.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   4%|▍         | 1/26 [00:02<00:56,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   8%|▊         | 2/26 [00:04<00:53,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  12%|█▏        | 3/26 [00:06<00:51,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  15%|█▌        | 4/26 [00:09<00:51,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  19%|█▉        | 5/26 [00:11<00:50,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  23%|██▎       | 6/26 [00:14<00:48,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  27%|██▋       | 7/26 [00:16<00:45,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  31%|███       | 8/26 [00:18<00:42,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  35%|███▍      | 9/26 [00:21<00:39,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  38%|███▊      | 10/26 [00:23<00:37,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  42%|████▏     | 11/26 [00:25<00:34,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  46%|████▌     | 12/26 [00:27<00:32,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  50%|█████     | 13/26 [00:30<00:30,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  54%|█████▍    | 14/26 [00:32<00:27,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  58%|█████▊    | 15/26 [00:34<00:25,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  62%|██████▏   | 16/26 [00:37<00:23,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  65%|██████▌   | 17/26 [00:39<00:20,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  69%|██████▉   | 18/26 [00:41<00:18,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  73%|███████▎  | 19/26 [00:44<00:16,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  77%|███████▋  | 20/26 [00:47<00:14,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  81%|████████  | 21/26 [00:49<00:12,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  85%|████████▍ | 22/26 [00:53<00:11,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  88%|████████▊ | 23/26 [00:55<00:08,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  92%|█████████▏| 24/26 [00:58<00:05,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  96%|█████████▌| 25/26 [01:00<00:02,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 26/26 [01:02<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 1.2295, Accuracy: 48.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:   4%|▍         | 1/26 [00:02<00:59,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:   8%|▊         | 2/26 [00:04<00:56,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  12%|█▏        | 3/26 [00:07<00:56,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  15%|█▌        | 4/26 [00:09<00:53,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  19%|█▉        | 5/26 [00:12<00:53,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  23%|██▎       | 6/26 [00:14<00:50,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  27%|██▋       | 7/26 [00:17<00:48,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  31%|███       | 8/26 [00:20<00:46,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  35%|███▍      | 9/26 [00:22<00:42,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  38%|███▊      | 10/26 [00:24<00:38,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  42%|████▏     | 11/26 [00:27<00:35,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  46%|████▌     | 12/26 [00:31<00:40,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  50%|█████     | 13/26 [00:34<00:37,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  54%|█████▍    | 14/26 [00:36<00:32,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  58%|█████▊    | 15/26 [00:38<00:29,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  62%|██████▏   | 16/26 [00:41<00:25,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  65%|██████▌   | 17/26 [00:43<00:23,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  69%|██████▉   | 18/26 [00:46<00:20,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  73%|███████▎  | 19/26 [00:48<00:16,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  77%|███████▋  | 20/26 [00:50<00:14,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  81%|████████  | 21/26 [00:52<00:11,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  85%|████████▍ | 22/26 [00:55<00:09,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  88%|████████▊ | 23/26 [00:57<00:06,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  92%|█████████▏| 24/26 [00:59<00:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  96%|█████████▌| 25/26 [01:01<00:02,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 26/26 [01:03<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 1.1376, Accuracy: 53.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:   4%|▍         | 1/26 [00:02<00:54,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:   8%|▊         | 2/26 [00:04<00:52,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  12%|█▏        | 3/26 [00:06<00:50,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  15%|█▌        | 4/26 [00:08<00:47,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  19%|█▉        | 5/26 [00:11<00:49,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  23%|██▎       | 6/26 [00:13<00:48,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  27%|██▋       | 7/26 [00:16<00:44,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  31%|███       | 8/26 [00:18<00:41,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  35%|███▍      | 9/26 [00:20<00:38,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  38%|███▊      | 10/26 [00:22<00:35,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  42%|████▏     | 11/26 [00:25<00:33,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  46%|████▌     | 12/26 [00:27<00:31,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  50%|█████     | 13/26 [00:29<00:29,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  54%|█████▍    | 14/26 [00:31<00:26,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  58%|█████▊    | 15/26 [00:33<00:24,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  62%|██████▏   | 16/26 [00:36<00:22,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  65%|██████▌   | 17/26 [00:38<00:20,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  69%|██████▉   | 18/26 [00:41<00:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  73%|███████▎  | 19/26 [00:43<00:16,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  77%|███████▋  | 20/26 [00:45<00:13,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  81%|████████  | 21/26 [00:47<00:11,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  85%|████████▍ | 22/26 [00:50<00:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  88%|████████▊ | 23/26 [00:52<00:06,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  92%|█████████▏| 24/26 [00:54<00:04,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  96%|█████████▌| 25/26 [00:56<00:02,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 26/26 [00:58<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 1.1369, Accuracy: 51.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:   4%|▍         | 1/26 [00:02<00:54,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:   8%|▊         | 2/26 [00:04<00:51,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  12%|█▏        | 3/26 [00:06<00:49,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  15%|█▌        | 4/26 [00:08<00:48,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  19%|█▉        | 5/26 [00:10<00:46,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  23%|██▎       | 6/26 [00:13<00:44,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  27%|██▋       | 7/26 [00:15<00:42,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  31%|███       | 8/26 [00:17<00:40,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  35%|███▍      | 9/26 [00:19<00:38,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  38%|███▊      | 10/26 [00:22<00:35,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  42%|████▏     | 11/26 [00:24<00:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  46%|████▌     | 12/26 [00:26<00:30,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  50%|█████     | 13/26 [00:28<00:28,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  54%|█████▍    | 14/26 [00:30<00:26,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  58%|█████▊    | 15/26 [00:33<00:24,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  62%|██████▏   | 16/26 [00:35<00:21,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  65%|██████▌   | 17/26 [00:37<00:19,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  69%|██████▉   | 18/26 [00:39<00:17,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  73%|███████▎  | 19/26 [00:42<00:15,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  77%|███████▋  | 20/26 [00:44<00:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  81%|████████  | 21/26 [00:46<00:11,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  85%|████████▍ | 22/26 [00:48<00:08,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  88%|████████▊ | 23/26 [00:50<00:06,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  92%|█████████▏| 24/26 [00:52<00:04,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  96%|█████████▌| 25/26 [00:55<00:02,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 26/26 [00:56<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 1.1375, Accuracy: 48.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:   4%|▍         | 1/26 [00:02<01:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:   8%|▊         | 2/26 [00:04<00:55,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  12%|█▏        | 3/26 [00:06<00:51,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  15%|█▌        | 4/26 [00:09<00:49,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  19%|█▉        | 5/26 [00:11<00:47,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  23%|██▎       | 6/26 [00:13<00:44,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  27%|██▋       | 7/26 [00:15<00:42,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  31%|███       | 8/26 [00:18<00:40,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  35%|███▍      | 9/26 [00:20<00:37,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  38%|███▊      | 10/26 [00:22<00:35,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  42%|████▏     | 11/26 [00:24<00:34,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  46%|████▌     | 12/26 [00:26<00:31,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  50%|█████     | 13/26 [00:29<00:29,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  54%|█████▍    | 14/26 [00:31<00:26,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  58%|█████▊    | 15/26 [00:33<00:24,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  62%|██████▏   | 16/26 [00:35<00:22,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  65%|██████▌   | 17/26 [00:38<00:19,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  69%|██████▉   | 18/26 [00:40<00:17,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  73%|███████▎  | 19/26 [00:42<00:15,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  77%|███████▋  | 20/26 [00:44<00:13,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  81%|████████  | 21/26 [00:47<00:11,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  85%|████████▍ | 22/26 [00:49<00:08,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  88%|████████▊ | 23/26 [00:51<00:06,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  92%|█████████▏| 24/26 [00:53<00:04,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  96%|█████████▌| 25/26 [00:55<00:02,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 26/26 [00:57<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 1.0693, Accuracy: 51.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:   4%|▍         | 1/26 [00:02<00:55,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:   8%|▊         | 2/26 [00:04<00:54,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  12%|█▏        | 3/26 [00:06<00:50,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  15%|█▌        | 4/26 [00:08<00:48,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  19%|█▉        | 5/26 [00:11<00:46,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  23%|██▎       | 6/26 [00:13<00:43,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  27%|██▋       | 7/26 [00:15<00:41,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  31%|███       | 8/26 [00:17<00:39,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  35%|███▍      | 9/26 [00:19<00:37,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  38%|███▊      | 10/26 [00:22<00:35,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  42%|████▏     | 11/26 [00:24<00:33,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  46%|████▌     | 12/26 [00:26<00:30,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  50%|█████     | 13/26 [00:28<00:28,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  54%|█████▍    | 14/26 [00:31<00:26,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  58%|█████▊    | 15/26 [00:33<00:24,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  62%|██████▏   | 16/26 [00:35<00:22,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  65%|██████▌   | 17/26 [00:37<00:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  69%|██████▉   | 18/26 [00:39<00:17,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  73%|███████▎  | 19/26 [00:42<00:15,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  77%|███████▋  | 20/26 [00:44<00:13,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  81%|████████  | 21/26 [00:46<00:11,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  85%|████████▍ | 22/26 [00:48<00:09,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  88%|████████▊ | 23/26 [00:51<00:06,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  92%|█████████▏| 24/26 [00:53<00:04,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  96%|█████████▌| 25/26 [00:55<00:02,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 26/26 [00:57<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.9279, Accuracy: 58.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   4%|▍         | 1/26 [00:02<00:54,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   8%|▊         | 2/26 [00:04<00:52,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  12%|█▏        | 3/26 [00:06<00:50,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  15%|█▌        | 4/26 [00:08<00:48,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  19%|█▉        | 5/26 [00:10<00:46,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  23%|██▎       | 6/26 [00:13<00:43,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  27%|██▋       | 7/26 [00:15<00:41,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  31%|███       | 8/26 [00:17<00:39,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  35%|███▍      | 9/26 [00:19<00:37,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  38%|███▊      | 10/26 [00:22<00:36,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  42%|████▏     | 11/26 [00:24<00:33,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  46%|████▌     | 12/26 [00:26<00:31,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  50%|█████     | 13/26 [00:28<00:29,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  54%|█████▍    | 14/26 [00:31<00:26,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  58%|█████▊    | 15/26 [00:33<00:24,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  62%|██████▏   | 16/26 [00:35<00:22,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  65%|██████▌   | 17/26 [00:37<00:20,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  69%|██████▉   | 18/26 [00:39<00:17,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  73%|███████▎  | 19/26 [00:42<00:15,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  77%|███████▋  | 20/26 [00:44<00:13,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  81%|████████  | 21/26 [00:46<00:10,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  85%|████████▍ | 22/26 [00:48<00:08,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  88%|████████▊ | 23/26 [00:50<00:06,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  92%|█████████▏| 24/26 [00:53<00:04,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  96%|█████████▌| 25/26 [00:55<00:02,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 26/26 [00:56<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.9475, Accuracy: 55.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:   4%|▍         | 1/26 [00:02<00:54,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:   8%|▊         | 2/26 [00:04<00:52,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  12%|█▏        | 3/26 [00:06<00:51,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  15%|█▌        | 4/26 [00:08<00:48,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  19%|█▉        | 5/26 [00:11<00:46,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  23%|██▎       | 6/26 [00:13<00:44,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  27%|██▋       | 7/26 [00:15<00:41,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  31%|███       | 8/26 [00:17<00:38,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  35%|███▍      | 9/26 [00:19<00:36,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  38%|███▊      | 10/26 [00:22<00:36,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  42%|████▏     | 11/26 [00:24<00:35,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  46%|████▌     | 12/26 [00:27<00:34,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  50%|█████     | 13/26 [00:29<00:31,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  54%|█████▍    | 14/26 [00:32<00:28,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  58%|█████▊    | 15/26 [00:34<00:26,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  62%|██████▏   | 16/26 [00:36<00:23,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  65%|██████▌   | 17/26 [00:39<00:20,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  69%|██████▉   | 18/26 [00:41<00:18,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  73%|███████▎  | 19/26 [00:43<00:16,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  77%|███████▋  | 20/26 [00:46<00:13,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  81%|████████  | 21/26 [00:48<00:11,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  85%|████████▍ | 22/26 [00:50<00:09,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  88%|████████▊ | 23/26 [00:52<00:06,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  92%|█████████▏| 24/26 [00:55<00:04,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  96%|█████████▌| 25/26 [00:57<00:02,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 26/26 [00:59<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.9481, Accuracy: 56.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:   4%|▍         | 1/26 [00:02<00:56,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:   8%|▊         | 2/26 [00:04<00:53,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  12%|█▏        | 3/26 [00:06<00:51,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  15%|█▌        | 4/26 [00:08<00:49,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  19%|█▉        | 5/26 [00:11<00:47,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  23%|██▎       | 6/26 [00:13<00:45,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  27%|██▋       | 7/26 [00:16<00:45,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  31%|███       | 8/26 [00:18<00:42,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  35%|███▍      | 9/26 [00:20<00:39,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  38%|███▊      | 10/26 [00:23<00:37,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  42%|████▏     | 11/26 [00:25<00:34,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  46%|████▌     | 12/26 [00:27<00:32,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  50%|█████     | 13/26 [00:29<00:29,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  54%|█████▍    | 14/26 [00:32<00:27,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  58%|█████▊    | 15/26 [00:34<00:24,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  62%|██████▏   | 16/26 [00:36<00:22,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  65%|██████▌   | 17/26 [00:38<00:20,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  69%|██████▉   | 18/26 [00:41<00:17,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  73%|███████▎  | 19/26 [00:43<00:15,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  77%|███████▋  | 20/26 [00:45<00:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  81%|████████  | 21/26 [00:47<00:11,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  85%|████████▍ | 22/26 [00:50<00:09,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  88%|████████▊ | 23/26 [00:52<00:06,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  92%|█████████▏| 24/26 [00:54<00:04,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  96%|█████████▌| 25/26 [00:56<00:02,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 26/26 [00:58<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.8518, Accuracy: 59.93%\n",
      "Input shape to ImprovedSleepdetector: torch.Size([206, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([206, 4, 3000])\n",
      "Shape after normalization: torch.Size([206, 4, 3000])\n",
      "Shape of extracted features: torch.Size([206, 1024])\n",
      "Input shape to CNN: torch.Size([206, 4, 3000])\n",
      "Shape of x_0: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([206, 128, 47])\n",
      "Shape of x_1: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([206, 128, 47])\n",
      "Shape of x_2: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([206, 128, 47])\n",
      "Shape of x_3: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([206, 128, 47])\n",
      "Shape after concatenation: torch.Size([206, 512, 47])\n",
      "Shape after flatten: torch.Size([206, 24064])\n",
      "Final output shape: torch.Size([206, 5])\n",
      "Shape of CNN output: torch.Size([206, 5])\n",
      "Shape of combined features: torch.Size([206, 1029])\n",
      "Shape of LSTM input: torch.Size([206, 1, 1029])\n",
      "Final output shape: torch.Size([206, 5])\n",
      "Test Accuracy: 0.23%\n",
      "Cohen's Kappa: 0.0071\n"
     ]
    }
   ],
   "source": [
    "# Reshape x to match the expected input shape of the model\n",
    "x = x.permute(1, 0, 2, 3)  # Change from [4, 1027, 3000, 1] to [1027, 4, 3000, 1]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_size = int(0.8 * len(x))\n",
    "test_size = len(x) - train_size\n",
    "\n",
    "X_train, X_test = x[:train_size], x[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = ImprovedSleepdetector()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test.to(device))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    test_accuracy = accuracy_score(y_test.cpu().numpy(), predicted.cpu().numpy())\n",
    "    kappa = cohen_kappa_score(y_test.cpu().numpy(), predicted.cpu().numpy())\n",
    "    conf_matrix = confusion_matrix(y_test.cpu().numpy(), predicted.cpu().numpy())\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "print(f'Cohen\\'s Kappa: {kappa:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "torch.save(model.state_dict(), 'improved_sleepdetector_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([206, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([206, 4, 3000])\n",
      "Shape after normalization: torch.Size([206, 4, 3000])\n",
      "Shape of extracted features: torch.Size([206, 1024])\n",
      "Input shape to CNN: torch.Size([206, 4, 3000])\n",
      "Shape of x_0: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([206, 128, 47])\n",
      "Shape of x_1: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([206, 128, 47])\n",
      "Shape of x_2: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([206, 128, 47])\n",
      "Shape of x_3: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([206, 128, 47])\n",
      "Shape after concatenation: torch.Size([206, 512, 47])\n",
      "Shape after flatten: torch.Size([206, 24064])\n",
      "Final output shape: torch.Size([206, 5])\n",
      "Shape of CNN output: torch.Size([206, 5])\n",
      "Shape of combined features: torch.Size([206, 1029])\n",
      "Shape of LSTM input: torch.Size([206, 1, 1029])\n",
      "Final output shape: torch.Size([206, 5])\n",
      "Test Accuracy: 0.23%\n",
      "Cohen's Kappa: 0.0071\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test.to(device))\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    test_accuracy = accuracy_score(y_test.cpu().numpy(), predicted.cpu().numpy())\n",
    "    kappa = cohen_kappa_score(y_test.cpu().numpy(), predicted.cpu().numpy())\n",
    "    conf_matrix = confusion_matrix(y_test.cpu().numpy(), predicted.cpu().numpy())\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "print(f'Cohen\\'s Kappa: {kappa:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([206, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([206, 4, 3000])\n",
      "Shape after normalization: torch.Size([206, 4, 3000])\n",
      "Shape of extracted features: torch.Size([206, 1024])\n",
      "Input shape to CNN: torch.Size([206, 4, 3000])\n",
      "Shape of x_0: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([206, 128, 47])\n",
      "Shape of x_1: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([206, 128, 47])\n",
      "Shape of x_2: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([206, 128, 47])\n",
      "Shape of x_3: torch.Size([206, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([206, 128, 47])\n",
      "Shape after concatenation: torch.Size([206, 512, 47])\n",
      "Shape after flatten: torch.Size([206, 24064])\n",
      "Final output shape: torch.Size([206, 5])\n",
      "Shape of CNN output: torch.Size([206, 5])\n",
      "Shape of combined features: torch.Size([206, 1029])\n",
      "Shape of LSTM input: torch.Size([206, 1, 1029])\n",
      "Final output shape: torch.Size([206, 5])\n",
      "Test Accuracy: 0.23\n",
      "Cohen's Kappa: 0.0071\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        y_true = y_test.cpu().numpy()\n",
    "        y_pred = predicted.cpu().numpy()\n",
    "        \n",
    "        test_accuracy = accuracy_score(y_true, y_pred)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "        print(f'Cohen\\'s Kappa: {kappa:.4f}')\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        class_names = ['N3', 'N2', 'N1', 'REM', 'Awake']\n",
    "        plot_confusion_matrix(conf_matrix, class_names)\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Use the evaluation function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "evaluate_model(model, X_test, y_test, device)\n",
    "\n",
    "\n",
    "# # Calculate metrics\n",
    "# accuracy = accuracy_score(true_labels, predictions)\n",
    "# kappa = cohen_kappa_score(true_labels, predictions)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plot_confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# # Print classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# class_names = ['N3', 'N2', 'N1', 'REM', 'Awake']\n",
    "# print(classification_report(true_labels, predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([32, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([32, 4, 3000])\n",
      "Shape after normalization: torch.Size([32, 4, 3000])\n",
      "Shape of extracted features: torch.Size([32, 1024])\n",
      "Input shape to CNN: torch.Size([32, 4, 3000])\n",
      "Shape of x_0: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([32, 128, 47])\n",
      "Shape of x_1: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([32, 128, 47])\n",
      "Shape of x_2: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([32, 128, 47])\n",
      "Shape of x_3: torch.Size([32, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([32, 128, 47])\n",
      "Shape after concatenation: torch.Size([32, 512, 47])\n",
      "Shape after flatten: torch.Size([32, 24064])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Shape of CNN output: torch.Size([32, 5])\n",
      "Shape of combined features: torch.Size([32, 1029])\n",
      "Shape of LSTM input: torch.Size([32, 1, 1029])\n",
      "Final output shape: torch.Size([32, 5])\n",
      "Input shape to ImprovedSleepdetector: torch.Size([21, 4, 3000, 1])\n",
      "Shape after squeeze: torch.Size([21, 4, 3000])\n",
      "Shape after normalization: torch.Size([21, 4, 3000])\n",
      "Shape of extracted features: torch.Size([21, 1024])\n",
      "Input shape to CNN: torch.Size([21, 4, 3000])\n",
      "Shape of x_0: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[0]: torch.Size([21, 128, 47])\n",
      "Shape of x_1: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[1]: torch.Size([21, 128, 47])\n",
      "Shape of x_2: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[2]: torch.Size([21, 128, 47])\n",
      "Shape of x_3: torch.Size([21, 1, 3000])\n",
      "Shape after conv_blocks[3]: torch.Size([21, 128, 47])\n",
      "Shape after concatenation: torch.Size([21, 512, 47])\n",
      "Shape after flatten: torch.Size([21, 24064])\n",
      "Final output shape: torch.Size([21, 5])\n",
      "Shape of CNN output: torch.Size([21, 5])\n",
      "Shape of combined features: torch.Size([21, 1029])\n",
      "Shape of LSTM input: torch.Size([21, 1, 1029])\n",
      "Final output shape: torch.Size([21, 5])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(target.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "train_conf_matrix = confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies)\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "class_names = ['N3', 'N2', 'N1', 'REM', 'Awake']\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(train_conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Training Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
