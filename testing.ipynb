{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 12:49:20,955 - INFO - Using CUDA device 0: NVIDIA TITAN V\n",
      "2024-11-01 12:49:20,959 - INFO - Memory available: 12.65GB\n",
      "2024-11-01 12:49:20,977 - INFO - Using CUDA device: NVIDIA TITAN V\n",
      "2024-11-01 12:49:20,985 - INFO - CUDA Memory Available: 12.65GB\n",
      "/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-01 12:49:27,003 - INFO - Not saving outputs\n",
      "2024-11-01 12:49:27,006 - INFO - Loading data from 4 nights...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA seed set on device NVIDIA TITAN V\n",
      "Starting model evaluation...\n",
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 12:49:28,079 - INFO - \n",
      "Data Loading Summary:\n",
      "2024-11-01 12:49:28,080 - INFO -     Total nights processed: 4\n",
      "2024-11-01 12:49:28,092 - INFO -     Total epochs: 4118\n",
      "2024-11-01 12:49:28,101 - INFO -     Average epochs per night: 1029.5 Â± 33.4\n",
      "2024-11-01 12:49:28,112 - INFO -     Range: 983 to 1066 epochs\n",
      "2024-11-01 12:49:28,122 - INFO - \n",
      "Overall Data Shapes:\n",
      "2024-11-01 12:49:28,169 - INFO -     Combined data: torch.Size([4118, 4, 3000])\n",
      "2024-11-01 12:49:28,186 - INFO -     Combined labels: torch.Size([4118])\n",
      "2024-11-01 12:49:28,216 - INFO - \n",
      "Overall Class Distribution:\n",
      "2024-11-01 12:49:28,231 - INFO -     N3 (Deep): 90 (2.2%)\n",
      "        N2 (Light): 2146 (52.1%)\n",
      "        N1 (Light): 271 (6.6%)\n",
      "        REM: 669 (16.2%)\n",
      "        Wake: 942 (22.9%)\n",
      "2024-11-01 12:49:28,283 - INFO - \n",
      "Initial class distribution:\n",
      "2024-11-01 12:49:28,284 - INFO -     Class 0 (N3 (Deep)): 90 samples (2.2%)\n",
      "2024-11-01 12:49:28,313 - INFO -     Class 1 (N2 (Light)): 2146 samples (52.1%)\n",
      "2024-11-01 12:49:28,368 - INFO -     Class 2 (N1 (Light)): 271 samples (6.6%)\n",
      "2024-11-01 12:49:28,381 - INFO -     Class 3 (REM): 669 samples (16.2%)\n",
      "2024-11-01 12:49:28,392 - INFO -     Class 4 (Wake): 942 samples (22.9%)\n",
      "2024-11-01 12:49:28,435 - INFO - \n",
      "Night 0 statistics:\n",
      "2024-11-01 12:49:28,444 - INFO -     Class distribution:\n",
      "2024-11-01 12:49:28,465 - INFO -         Class 0: 7 (0.7%)\n",
      "2024-11-01 12:49:28,476 - INFO -         Class 1: 668 (62.7%)\n",
      "2024-11-01 12:49:28,509 - INFO -         Class 2: 57 (5.3%)\n",
      "2024-11-01 12:49:28,520 - INFO -         Class 3: 191 (17.9%)\n",
      "2024-11-01 12:49:28,557 - INFO -         Class 4: 143 (13.4%)\n",
      "2024-11-01 12:49:28,570 - INFO -     Common transitions:\n",
      "2024-11-01 12:49:28,580 - INFO -         N2 (Light) -> N2 (Light): 622\n",
      "2024-11-01 12:49:28,642 - INFO -         REM -> REM: 182\n",
      "2024-11-01 12:49:28,654 - INFO -         Wake -> Wake: 121\n",
      "2024-11-01 12:49:28,684 - INFO -         N1 (Light) -> N2 (Light): 32\n",
      "2024-11-01 12:49:28,696 - INFO -         N2 (Light) -> N1 (Light): 27\n",
      "2024-11-01 12:49:28,717 - INFO - \n",
      "Night 1 statistics:\n",
      "2024-11-01 12:49:28,742 - INFO -     Class distribution:\n",
      "2024-11-01 12:49:28,772 - INFO -         Class 0: 78 (7.7%)\n",
      "2024-11-01 12:49:28,786 - INFO -         Class 1: 564 (55.7%)\n",
      "2024-11-01 12:49:28,798 - INFO -         Class 2: 29 (2.9%)\n",
      "2024-11-01 12:49:28,808 - INFO -         Class 3: 196 (19.3%)\n",
      "2024-11-01 12:49:28,820 - INFO -         Class 4: 146 (14.4%)\n",
      "2024-11-01 12:49:28,831 - INFO -     Common transitions:\n",
      "2024-11-01 12:49:28,843 - INFO -         N2 (Light) -> N2 (Light): 539\n",
      "2024-11-01 12:49:28,854 - INFO -         REM -> REM: 186\n",
      "2024-11-01 12:49:28,865 - INFO -         Wake -> Wake: 131\n",
      "2024-11-01 12:49:28,875 - INFO -         N3 (Deep) -> N3 (Deep): 67\n",
      "2024-11-01 12:49:28,904 - INFO -         N1 (Light) -> N1 (Light): 13\n",
      "2024-11-01 12:49:28,917 - INFO - \n",
      "Night 2 statistics:\n",
      "2024-11-01 12:49:28,926 - INFO -     Class distribution:\n",
      "2024-11-01 12:49:28,938 - INFO -         Class 1: 426 (43.3%)\n",
      "2024-11-01 12:49:28,949 - INFO -         Class 2: 114 (11.6%)\n",
      "2024-11-01 12:49:28,960 - INFO -         Class 3: 72 (7.3%)\n",
      "2024-11-01 12:49:28,971 - INFO -         Class 4: 371 (37.7%)\n",
      "2024-11-01 12:49:28,982 - INFO -     Common transitions:\n",
      "2024-11-01 12:49:29,024 - INFO -         N2 (Light) -> N2 (Light): 401\n",
      "2024-11-01 12:49:29,035 - INFO -         Wake -> Wake: 349\n",
      "2024-11-01 12:49:29,048 - INFO -         N1 (Light) -> N1 (Light): 78\n",
      "2024-11-01 12:49:29,059 - INFO -         REM -> REM: 65\n",
      "2024-11-01 12:49:29,077 - INFO -         N1 (Light) -> N2 (Light): 25\n",
      "2024-11-01 12:49:29,089 - INFO - \n",
      "Night 3 statistics:\n",
      "2024-11-01 12:49:29,099 - INFO -     Class distribution:\n",
      "2024-11-01 12:49:29,109 - INFO -         Class 0: 5 (0.5%)\n",
      "2024-11-01 12:49:29,119 - INFO -         Class 1: 488 (46.2%)\n",
      "2024-11-01 12:49:29,132 - INFO -         Class 2: 71 (6.7%)\n",
      "2024-11-01 12:49:29,185 - INFO -         Class 3: 210 (19.9%)\n",
      "2024-11-01 12:49:29,222 - INFO -         Class 4: 282 (26.7%)\n",
      "2024-11-01 12:49:29,243 - INFO -     Common transitions:\n",
      "2024-11-01 12:49:29,255 - INFO -         N2 (Light) -> N2 (Light): 469\n",
      "2024-11-01 12:49:29,267 - INFO -         Wake -> Wake: 254\n",
      "2024-11-01 12:49:29,278 - INFO -         REM -> REM: 198\n",
      "2024-11-01 12:49:29,300 - INFO -         N1 (Light) -> N1 (Light): 45\n",
      "2024-11-01 12:49:29,311 - INFO -         Wake -> N1 (Light): 22\n",
      "2024-11-01 12:49:29,463 - INFO - \n",
      "Target sample counts:\n",
      "2024-11-01 12:49:29,464 - INFO -     Class 0: 157 (from 90)\n",
      "2024-11-01 12:49:29,476 - INFO -     Class 1: 2048 (from 2146)\n",
      "2024-11-01 12:49:29,520 - INFO -     Class 2: 813 (from 271)\n",
      "2024-11-01 12:49:29,530 - INFO -     Class 3: 468 (from 669)\n",
      "2024-11-01 12:49:29,544 - INFO -     Class 4: 1413 (from 942)\n",
      "2024-11-01 12:49:29,671 - INFO - \n",
      "Training split distribution:\n",
      "2024-11-01 12:49:29,673 - INFO -     Samples: 3623 (88.0%)\n",
      "2024-11-01 12:49:29,695 - INFO -     Class 0: 64 (1.8%)\n",
      "2024-11-01 12:49:29,706 - INFO -     Class 1: 2001 (55.2%)\n",
      "2024-11-01 12:49:29,717 - INFO -     Class 2: 123 (3.4%)\n",
      "2024-11-01 12:49:29,729 - INFO -     Class 3: 595 (16.4%)\n",
      "2024-11-01 12:49:29,762 - INFO -     Class 4: 840 (23.2%)\n",
      "2024-11-01 12:49:29,773 - INFO - \n",
      "Validation split distribution:\n",
      "2024-11-01 12:49:29,784 - INFO -     Samples: 124 (3.0%)\n",
      "2024-11-01 12:49:29,811 - INFO -     Class 1: 61 (49.2%)\n",
      "2024-11-01 12:49:29,824 - INFO -     Class 2: 9 (7.3%)\n",
      "2024-11-01 12:49:29,835 - INFO -     Class 3: 38 (30.6%)\n",
      "2024-11-01 12:49:29,846 - INFO -     Class 4: 16 (12.9%)\n",
      "2024-11-01 12:49:29,857 - WARNING -     Missing classes in Validation: {0}\n",
      "2024-11-01 12:49:29,868 - INFO - \n",
      "Testing split distribution:\n",
      "2024-11-01 12:49:29,879 - INFO -     Samples: 119 (2.9%)\n",
      "2024-11-01 12:49:29,889 - INFO -     Class 0: 8 (6.7%)\n",
      "2024-11-01 12:49:29,901 - INFO -     Class 1: 49 (41.2%)\n",
      "2024-11-01 12:49:29,912 - INFO -     Class 2: 15 (12.6%)\n",
      "2024-11-01 12:49:29,923 - INFO -     Class 3: 29 (24.4%)\n",
      "2024-11-01 12:49:29,957 - INFO -     Class 4: 18 (15.1%)\n",
      "2024-11-01 12:49:29,995 - ERROR - Error in data preparation: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "2024-11-01 12:49:30,007 - ERROR - Detailed error information:\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py\", line 456, in prepare_data_multi_night\n",
      "    X_train_spectral = extract_spectral_features_batch(X_train)\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py\", line 952, in extract_spectral_features_batch\n",
      "    features = extract_spectral_features(sample)\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py\", line 910, in extract_spectral_features\n",
      "    channel_data = x[channel].cpu().numpy()\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'cpu'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in load_and_evaluate_models: 'numpy.ndarray' object has no attribute 'cpu'\n",
      "\n",
      "Evaluation failed - no results generated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tools.config import CONFIG, device, cuda_manager\n",
    "from tools.classes import *\n",
    "from tools.functions import *\n",
    "from tools.utils import *\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Configure logging to display in notebook\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "set_seed(CONFIG['settings']['seed'])\n",
    "\n",
    "SAVE_OUTPUTS = False\n",
    "if SAVE_OUTPUTS:\n",
    "    logging.info(f\"Saving outputs to {CONFIG['model_dir']}\")\n",
    "else:\n",
    "    logging.info(\"Not saving outputs\")\n",
    "\n",
    "def compare_models(results, save_dir):\n",
    "    \"\"\"Generate and display model comparison\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to compare!\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Extract overall metrics for each model\n",
    "        comparison_data = {\n",
    "            model_name: {\n",
    "                'Accuracy': (result['true_labels'] == result['predictions']).mean() * 100,\n",
    "                'Macro F1': f1_score(result['true_labels'], result['predictions'], average='macro') * 100,\n",
    "                'Weighted F1': f1_score(result['true_labels'], result['predictions'], average='weighted') * 100\n",
    "            }\n",
    "            for model_name, result in results.items()\n",
    "        }\n",
    "        \n",
    "        # Create comparison DataFrame\n",
    "        comparison_df = pd.DataFrame(comparison_data).round(1)\n",
    "        \n",
    "        # Display comparison\n",
    "        print(\"\\nModel Comparison (%):\")\n",
    "        styled_comparison = comparison_df.style\\\n",
    "            .format(\"{:.1f}%\")\\\n",
    "            .background_gradient(cmap='RdYlGn')\\\n",
    "            .set_caption(\"Model Performance Comparison\")\n",
    "        display(styled_comparison)\n",
    "        \n",
    "        # Plot comparison\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        comparison_df.T.plot(kind='bar')\n",
    "        plt.title('Model Performance Comparison')\n",
    "        plt.ylabel('Score (%)')\n",
    "        plt.xlabel('Model')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if SAVE_OUTPUTS:\n",
    "            plt.savefig(os.path.join(save_dir, 'test_results', 'model_comparison.png'), \n",
    "                        dpi=300, bbox_inches='tight')\n",
    "        display(plt.gcf())\n",
    "        plt.close()\n",
    "        \n",
    "        if SAVE_OUTPUTS:\n",
    "            comparison_df.to_csv(os.path.join(save_dir, 'test_results', 'model_comparison.csv'))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in compare_models: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_and_evaluate_models():\n",
    "    \"\"\"Load and evaluate all models\"\"\"\n",
    "    try:\n",
    "        # Load test data\n",
    "        print(\"Loading test data...\")\n",
    "        x, y, night_indices, night_lengths = load_data(CONFIG['data_paths'])\n",
    "        \n",
    "        # Split data with proper ratios\n",
    "        training_split = prepare_data_multi_night(\n",
    "            x, y, night_indices, night_lengths,\n",
    "            train_size=0.7,\n",
    "            val_size=0.15,\n",
    "            test_size=0.15\n",
    "        )\n",
    "        \n",
    "        _, _, _, _, _, _, X_test, X_test_spectral, y_test = training_split\n",
    "        X_test, X_test_spectral = preprocess_data(X_test, X_test_spectral)\n",
    "        \n",
    "        # Initialize evaluator\n",
    "        evaluator = SleepStageEvaluator()\n",
    "        evaluator.save_outputs = SAVE_OUTPUTS\n",
    "        \n",
    "        # Load model parameters\n",
    "        try:\n",
    "            params_path = os.path.join(CONFIG['model_dir'], CONFIG['model_names']['params'])\n",
    "            with open(params_path, 'r') as f:\n",
    "                model_params = json.load(f)['model_params']\n",
    "            print(\"Successfully loaded model parameters\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model parameters: {str(e)}\")\n",
    "            print(\"Using default parameters from CONFIG\")\n",
    "            model_params = CONFIG['model_params']['initial']\n",
    "        \n",
    "        # Model name mapping\n",
    "        model_file_mapping = {\n",
    "            'Ensemble Model': 'ensemble',\n",
    "            'Diverse Ensemble': 'diverse',\n",
    "            'Distilled Model': 'distilled'\n",
    "        }\n",
    "        \n",
    "        # Initialize and evaluate models\n",
    "        results = {}\n",
    "        for model_name, file_name in model_file_mapping.items():\n",
    "            try:\n",
    "                print(f\"\\nEvaluating {model_name}...\")\n",
    "                \n",
    "                # Initialize appropriate model\n",
    "                if model_name == 'Ensemble Model':\n",
    "                    model = EnsembleModel(model_params)\n",
    "                elif model_name == 'Diverse Ensemble':\n",
    "                    model = DiverseEnsembleModel(model_params)\n",
    "                else:  # Distilled Model\n",
    "                    model = ImprovedSleepdetector(**model_params)\n",
    "                \n",
    "                # Load model weights\n",
    "                model_path = os.path.join(CONFIG['model_dir'], CONFIG['model_names'][file_name])\n",
    "                print(f\"Loading model from: {model_path}\")\n",
    "                \n",
    "                if not os.path.exists(model_path):\n",
    "                    raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "                \n",
    "                model = load_model(model, model_path)\n",
    "                model = model.to(device)\n",
    "                print(f\"Successfully loaded {model_name}\")\n",
    "                \n",
    "                # Memory check before evaluation\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    memory_allocated = torch.cuda.memory_allocated(device) / 1e9\n",
    "                    memory_reserved = torch.cuda.memory_reserved(device) / 1e9\n",
    "                    print(f\"GPU Memory before evaluation:\")\n",
    "                    print(f\"    Allocated: {memory_allocated:.2f} GB\")\n",
    "                    print(f\"    Reserved: {memory_reserved:.2f} GB\")\n",
    "                \n",
    "                # Evaluate model\n",
    "                results[model_name] = evaluator.evaluate_model(\n",
    "                    model, X_test, X_test_spectral, y_test, model_name\n",
    "                )\n",
    "                \n",
    "                # Clear memory after evaluation\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating {model_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No models were successfully evaluated!\")\n",
    "            return None\n",
    "        \n",
    "        # Compare models only if we have results\n",
    "        compare_models(results, evaluator.model_dir)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in load_and_evaluate_models: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"Starting model evaluation...\")\n",
    "try:\n",
    "    results = load_and_evaluate_models()\n",
    "    if results:\n",
    "        print(\"\\nEvaluation completed successfully\")\n",
    "    else:\n",
    "        print(\"\\nEvaluation failed - no results generated\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nEvaluation failed with error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
