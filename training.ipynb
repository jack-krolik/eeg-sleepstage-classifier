{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from classes import *\n",
    "from utils import *\n",
    "from config import CONFIG, get_device\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "device = get_device()\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model save directory exists\n",
    "ensure_dir(CONFIG['model_path'])\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    x, y = load_data()\n",
    "    logging.info(f\"Loaded data shape: {x.shape}, Labels shape: {y.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading data: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Prepare the data (includes SMOTE)\n",
    "X_train, X_train_spectral, y_train, X_val, X_val_spectral, y_val, X_test, X_test_spectral, y_test = prepare_data(x, y)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train, X_train_spectral = preprocess_data(X_train, X_train_spectral)\n",
    "X_val, X_val_spectral = preprocess_data(X_val, X_val_spectral)\n",
    "X_test, X_test_spectral = preprocess_data(X_test, X_test_spectral)\n",
    "\n",
    "# Identify minority classes for augmentation\n",
    "class_counts = Counter(y_train.numpy())\n",
    "minority_classes = [cls for cls, count in class_counts.items() if count < len(y_train) / len(class_counts) * 0.5]\n",
    "\n",
    "# Apply augmentation\n",
    "X_train, X_train_spectral, y_train = augment_minority_classes(X_train, X_train_spectral, y_train, minority_classes)\n",
    "\n",
    "# Initialize model and get parameters\n",
    "ensemble_model, params = initialize_model(device)\n",
    "\n",
    "# Save initial parameters\n",
    "# save_params(params, 'initial_params.json')\n",
    "\n",
    "# Set up training parameters\n",
    "train_params = params['train_params']\n",
    "balanced_sampler = BalancedBatchSampler(y_train.numpy(), batch_size=train_params['batch_size'])\n",
    "train_loader = DataLoader(TensorDataset(X_train, X_train_spectral, y_train), batch_sampler=balanced_sampler)\n",
    "\n",
    "# Set up loss function\n",
    "class_weights = get_class_weights(y_train).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights + 1e-6, label_smoothing=0.1)\n",
    "\n",
    "# Set up optimizer and scheduler with the selected learning rate\n",
    "optimizer = optim.AdamW(ensemble_model.parameters(), lr=train_params['lr'], weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Train model\n",
    "best_model_state, best_accuracy = train_model(\n",
    "    ensemble_model, train_loader, (X_val, X_val_spectral, y_val),\n",
    "    optimizer, scheduler, criterion, device, epochs=train_params['num_epochs']\n",
    ")\n",
    "\n",
    "# Save best model\n",
    "if best_model_state is not None:\n",
    "    # save_model(ensemble_model, CONFIG['best_model_name'])\n",
    "    # logging.info(f\"Best ensemble model saved. Final validation accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    ensemble_model.load_state_dict(best_model_state)\n",
    "    test_loss, test_accuracy, test_predictions = evaluate_model(ensemble_model, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "    logging.info(f\"Ensemble Model - Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Generate and save confusion matrix\n",
    "    cm = confusion_matrix(y_test.cpu().numpy(), test_predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(CONFIG['model_path'], 'confusion_matrix.png'))\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test.cpu().numpy(), test_predictions)\n",
    "    logging.info(f\"Classification Report:\\n{report}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train diverse ensemble\n",
    "diverse_ensemble = DiverseEnsembleModel(CONFIG['initial_params']['model_params']).to(device)\n",
    "diverse_optimizer = optim.AdamW(diverse_ensemble.parameters(), lr=train_params['lr'], weight_decay=1e-2)\n",
    "diverse_scheduler = get_scheduler(diverse_optimizer, num_warmup_steps=len(train_loader)*5, num_training_steps=len(train_loader)*train_params['num_epochs'])\n",
    "\n",
    "logging.info(\"Training diverse ensemble model...\")\n",
    "diverse_best_state, diverse_accuracy = train_model(\n",
    "    diverse_ensemble, train_loader, (X_val, X_val_spectral, y_val),\n",
    "    diverse_optimizer, diverse_scheduler, criterion, device, epochs=train_params['num_epochs']\n",
    ")\n",
    "\n",
    "save_model(diverse_ensemble, CONFIG['diverse_model_name'])\n",
    "logging.info(f\"Best diverse ensemble model saved. Final accuracy: {diverse_accuracy:.4f}\")\n",
    "\n",
    "# Distill knowledge\n",
    "single_model = ImprovedSleepdetector(**CONFIG['initial_params']['model_params']).to(device)\n",
    "\n",
    "logging.info(\"Performing knowledge distillation...\")\n",
    "distilled_model = distill_knowledge(ensemble_model, single_model, train_loader, (X_val, X_val_spectral, y_val), device)\n",
    "\n",
    "save_model(distilled_model, CONFIG['distilled_model_name'])\n",
    "\n",
    "# Final evaluation\n",
    "_, ensemble_accuracy, _ = evaluate_model(ensemble_model, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "_, diverse_accuracy, _ = evaluate_model(diverse_ensemble, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "_, distilled_accuracy, _ = evaluate_model(distilled_model, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "\n",
    "logging.info(f\"Training completed.\")\n",
    "logging.info(f\"Ensemble Model - Final Test Accuracy: {ensemble_accuracy:.4f}\")\n",
    "logging.info(f\"Diverse Ensemble Model - Final Test Accuracy: {diverse_accuracy:.4f}\")\n",
    "logging.info(f\"Distilled Model - Final Test Accuracy: {distilled_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
