{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.functions import *\n",
    "from tools.classes import *\n",
    "from tools.utils import *\n",
    "from tools.config import CONFIG, device\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model save directory exists\n",
    "ensure_dir(CONFIG['new_model_path'])\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    x, y = load_data(CONFIG['data_path'])\n",
    "    logging.info(f\"Loaded data shape: {x.shape}, Labels shape: {y.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading data: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Prepare the data (includes SMOTE)\n",
    "X_train, X_train_spectral, y_train, X_val, X_val_spectral, y_val, X_test, X_test_spectral, y_test = prepare_data(x, y)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train, X_train_spectral = preprocess_data(X_train, X_train_spectral)\n",
    "X_val, X_val_spectral = preprocess_data(X_val, X_val_spectral)\n",
    "X_test, X_test_spectral = preprocess_data(X_test, X_test_spectral)\n",
    "\n",
    "# Identify minority classes for augmentation\n",
    "class_counts = Counter(y_train.numpy())\n",
    "minority_classes = [cls for cls, count in class_counts.items() if count < len(y_train) / len(class_counts) * 0.5]\n",
    "\n",
    "# Apply augmentation\n",
    "X_train, X_train_spectral, y_train = augment_minority_classes(X_train, X_train_spectral, y_train, minority_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tuning = False\n",
    "get_best_lr = False\n",
    "\n",
    "if run_tuning:\n",
    "    logging.info(\"Starting hyperparameter tuning...\")\n",
    "    best_params = run_hyperparameter_tuning(X_train, X_train_spectral, y_train, device)\n",
    "    params = {'model_params': best_params, 'train_params': best_params}\n",
    "else:\n",
    "    params = CONFIG['initial_params']\n",
    "\n",
    "# Initialize model and get parameters\n",
    "ensemble_model, params = initialize_model(device)\n",
    "\n",
    "if CONFIG['use_pretrained_weights']:\n",
    "    pretrained_path = os.path.join(CONFIG['old_model_path'], CONFIG['model_names']['ensemble'])\n",
    "    ensemble_model.load_state_dict(torch.load(pretrained_path))\n",
    "    logging.info(f\"Loaded pretrained weights from {pretrained_path}\")\n",
    "\n",
    "# Save initial parameters\n",
    "# save_params(params, os.path.join(CONFIG['new_model_path'], 'initial_params.json'))\n",
    "\n",
    "# Set up training parameters\n",
    "train_params = params['train_params']\n",
    "balanced_sampler = BalancedBatchSampler(y_train.numpy(), batch_size=train_params['batch_size'])\n",
    "train_loader = DataLoader(TensorDataset(X_train, X_train_spectral, y_train), batch_sampler=balanced_sampler)\n",
    "\n",
    "# Set up loss function\n",
    "class_weights = get_class_weights(y_train).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights + 1e-6, label_smoothing=0.1)\n",
    "\n",
    " # Find best learning rate if requested\n",
    "if get_best_lr:\n",
    "    best_lr = find_lr(ensemble_model, train_loader, criterion, device)\n",
    "    train_params['lr'] = best_lr\n",
    "    logging.info(f\"Best learning rate found: {best_lr}\")\n",
    "\n",
    "\n",
    "\n",
    "# Set up optimizer and scheduler with the selected learning rate\n",
    "optimizer = optim.AdamW(ensemble_model.parameters(), lr=train_params['lr'], weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Train model\n",
    "best_model_state, best_accuracy = train_model(\n",
    "    ensemble_model, train_loader, (X_val, X_val_spectral, y_val),\n",
    "    optimizer, scheduler, criterion, device, epochs=train_params['num_epochs']\n",
    ")\n",
    "\n",
    "# Save best model\n",
    "if best_model_state is not None:\n",
    "    \n",
    "    # save_model(ensemble_model, os.path.join(CONFIG['new_model_path'], CONFIG['model_names']['ensemble']))\n",
    "\n",
    "    # logging.info(f\"Best ensemble model saved. Final validation accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    ensemble_model.load_state_dict(best_model_state)\n",
    "    test_loss, test_accuracy, test_predictions = evaluate_model(ensemble_model, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "    logging.info(f\"Ensemble Model - Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Generate and save confusion matrix\n",
    "    cm = confusion_matrix(y_test.cpu().numpy(), test_predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    # plt.savefig(os.path.join(CONFIG['new_model_path'], 'confusion_matrix.png'))\n",
    "\n",
    "\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test.cpu().numpy(), test_predictions)\n",
    "    logging.info(f\"Classification Report:\\n{report}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
