{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import scipy.io as sio\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Assuming you have these classes defined in a separate file, import them\n",
    "from sleepdetector_new import ImprovedSleepdetector\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model_params, n_models=3):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList([ImprovedSleepdetector(**model_params) for _ in range(n_models)])\n",
    "    \n",
    "    def forward(self, x, spectral_features):\n",
    "        outputs = [model(x.clone(), spectral_features.clone()) for model in self.models]\n",
    "        return torch.mean(torch.stack(outputs), dim=0)\n",
    "\n",
    "def load_data(filepath, labels_file):\n",
    "    try:\n",
    "        mat_file = sio.loadmat(filepath)\n",
    "        x = np.stack((mat_file['sig1'], mat_file['sig2'], mat_file['sig3'], mat_file['sig4']), axis=0)\n",
    "        x = torch.from_numpy(x).float()\n",
    "        y_true = sio.loadmat(labels_file)['labels'].flatten() - 1\n",
    "        y = torch.from_numpy(y_true).long()\n",
    "        return x.permute(1, 0, 2, 3).squeeze(-1), y\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "def extract_spectral_features(x):\n",
    "    features = []\n",
    "    for channel in x:\n",
    "        f, psd = welch(channel.squeeze().numpy(), fs=100, nperseg=1000)\n",
    "        delta = np.sum(psd[(f >= 0.5) & (f <= 4)])\n",
    "        theta = np.sum(psd[(f > 4) & (f <= 8)])\n",
    "        alpha = np.sum(psd[(f > 8) & (f <= 13)])\n",
    "        beta = np.sum(psd[(f > 13) & (f <= 30)])\n",
    "        features.extend([delta, theta, alpha, beta])\n",
    "    return np.array(features)\n",
    "\n",
    "def prepare_test_data(x, y):\n",
    "    X_test_spectral = np.array([extract_spectral_features(torch.from_numpy(x_i)) for x_i in x.numpy()])\n",
    "    return torch.from_numpy(x.numpy()).float(), torch.from_numpy(X_test_spectral).float(), y\n",
    "\n",
    "def evaluate_model(model, data, device):\n",
    "    model.eval()\n",
    "    X, X_spectral, y = data\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X.to(device), X_spectral.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = accuracy_score(y.cpu().numpy(), predicted.cpu().numpy())\n",
    "        kappa = cohen_kappa_score(y.cpu().numpy(), predicted.cpu().numpy())\n",
    "    return accuracy, kappa, predicted.cpu().numpy()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    class_names = ['N3', 'N2', 'N1', 'REM', 'Awake']\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = '.2f'\n",
    "        title = 'Normalized Confusion Matrix'\n",
    "    else:\n",
    "        fmt = 'd'\n",
    "        title = 'Confusion Matrix, without normalization'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=cmap, square=True, \n",
    "                xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "    \n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Load the best parameters from JSON file\n",
    "    with open('./models/original/best_params_ensemble.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "    \n",
    "    best_model_params = params['best_model_params']\n",
    "    logging.info(f\"Loaded best model parameters: {best_model_params}\")\n",
    "\n",
    "    # Load the saved model\n",
    "    model_state = torch.load(\"./models/original/best_ensemble_model.pth\", map_location=device)\n",
    "    \n",
    "    # Recreate the model architecture using the loaded parameters\n",
    "    model = EnsembleModel(best_model_params, n_models=3).to(device)\n",
    "    \n",
    "    # Load the state dict\n",
    "    model.load_state_dict(model_state)\n",
    "    logging.info(\"Model loaded successfully\")\n",
    "\n",
    "    # # Load and prepare test data\n",
    "    # x_test, y_test = load_data('../data/data.mat', '../data/labels.mat')\n",
    "    # X_test, X_test_spectral, y_test = prepare_test_data(x_test, y_test)\n",
    "\n",
    "\n",
    "    # Load the data from the JSON file\n",
    "    with open('./models/original/test_data_emsemble.json', 'r') as f:\n",
    "        loaded_data = json.load(f)\n",
    "\n",
    "    # Convert lists back to tensors\n",
    "    X_test = torch.tensor(loaded_data['X_test'])\n",
    "    X_test_spectral = torch.tensor(loaded_data['X_test_spectral'])\n",
    "    y_test = torch.tensor(loaded_data['y_test'])\n",
    "    logging.info(\"Test data loaded and prepared successfully\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, kappa, predictions = evaluate_model(model, (X_test, X_test_spectral, y_test), device)\n",
    "    \n",
    "    logging.info(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    logging.info(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "\n",
    "    # Plot and save confusion matrices\n",
    "    fig_norm = plot_confusion_matrix(y_test.numpy(), predictions, normalize=True)\n",
    "    fig_norm.savefig('./images/confusion_matrix_normalized.png')\n",
    "    logging.info(\"Normalized confusion matrix saved to 'images' folder as 'confusion_matrix_normalized.png'\") \n",
    "    \n",
    "\n",
    "    fig_non_norm = plot_confusion_matrix(y_test.numpy(), predictions, normalize=False)\n",
    "    fig_non_norm.savefig('./images/confusion_matrix_non_normalized.png')\n",
    "    logging.info(\"Non-normalized confusion matrix saved to 'images' folder as 'confusion_matrix_non_normalized.png'\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
