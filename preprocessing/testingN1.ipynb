{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.signal import welch\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import optuna\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Import\n",
    "from sleepdetector_new import ImprovedSleepdetector\n",
    "\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "\n",
    "def load_data(filepath, add_dim=False):\n",
    "    try:\n",
    "        # Load the data from the .mat file\n",
    "        mat_file = sio.loadmat(filepath)\n",
    "        \n",
    "        # Stack the signals into x\n",
    "        x = np.stack((mat_file['sig1'], mat_file['sig2'], mat_file['sig3'], mat_file['sig4']), axis=1)\n",
    "        x = torch.from_numpy(x).float()  # Convert to PyTorch tensor\n",
    "        \n",
    "        # Load the labels\n",
    "        y = torch.from_numpy(mat_file['labels'].flatten()).long()\n",
    "        \n",
    "        # Remove epochs where y is -1 (if any)\n",
    "        valid_indices = y != -1\n",
    "        x = x[valid_indices]\n",
    "        y = y[valid_indices]\n",
    "        \n",
    "        # x is already in shape [number of epochs, 4, 3000], so no need to permute\n",
    "        \n",
    "        if add_dim:\n",
    "            x = x.unsqueeze(1)  # Add an extra dimension if required\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_spectral_features(x):\n",
    "    features = []\n",
    "    for channel in x:\n",
    "        f, psd = welch(channel.squeeze().numpy(), fs=100, nperseg=1000)\n",
    "        delta = np.sum(psd[(f >= 0.5) & (f <= 4)])\n",
    "        theta = np.sum(psd[(f > 4) & (f <= 8)])\n",
    "        alpha = np.sum(psd[(f > 8) & (f <= 13)])\n",
    "        beta = np.sum(psd[(f > 13) & (f <= 30)])\n",
    "        features.extend([delta, theta, alpha, beta])\n",
    "    return np.array(features)\n",
    "\n",
    "def prepare_data(x, y, test_size=0.2, split=True):\n",
    "    \"\"\"\n",
    "    Prepare data for training or testing.\n",
    "    \n",
    "    :param x: Input data tensor\n",
    "    :param y: Labels tensor\n",
    "    :param test_size: Proportion of the dataset to include in the test split\n",
    "    :param split: If True, split the data into train and test sets. If False, process all data without splitting.\n",
    "    :return: Processed data tensors\n",
    "    \"\"\"\n",
    "    if split:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x.numpy(), y.numpy(), test_size=test_size, stratify=y, random_state=42)\n",
    "        \n",
    "        X_train_spectral = np.array([extract_spectral_features(torch.from_numpy(x)) for x in X_train])\n",
    "        X_test_spectral = np.array([extract_spectral_features(torch.from_numpy(x)) for x in X_test])\n",
    "        \n",
    "        X_train_combined = np.concatenate([X_train.reshape(X_train.shape[0], -1), X_train_spectral], axis=1)\n",
    "        X_test_combined = np.concatenate([X_test.reshape(X_test.shape[0], -1), X_test_spectral], axis=1)\n",
    "        \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train_combined, y_train)\n",
    "        \n",
    "        original_shape = list(X_train.shape)\n",
    "        original_shape[0] = X_train_resampled.shape[0]\n",
    "        spectral_shape = (X_train_resampled.shape[0], X_train_spectral.shape[1])\n",
    "        \n",
    "        X_train_final = X_train_resampled[:, :-X_train_spectral.shape[1]].reshape(original_shape)\n",
    "        X_train_spectral_final = X_train_resampled[:, -X_train_spectral.shape[1]:].reshape(spectral_shape)\n",
    "        \n",
    "        return (torch.from_numpy(X_train_final).float(),\n",
    "                torch.from_numpy(X_train_spectral_final).float(),\n",
    "                torch.from_numpy(y_train_resampled).long(),\n",
    "                torch.from_numpy(X_test).float(),\n",
    "                torch.from_numpy(X_test_spectral).float(),\n",
    "                torch.from_numpy(y_test).long())\n",
    "    else:\n",
    "        X_spectral = np.array([extract_spectral_features(x_i) for x_i in x])\n",
    "        \n",
    "        return (x.float(),\n",
    "                torch.from_numpy(X_spectral).float(),\n",
    "                y.long())\n",
    "\n",
    "# Model definition\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, model_params, n_models=3):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList([ImprovedSleepdetector(**model_params) for _ in range(n_models)])\n",
    "    \n",
    "    def forward(self, x, spectral_features):\n",
    "        outputs = [model(x.clone(), spectral_features.clone()) for model in self.models]\n",
    "        return torch.mean(torch.stack(outputs), dim=0)\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train_model(model, train_loader, val_data, optimizer, scheduler, criterion, device, epochs=100):\n",
    "    best_accuracy = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Progress\"):\n",
    "        model.train()\n",
    "        for batch_x, batch_x_spectral, batch_y in train_loader:\n",
    "            batch_x, batch_x_spectral, batch_y = batch_x.to(device), batch_x_spectral.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x, batch_x_spectral)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        accuracy = evaluate_model(model, val_data, device)\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_state = model.state_dict()\n",
    "        \n",
    "        scheduler.step(accuracy)\n",
    "    \n",
    "    return best_model_state, best_accuracy\n",
    "\n",
    "# def evaluate_model(model, data, device):\n",
    "#     model.eval()\n",
    "#     X, X_spectral, y = data\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(X.to(device), X_spectral.to(device))\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         accuracy = accuracy_score(y.cpu().numpy(), predicted.cpu().numpy())\n",
    "#     return accuracy\n",
    "\n",
    "def evaluate_model(model, data, device):\n",
    "    model.eval()\n",
    "    try:\n",
    "        X, X_spectral, y = data\n",
    "        logging.info(f\"Data shapes - X: {X.shape}, X_spectral: {X_spectral.shape}, y: {y.shape}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(X.to(device), X_spectral.to(device))\n",
    "            logging.info(f\"Model output shape: {outputs.shape}\")\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            logging.info(f\"Predicted shape: {predicted.shape}\")\n",
    "            \n",
    "            accuracy = accuracy_score(y.cpu().numpy(), predicted.cpu().numpy())\n",
    "            kappa = cohen_kappa_score(y.cpu().numpy(), predicted.cpu().numpy())\n",
    "            \n",
    "        return accuracy, kappa, predicted.cpu().numpy()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in evaluate_model: {e}\")\n",
    "        raise\n",
    "\n",
    "# Hyperparameter optimization\n",
    "def objective(trial, X_train, X_train_spectral, y_train, X_test, X_test_spectral, y_test, device):\n",
    "    model_params = {\n",
    "        'n_filters': trial.suggest_categorical('n_filters', [[32, 64, 128], [64, 128, 256]]),\n",
    "        'lstm_hidden': trial.suggest_int('lstm_hidden', 64, 512),\n",
    "        'lstm_layers': trial.suggest_int('lstm_layers', 1, 3),\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    }\n",
    "    \n",
    "    train_params = {\n",
    "        'lr': trial.suggest_float('lr', 1e-5, 1e-2, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    }\n",
    "    \n",
    "    model = ImprovedSleepdetector(**model_params).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=train_params['lr'])\n",
    "    train_loader = DataLoader(TensorDataset(X_train, X_train_spectral, y_train), batch_size=train_params['batch_size'], shuffle=True)\n",
    "    \n",
    "    _, accuracy = train_model(model, train_loader, (X_test, X_test_spectral, y_test), optimizer, ReduceLROnPlateau(optimizer), nn.CrossEntropyLoss(), device, epochs=10)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Cross-validation\n",
    "def cross_validate(X, X_spectral, y, model_params, train_params, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        X_spectral_train_fold, X_spectral_val_fold = X_spectral[train_idx], X_spectral[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = ImprovedSleepdetector(**model_params).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=train_params['lr'])\n",
    "        train_loader = DataLoader(TensorDataset(X_train_fold, X_spectral_train_fold, y_train_fold), batch_size=train_params['batch_size'], shuffle=True)\n",
    "        \n",
    "        _, accuracy = train_model(model, train_loader, (X_val_fold, X_spectral_val_fold, y_val_fold), optimizer, ReduceLROnPlateau(optimizer), nn.CrossEntropyLoss(), device, epochs=50)\n",
    "        scores.append(accuracy)\n",
    "        \n",
    "        logging.info(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    logging.info(f\"Average Accuracy: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")\n",
    "    return scores\n",
    "\n",
    "# Confusion matrix plotting\n",
    "def plot_confusion_matrix(y_true, y_pred, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Class names in the correct order (0 to 4)\n",
    "    class_names = ['N3', 'N2', 'N1', 'REM', 'Awake']\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f' if normalize else 'd',\n",
    "                cmap=cmap, square=True, xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "x, y = load_data('preprocessed_data_combined.mat')\n",
    "X, X_spectral, y = prepare_data(x, y, split=False)\n",
    "print(f\"X shape: {x.shape}, Y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy.io\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_eeg_and_sleep_stages(x, y, fs, ch_names, start_epoch=0, num_epochs=None):\n",
    "    \"\"\"\n",
    "    Plot EEG data and corresponding sleep stages.\n",
    "    \n",
    "    :param x: EEG data tensor of shape (epochs, channels, time)\n",
    "    :param y: Sleep stage labels tensor of shape (epochs,)\n",
    "    :param fs: Sampling frequency (Hz)\n",
    "    :param ch_names: List of EEG channel names\n",
    "    :param start_epoch: Starting epoch to plot (default 0)\n",
    "    :param num_epochs: Number of epochs to plot (default is all epochs)\n",
    "    \"\"\"\n",
    "    if num_epochs is None:\n",
    "        num_epochs = x.shape[0]\n",
    "    \n",
    "    start_epoch = max(0, min(start_epoch, x.shape[0] - num_epochs))\n",
    "    \n",
    "    plot_x = x[start_epoch:start_epoch+num_epochs].numpy()\n",
    "    plot_y = y[start_epoch:start_epoch+num_epochs].numpy()\n",
    "    \n",
    "    num_samples_per_epoch = plot_x.shape[2]\n",
    "    total_samples = num_epochs * num_samples_per_epoch\n",
    "    time_vector = np.arange(total_samples) / fs\n",
    "    \n",
    "    # fig, axs = plt.subplots(5, 1, figsize=(15, 12), sharex=True, gridspec_kw={'height_ratios': [3, 3, 3, 3, 1]})\n",
    "    fig, axs = plt.subplots(5, 1, figsize=(15, 12), sharex=False, gridspec_kw={'height_ratios': [3, 3, 3, 3, 1]})\n",
    "    fig.suptitle(f'EEG Data and Sleep Stages (Epochs {start_epoch} to {start_epoch+num_epochs-1})')\n",
    "    \n",
    "    for i in range(4):\n",
    "        flattened_data = plot_x[:, i, :].flatten()\n",
    "        axs[i].plot(time_vector, flattened_data)\n",
    "        axs[i].set_ylabel(ch_names[i])\n",
    "        axs[i].set_xlim(0, total_samples / fs)\n",
    "        axs[i].set_ylim(flattened_data.min(), flattened_data.max())\n",
    "    \n",
    "    stage_colors = ['purple', 'blue', 'green', 'yellow', 'red']  # Colors for N3, N2, N1, REM, Awake\n",
    "    cmap = ListedColormap(stage_colors)\n",
    "    \n",
    "    epoch_duration = num_samples_per_epoch / fs\n",
    "    for i, stage in enumerate(plot_y):\n",
    "        start = i * epoch_duration\n",
    "        end = (i + 1) * epoch_duration\n",
    "        axs[4].axvspan(start, end, facecolor=stage_colors[int(stage)], alpha=0.7)\n",
    "    \n",
    "    axs[4].set_yticks([])\n",
    "    # axs[4].set_xlabel('Time (seconds)')   \n",
    "    axs[4].set_xlim(0, total_samples / fs)\n",
    "\n",
    "    print(\"Total Length of time in hours:\", total_samples / fs / 3600)\n",
    "\n",
    "    for i in range(5):  # Now including the sleep stage plot\n",
    "        axs[i].set_xlabel('Time (seconds)')\n",
    "\n",
    "    # Create legend elements\n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=stage_colors[i], alpha=0.7) \n",
    "                       for i in range(5)]\n",
    "    \n",
    "    # Add legend to the right side under the graph\n",
    "    fig.legend(legend_elements, ['N3', 'N2', 'N1', 'REM', 'Awake'], \n",
    "               loc='lower right', bbox_to_anchor=(0.98, 0.02), ncol=1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Adjust the layout to make room for the legend\n",
    "    plt.subplots_adjust(bottom=0.1, right=.9)\n",
    "    return fig\n",
    "\n",
    "# Usage remains the same\n",
    "fs = scipy.io.loadmat('./preprocessed_data.mat')['Fs'].flatten()[0]\n",
    "ch_names = scipy.io.loadmat('./preprocessed_data.mat')['ch_names'].flatten().tolist()\n",
    "\n",
    "# Plot all epochs\n",
    "plot_eeg_and_sleep_stages(x, y, fs, ch_names, start_epoch=0, num_epochs=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load the best parameters from JSON file\n",
    "    with open('../models/best_params_ensemble.json', 'r') as f:\n",
    "        params = json.load(f)\n",
    "    \n",
    "    best_model_params = params['best_model_params']\n",
    "    logging.info(f\"Loaded best model parameters: {best_model_params}\")\n",
    "\n",
    "    # Load the saved model\n",
    "    model_state = torch.load(\"../models/best_ensemble_model.pth\", map_location=device)\n",
    "    \n",
    "    # Recreate the model architecture using the loaded parameters\n",
    "    model = EnsembleModel(best_model_params, n_models=3).to(device)\n",
    "    \n",
    "    # Load the state dict\n",
    "    model.load_state_dict(model_state)\n",
    "    logging.info(\"Model loaded successfully\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    logging.info(\"Starting model evaluation\")\n",
    "    accuracy, kappa, predictions = evaluate_model(model, (X, X_spectral, y), device)\n",
    "    \n",
    "    logging.info(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    logging.info(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "\n",
    "    # Plot and save confusion matrices\n",
    "    fig_norm = plot_confusion_matrix(y.numpy(), predictions, normalize=True)\n",
    "    fig_norm.savefig('../images/confusion_matrix_normalized.png')\n",
    "    logging.info(\"Normalized confusion matrix saved to 'images' folder as 'confusion_matrix_normalized.png'\") \n",
    "    \n",
    "\n",
    "    fig_non_norm = plot_confusion_matrix(y.numpy(), predictions, normalize=False)\n",
    "    fig_non_norm.savefig('../images/confusion_matrix_non_normalized.png')\n",
    "    logging.info(\"Non-normalized confusion matrix saved to 'images' folder as 'confusion_matrix_non_normalized.png'\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")\n",
    "    logging.error(f\"Error type: {type(e)}\")\n",
    "    logging.error(f\"Error args: {e.args}\")\n",
    "    # Optionally, print the full traceback\n",
    "    import traceback\n",
    "    logging.error(f\"Traceback: {traceback.format_exc()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
