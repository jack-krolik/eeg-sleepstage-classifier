{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.functions import *\n",
    "from tools.classes import *\n",
    "from tools.utils import *\n",
    "from tools.config import CONFIG, device\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.utils.tensorboard import SummaryWriter as TorchSummaryWriter\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 21:27:34,284 - INFO - Loaded data shape: torch.Size([1066, 4, 3000]), Labels shape: torch.Size([1066])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data shape: torch.Size([1066, 4, 3000]), Labels shape: torch.Size([1066])\n",
      "Original train set class distribution:\n",
      "Counter({1: 467, 3: 134, 4: 100, 2: 39, 0: 5})\n",
      "Not enough samples in minority class for SMOTE. Using simple oversampling.\n",
      "After simple oversampling train set class distribution:\n",
      "Counter({2: 467, 1: 467, 4: 467, 3: 467, 0: 467})\n"
     ]
    }
   ],
   "source": [
    "# Ensure the model save directory exists\n",
    "ensure_dir(CONFIG['new_model_path'])\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    x, y = load_data(CONFIG['data_path'])\n",
    "    logging.info(f\"Loaded data shape: {x.shape}, Labels shape: {y.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading data: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Prepare the data (includes SMOTE)\n",
    "X_train, X_train_spectral, y_train, X_val, X_val_spectral, y_val, X_test, X_test_spectral, y_test = prepare_data(x, y)\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train, X_train_spectral = preprocess_data(X_train, X_train_spectral)\n",
    "X_val, X_val_spectral = preprocess_data(X_val, X_val_spectral)\n",
    "X_test, X_test_spectral = preprocess_data(X_test, X_test_spectral)\n",
    "\n",
    "# Identify minority classes for augmentation\n",
    "class_counts = Counter(y_train.numpy())\n",
    "minority_classes = [cls for cls, count in class_counts.items() if count < len(y_train) / len(class_counts) * 0.5]\n",
    "\n",
    "# Apply augmentation\n",
    "X_train, X_train_spectral, y_train = augment_minority_classes(X_train, X_train_spectral, y_train, minority_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 21:27:42,538 - INFO - Starting hyperparameter tuning...\n",
      "[I 2024-10-21 21:27:42,540] A new study created in memory with name: no-name-95b6821d-aa04-4c89-900d-d383110fd2e5\n",
      "/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/distributions.py:524: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains [32, 64, 128] which is of type list.\n",
      "  warnings.warn(message)\n",
      "/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "Training Progress:   0%|          | 0/1 [01:39<?, ?it/s]\n",
      "[W 2024-10-21 21:29:29,382] Trial 0 failed with parameters: {'n_filters': [32, 64, 128], 'lstm_hidden': 264, 'lstm_layers': 2, 'dropout': 0.22931168779815797, 'batch_size': 32, 'lr': 0.0031208472635093423} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py\", line 450, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, X, X_spectral, y, device, start_with_config=start_with_config), n_trials=n_trials)\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py\", line 435, in objective\n",
      "    train_model(model, train_loader, (X_val, X_val_spectral, y_val),\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py\", line 473, in train_model\n",
      "    outputs = model(batch_x, batch_x_spectral)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/classes.py\", line 25, in forward\n",
      "    outputs = [model(x.clone(), spectral_features.clone()) for model in self.models]\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/tools/classes.py\", line 25, in <listcomp>\n",
      "    outputs = [model(x.clone(), spectral_features.clone()) for model in self.models]\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/sleepdetector_new.py\", line 200, in forward\n",
      "    x_cnn = self.cnn(x)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/eeg-sleepstage-classifier/sleepdetector_new.py\", line 53, in forward\n",
      "    x_i = self.conv_blocks[i](x_i)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 308, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 304, in _conv_forward\n",
      "    return F.conv1d(input, weight, bias, self.stride,\n",
      "KeyboardInterrupt\n",
      "[W 2024-10-21 21:29:29,396] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_tuning:\n\u001b[1;32m      6\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting hyperparameter tuning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m \u001b[43mrun_hyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_spectral\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_with_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_with_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Initialize model with best parameters\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     model_params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m best_params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_filters\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_hidden\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlstm_layers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py:450\u001b[0m, in \u001b[0;36mrun_hyperparameter_tuning\u001b[0;34m(X, X_spectral, y, device, n_trials, start_with_config)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_hyperparameter_tuning\u001b[39m(X, X_spectral, y, device, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, start_with_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    449\u001b[0m     study \u001b[38;5;241m=\u001b[39m create_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mTPESampler())\n\u001b[0;32m--> 450\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_spectral\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_with_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_with_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m    453\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py:450\u001b[0m, in \u001b[0;36mrun_hyperparameter_tuning.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_hyperparameter_tuning\u001b[39m(X, X_spectral, y, device, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, start_with_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    449\u001b[0m     study \u001b[38;5;241m=\u001b[39m create_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mTPESampler())\n\u001b[0;32m--> 450\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_spectral\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_with_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_with_config\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39mn_trials)\n\u001b[1;32m    452\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m    453\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py:435\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, X, X_spectral, y, device, n_folds, start_with_config)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# Train for a few epochs\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# Reduced number of epochs for faster tuning\u001b[39;00m\n\u001b[0;32m--> 435\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_spectral\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m    439\u001b[0m val_loss, val_accuracy, _ \u001b[38;5;241m=\u001b[39m evaluate_model(model, (X_val, X_val_spectral, y_val), criterion, device)\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/tools/functions.py:473\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_data, optimizer, scheduler, criterion, device, epochs, patience, accumulation_steps, verbose)\u001b[0m\n\u001b[1;32m    470\u001b[0m batch_x, batch_x_spectral, batch_y \u001b[38;5;241m=\u001b[39m batch_x\u001b[38;5;241m.\u001b[39mto(device), batch_x_spectral\u001b[38;5;241m.\u001b[39mto(device), batch_y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype):\n\u001b[0;32m--> 473\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x_spectral\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, batch_y)\n\u001b[1;32m    475\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m accumulation_steps  \u001b[38;5;66;03m# Normalize the loss because it is accumulated\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/tools/classes.py:25\u001b[0m, in \u001b[0;36mEnsembleModel.forward\u001b[0;34m(self, x, spectral_features)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, spectral_features):\n\u001b[0;32m---> 25\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [model(x\u001b[38;5;241m.\u001b[39mclone(), spectral_features\u001b[38;5;241m.\u001b[39mclone()) \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels]\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(outputs), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/tools/classes.py:25\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, spectral_features):\n\u001b[0;32m---> 25\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectral_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels]\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mstack(outputs), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/sleepdetector_new.py:200\u001b[0m, in \u001b[0;36mImprovedSleepdetector.forward\u001b[0;34m(self, x, spectral_features)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Normalize spectral features\u001b[39;00m\n\u001b[1;32m    198\u001b[0m spectral_features \u001b[38;5;241m=\u001b[39m (spectral_features \u001b[38;5;241m-\u001b[39m spectral_features\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;241m/\u001b[39m (spectral_features\u001b[38;5;241m.\u001b[39mstd(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m epsilon)\n\u001b[0;32m--> 200\u001b[0m x_cnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misfinite(x_cnn)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m    202\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-finite values detected after CNN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_cnn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jkrolik/eeg-sleepstage-classifier/sleepdetector_new.py:53\u001b[0m, in \u001b[0;36mImprovedSleepDetectorCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     52\u001b[0m     x_i \u001b[38;5;241m=\u001b[39m x[:, i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 53\u001b[0m     x_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_blocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     x_list\u001b[38;5;241m.\u001b[39mappend(x_i)\n\u001b[1;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(x_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/userdata/jkrolik/miniconda3/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_tuning = True\n",
    "start_with_config = True  # Set this to True to start with CONFIG parameters\n",
    "fine_tune_lr = True  # Set this to True if you want to fine-tune the learning rate after hyperparameter tuning\n",
    "\n",
    "if run_tuning:\n",
    "    logging.info(\"Starting hyperparameter tuning...\")\n",
    "    best_params = run_hyperparameter_tuning(X_train, X_train_spectral, y_train, device, start_with_config=start_with_config)\n",
    "    \n",
    "    # Initialize model with best parameters\n",
    "    model_params = {k: v for k, v in best_params.items() if k in ['n_filters', 'lstm_hidden', 'lstm_layers', 'dropout']}\n",
    "    ensemble_model = EnsembleModel(model_params).to(device)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = create_data_loaders(X_train, X_train_spectral, y_train, batch_size=best_params['batch_size'], is_train=True)\n",
    "    val_loader = create_data_loaders(X_val, X_val_spectral, y_val, batch_size=best_params['batch_size'], is_train=False)\n",
    "    \n",
    "    # Set up loss function\n",
    "    class_weights = get_class_weights(y_train).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights + 1e-6, label_smoothing=0.1)\n",
    "    \n",
    "    # Optionally, find best learning rate\n",
    "    if fine_tune_lr:\n",
    "        temp_optimizer = optim.AdamW(ensemble_model.parameters(), lr=best_params['lr'], weight_decay=1e-5)\n",
    "        best_lr = find_lr(ensemble_model, train_loader, val_loader, temp_optimizer, criterion, device, start_lr=best_params['lr'])\n",
    "        logging.info(f\"Fine-tuned learning rate: {best_lr}\")\n",
    "    else:\n",
    "        best_lr = best_params['lr']\n",
    "    \n",
    "    params = {\n",
    "        'model_params': model_params,\n",
    "        'train_params': {'lr': best_lr, 'batch_size': best_params['batch_size'], 'num_epochs': CONFIG['initial_params']['train_params']['num_epochs'], 'patience': CONFIG['initial_params']['train_params']['patience']}\n",
    "    }\n",
    "else:\n",
    "    params = CONFIG['initial_params']\n",
    "    ensemble_model, _ = initialize_model(device)\n",
    "\n",
    "if CONFIG['use_pretrained_weights']:\n",
    "    pretrained_path = os.path.join(CONFIG['old_model_path'], CONFIG['model_names']['ensemble'])\n",
    "    ensemble_model.load_state_dict(torch.load(pretrained_path))\n",
    "    logging.info(f\"Loaded pretrained weights from {pretrained_path}\")\n",
    "\n",
    "# Save parameters\n",
    "save_params(params, os.path.join(CONFIG['new_model_path'], 'tuned_params.json'))\n",
    "\n",
    "# Set up training parameters\n",
    "train_params = params['train_params']\n",
    "train_loader = create_data_loaders(X_train, X_train_spectral, y_train, batch_size=train_params['batch_size'], is_train=True)\n",
    "val_loader = create_data_loaders(X_val, X_val_spectral, y_val, batch_size=train_params['batch_size'], is_train=False)\n",
    "\n",
    "# Set up optimizer and scheduler with the selected learning rate\n",
    "optimizer = optim.AdamW(ensemble_model.parameters(), lr=train_params['lr'], weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Train model\n",
    "best_model_state, best_accuracy = train_model(\n",
    "    ensemble_model, train_loader, (X_val, X_val_spectral, y_val),\n",
    "    optimizer, scheduler, criterion, device, epochs=train_params['num_epochs'], patience=train_params['patience']\n",
    ")\n",
    "\n",
    "# Save best model\n",
    "if best_model_state is not None:\n",
    "    save_model(ensemble_model, os.path.join(CONFIG['new_model_path'], CONFIG['model_names']['ensemble']))\n",
    "    logging.info(f\"Best ensemble model saved. Final validation accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    ensemble_model.load_state_dict(best_model_state)\n",
    "    test_loss, test_accuracy, test_predictions = evaluate_model(ensemble_model, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "    logging.info(f\"Ensemble Model - Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Generate and save confusion matrix\n",
    "    cm = confusion_matrix(y_test.cpu().numpy(), test_predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(os.path.join(CONFIG['new_model_path'], 'confusion_matrix.png'))\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test.cpu().numpy(), test_predictions)\n",
    "    logging.info(f\"Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 13:33:59,552 - INFO - Training diverse ensemble model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/2335 (0%)]\tLoss: 1.609874\n",
      "Validation set: Average loss: 1.5474, Accuracy: 34/107 (0.32%)\n",
      "Train Epoch: 1 [0/2335 (0%)]\tLoss: 0.438405\n",
      "Validation set: Average loss: 0.9783, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 2 [0/2335 (0%)]\tLoss: 0.411211\n",
      "Validation set: Average loss: 1.0700, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 3 [0/2335 (0%)]\tLoss: 0.410981\n",
      "Validation set: Average loss: 1.5015, Accuracy: 38/107 (0.36%)\n",
      "Train Epoch: 4 [0/2335 (0%)]\tLoss: 0.397645\n",
      "Validation set: Average loss: 2.0008, Accuracy: 22/107 (0.21%)\n",
      "Train Epoch: 5 [0/2335 (0%)]\tLoss: 0.393372\n",
      "Validation set: Average loss: 1.1069, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 6 [0/2335 (0%)]\tLoss: 0.394297\n",
      "Validation set: Average loss: 0.9498, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 7 [0/2335 (0%)]\tLoss: 0.397859\n",
      "Validation set: Average loss: 0.9906, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 8 [0/2335 (0%)]\tLoss: 0.402578\n",
      "Validation set: Average loss: 1.2587, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 9 [0/2335 (0%)]\tLoss: 0.392408\n",
      "Validation set: Average loss: 1.6496, Accuracy: 35/107 (0.33%)\n",
      "Train Epoch: 10 [0/2335 (0%)]\tLoss: 0.393125\n",
      "Validation set: Average loss: 1.2008, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 11 [0/2335 (0%)]\tLoss: 0.393768\n",
      "Validation set: Average loss: 1.3121, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 12 [0/2335 (0%)]\tLoss: 0.392451\n",
      "Validation set: Average loss: 1.4315, Accuracy: 52/107 (0.49%)\n",
      "Train Epoch: 13 [0/2335 (0%)]\tLoss: 0.393038\n",
      "Validation set: Average loss: 1.2661, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 14 [0/2335 (0%)]\tLoss: 0.396981\n",
      "Validation set: Average loss: 1.0636, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 15 [0/2335 (0%)]\tLoss: 0.415455\n",
      "Validation set: Average loss: 1.6936, Accuracy: 43/107 (0.40%)\n",
      "Train Epoch: 16 [0/2335 (0%)]\tLoss: 0.395934\n",
      "Validation set: Average loss: 0.6667, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 17 [0/2335 (0%)]\tLoss: 0.393591\n",
      "Validation set: Average loss: 0.9089, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 18 [0/2335 (0%)]\tLoss: 0.392882\n",
      "Validation set: Average loss: 0.9945, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 19 [0/2335 (0%)]\tLoss: 0.391194\n",
      "Validation set: Average loss: 0.9260, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 20 [0/2335 (0%)]\tLoss: 0.392554\n",
      "Validation set: Average loss: 0.9103, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 21 [0/2335 (0%)]\tLoss: 0.391785\n",
      "Validation set: Average loss: 0.9129, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 22 [0/2335 (0%)]\tLoss: 0.391859\n",
      "Validation set: Average loss: 1.0032, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 23 [0/2335 (0%)]\tLoss: 0.392704\n",
      "Validation set: Average loss: 1.0124, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 24 [0/2335 (0%)]\tLoss: 0.391263\n",
      "Validation set: Average loss: 1.0252, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 25 [0/2335 (0%)]\tLoss: 0.391293\n",
      "Validation set: Average loss: 0.8946, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 26 [0/2335 (0%)]\tLoss: 0.390987\n",
      "Validation set: Average loss: 0.9173, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 27 [0/2335 (0%)]\tLoss: 0.390883\n",
      "Validation set: Average loss: 0.9676, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 28 [0/2335 (0%)]\tLoss: 0.391187\n",
      "Validation set: Average loss: 0.9666, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 29 [0/2335 (0%)]\tLoss: 0.391021\n",
      "Validation set: Average loss: 0.9471, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 30 [0/2335 (0%)]\tLoss: 0.391506\n",
      "Validation set: Average loss: 0.9756, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 31 [0/2335 (0%)]\tLoss: 0.391302\n",
      "Validation set: Average loss: 0.8718, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 32 [0/2335 (0%)]\tLoss: 0.392477\n",
      "Validation set: Average loss: 1.1012, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 33 [0/2335 (0%)]\tLoss: 0.393759\n",
      "Validation set: Average loss: 0.6805, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 34 [0/2335 (0%)]\tLoss: 0.401312\n",
      "Validation set: Average loss: 1.4116, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 35 [0/2335 (0%)]\tLoss: 0.405760\n",
      "Validation set: Average loss: 1.4813, Accuracy: 41/107 (0.38%)\n",
      "Train Epoch: 36 [0/2335 (0%)]\tLoss: 0.398082\n",
      "Validation set: Average loss: 0.9486, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 37 [0/2335 (0%)]\tLoss: 0.400234\n",
      "Validation set: Average loss: 0.8790, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 38 [0/2335 (0%)]\tLoss: 0.393448\n",
      "Validation set: Average loss: 0.8855, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 39 [0/2335 (0%)]\tLoss: 0.391687\n",
      "Validation set: Average loss: 0.7824, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 40 [0/2335 (0%)]\tLoss: 0.391741\n",
      "Validation set: Average loss: 0.9380, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 41 [0/2335 (0%)]\tLoss: 0.399068\n",
      "Validation set: Average loss: 0.7317, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 42 [0/2335 (0%)]\tLoss: 0.391297\n",
      "Validation set: Average loss: 0.7755, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 43 [0/2335 (0%)]\tLoss: 0.391366\n",
      "Validation set: Average loss: 0.7278, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 44 [0/2335 (0%)]\tLoss: 0.391466\n",
      "Validation set: Average loss: 0.6544, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 45 [0/2335 (0%)]\tLoss: 0.391589\n",
      "Validation set: Average loss: 0.7524, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 46 [0/2335 (0%)]\tLoss: 0.390964\n",
      "Validation set: Average loss: 0.7369, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 47 [0/2335 (0%)]\tLoss: 0.391413\n",
      "Validation set: Average loss: 0.7548, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 48 [0/2335 (0%)]\tLoss: 0.392570\n",
      "Validation set: Average loss: 0.6926, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 49 [0/2335 (0%)]\tLoss: 0.391281\n",
      "Validation set: Average loss: 0.9567, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 50 [0/2335 (0%)]\tLoss: 0.391050\n",
      "Validation set: Average loss: 0.7116, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 51 [0/2335 (0%)]\tLoss: 0.391212\n",
      "Validation set: Average loss: 0.7623, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 52 [0/2335 (0%)]\tLoss: 0.391027\n",
      "Validation set: Average loss: 1.0637, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 53 [0/2335 (0%)]\tLoss: 0.391115\n",
      "Validation set: Average loss: 0.6968, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 54 [0/2335 (0%)]\tLoss: 0.391516\n",
      "Validation set: Average loss: 0.7064, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 55 [0/2335 (0%)]\tLoss: 0.390982\n",
      "Validation set: Average loss: 0.6964, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 56 [0/2335 (0%)]\tLoss: 0.391103\n",
      "Validation set: Average loss: 0.7031, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 57 [0/2335 (0%)]\tLoss: 0.391192\n",
      "Validation set: Average loss: 0.9383, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 58 [0/2335 (0%)]\tLoss: 0.390884\n",
      "Validation set: Average loss: 0.7549, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 59 [0/2335 (0%)]\tLoss: 0.391238\n",
      "Validation set: Average loss: 0.7209, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 60 [0/2335 (0%)]\tLoss: 0.395824\n",
      "Validation set: Average loss: 0.7794, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 61 [0/2335 (0%)]\tLoss: 0.390733\n",
      "Validation set: Average loss: 0.7047, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 62 [0/2335 (0%)]\tLoss: 0.391262\n",
      "Validation set: Average loss: 0.7005, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 63 [0/2335 (0%)]\tLoss: 0.390930\n",
      "Validation set: Average loss: 0.7284, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 64 [0/2335 (0%)]\tLoss: 0.391073\n",
      "Validation set: Average loss: 0.7536, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 65 [0/2335 (0%)]\tLoss: 0.391289\n",
      "Validation set: Average loss: 0.7617, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 66 [0/2335 (0%)]\tLoss: 0.390927\n",
      "Validation set: Average loss: 0.7337, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 67 [0/2335 (0%)]\tLoss: 0.390672\n",
      "Validation set: Average loss: 0.7881, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 68 [0/2335 (0%)]\tLoss: 0.390780\n",
      "Validation set: Average loss: 0.7207, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 69 [0/2335 (0%)]\tLoss: 0.390818\n",
      "Validation set: Average loss: 0.7107, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 70 [0/2335 (0%)]\tLoss: 0.391338\n",
      "Validation set: Average loss: 0.7654, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 71 [0/2335 (0%)]\tLoss: 0.391451\n",
      "Validation set: Average loss: 0.6710, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 72 [0/2335 (0%)]\tLoss: 0.391215\n",
      "Validation set: Average loss: 0.6760, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 73 [0/2335 (0%)]\tLoss: 0.391738\n",
      "Validation set: Average loss: 0.7288, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 74 [0/2335 (0%)]\tLoss: 0.391265\n",
      "Validation set: Average loss: 0.7639, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 75 [0/2335 (0%)]\tLoss: 0.397891\n",
      "Validation set: Average loss: 0.6976, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 76 [0/2335 (0%)]\tLoss: 0.411484\n",
      "Validation set: Average loss: 1.2324, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 77 [0/2335 (0%)]\tLoss: 0.406400\n",
      "Validation set: Average loss: 0.7751, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 78 [0/2335 (0%)]\tLoss: 0.408910\n",
      "Validation set: Average loss: 0.7480, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 79 [0/2335 (0%)]\tLoss: 0.394024\n",
      "Validation set: Average loss: 0.9660, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 80 [0/2335 (0%)]\tLoss: 0.397951\n",
      "Validation set: Average loss: 0.7135, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 81 [0/2335 (0%)]\tLoss: 0.391406\n",
      "Validation set: Average loss: 1.8361, Accuracy: 15/107 (0.14%)\n",
      "Train Epoch: 82 [0/2335 (0%)]\tLoss: 0.391093\n",
      "Validation set: Average loss: 0.9440, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 83 [0/2335 (0%)]\tLoss: 0.391655\n",
      "Validation set: Average loss: 1.3767, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 84 [0/2335 (0%)]\tLoss: 0.413362\n",
      "Validation set: Average loss: 0.6971, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 85 [0/2335 (0%)]\tLoss: 0.391680\n",
      "Validation set: Average loss: 0.7193, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 86 [0/2335 (0%)]\tLoss: 0.390822\n",
      "Validation set: Average loss: 0.8748, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 87 [0/2335 (0%)]\tLoss: 0.391309\n",
      "Validation set: Average loss: 0.7065, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 88 [0/2335 (0%)]\tLoss: 0.391225\n",
      "Validation set: Average loss: 0.7559, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 89 [0/2335 (0%)]\tLoss: 0.390970\n",
      "Validation set: Average loss: 0.6921, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 90 [0/2335 (0%)]\tLoss: 0.391030\n",
      "Validation set: Average loss: 0.9977, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 91 [0/2335 (0%)]\tLoss: 0.391351\n",
      "Validation set: Average loss: 1.3331, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 92 [0/2335 (0%)]\tLoss: 0.392123\n",
      "Validation set: Average loss: 0.7201, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 93 [0/2335 (0%)]\tLoss: 0.390735\n",
      "Validation set: Average loss: 1.1675, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 94 [0/2335 (0%)]\tLoss: 0.390791\n",
      "Validation set: Average loss: 0.6509, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 95 [0/2335 (0%)]\tLoss: 0.390715\n",
      "Validation set: Average loss: 0.7297, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 96 [0/2335 (0%)]\tLoss: 0.391186\n",
      "Validation set: Average loss: 1.7224, Accuracy: 43/107 (0.40%)\n",
      "Train Epoch: 97 [0/2335 (0%)]\tLoss: 0.391571\n",
      "Validation set: Average loss: 1.6711, Accuracy: 48/107 (0.45%)\n",
      "Train Epoch: 98 [0/2335 (0%)]\tLoss: 0.390506\n",
      "Validation set: Average loss: 0.7856, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 99 [0/2335 (0%)]\tLoss: 0.390759\n",
      "Validation set: Average loss: 1.5185, Accuracy: 55/107 (0.51%)\n",
      "Train Epoch: 100 [0/2335 (0%)]\tLoss: 0.390857\n",
      "Validation set: Average loss: 0.8371, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 101 [0/2335 (0%)]\tLoss: 0.390755\n",
      "Validation set: Average loss: 1.2182, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 102 [0/2335 (0%)]\tLoss: 0.390980\n",
      "Validation set: Average loss: 1.3849, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 103 [0/2335 (0%)]\tLoss: 0.390730\n",
      "Validation set: Average loss: 0.6896, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 104 [0/2335 (0%)]\tLoss: 0.390952\n",
      "Validation set: Average loss: 1.3465, Accuracy: 56/107 (0.52%)\n",
      "Train Epoch: 105 [0/2335 (0%)]\tLoss: 0.391143\n",
      "Validation set: Average loss: 0.8939, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 106 [0/2335 (0%)]\tLoss: 0.390780\n",
      "Validation set: Average loss: 0.7562, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 107 [0/2335 (0%)]\tLoss: 0.390663\n",
      "Validation set: Average loss: 0.7988, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 108 [0/2335 (0%)]\tLoss: 0.391033\n",
      "Validation set: Average loss: 0.6334, Accuracy: 97/107 (0.91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 13:58:03,068 - INFO - New best diverse ensemble model saved. Accuracy: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 109 [0/2335 (0%)]\tLoss: 0.390777\n",
      "Validation set: Average loss: 0.7205, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 110 [0/2335 (0%)]\tLoss: 0.391298\n",
      "Validation set: Average loss: 0.7797, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 111 [0/2335 (0%)]\tLoss: 0.391286\n",
      "Validation set: Average loss: 0.6538, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 112 [0/2335 (0%)]\tLoss: 0.390408\n",
      "Validation set: Average loss: 0.6700, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 113 [0/2335 (0%)]\tLoss: 0.390848\n",
      "Validation set: Average loss: 0.6892, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 114 [0/2335 (0%)]\tLoss: 0.390763\n",
      "Validation set: Average loss: 0.6523, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 115 [0/2335 (0%)]\tLoss: 0.390743\n",
      "Validation set: Average loss: 0.9589, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 116 [0/2335 (0%)]\tLoss: 0.390808\n",
      "Validation set: Average loss: 0.8330, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 117 [0/2335 (0%)]\tLoss: 0.390971\n",
      "Validation set: Average loss: 0.8865, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 118 [0/2335 (0%)]\tLoss: 0.390732\n",
      "Validation set: Average loss: 0.7513, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 119 [0/2335 (0%)]\tLoss: 0.390556\n",
      "Validation set: Average loss: 0.7986, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 120 [0/2335 (0%)]\tLoss: 0.390883\n",
      "Validation set: Average loss: 0.9080, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 121 [0/2335 (0%)]\tLoss: 0.390617\n",
      "Validation set: Average loss: 0.7492, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 122 [0/2335 (0%)]\tLoss: 0.391021\n",
      "Validation set: Average loss: 0.8238, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 123 [0/2335 (0%)]\tLoss: 0.390916\n",
      "Validation set: Average loss: 0.8047, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 124 [0/2335 (0%)]\tLoss: 0.390534\n",
      "Validation set: Average loss: 0.6593, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 125 [0/2335 (0%)]\tLoss: 0.390748\n",
      "Validation set: Average loss: 0.6725, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 126 [0/2335 (0%)]\tLoss: 0.390671\n",
      "Validation set: Average loss: 1.1499, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 127 [0/2335 (0%)]\tLoss: 0.390715\n",
      "Validation set: Average loss: 0.8848, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 128 [0/2335 (0%)]\tLoss: 0.390638\n",
      "Validation set: Average loss: 0.6598, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 129 [0/2335 (0%)]\tLoss: 0.390637\n",
      "Validation set: Average loss: 0.8004, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 130 [0/2335 (0%)]\tLoss: 0.390594\n",
      "Validation set: Average loss: 0.9222, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 131 [0/2335 (0%)]\tLoss: 0.390704\n",
      "Validation set: Average loss: 0.6400, Accuracy: 97/107 (0.91%)\n",
      "Train Epoch: 132 [0/2335 (0%)]\tLoss: 0.390641\n",
      "Validation set: Average loss: 1.1065, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 133 [0/2335 (0%)]\tLoss: 0.390716\n",
      "Validation set: Average loss: 1.0196, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 134 [0/2335 (0%)]\tLoss: 0.390455\n",
      "Validation set: Average loss: 0.7304, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 135 [0/2335 (0%)]\tLoss: 0.390606\n",
      "Validation set: Average loss: 0.9276, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 136 [0/2335 (0%)]\tLoss: 0.390758\n",
      "Validation set: Average loss: 0.7738, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 137 [0/2335 (0%)]\tLoss: 0.390720\n",
      "Validation set: Average loss: 0.6546, Accuracy: 97/107 (0.91%)\n",
      "Train Epoch: 138 [0/2335 (0%)]\tLoss: 0.390469\n",
      "Validation set: Average loss: 0.6576, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 139 [0/2335 (0%)]\tLoss: 0.390730\n",
      "Validation set: Average loss: 0.6409, Accuracy: 97/107 (0.91%)\n",
      "Train Epoch: 140 [0/2335 (0%)]\tLoss: 0.390499\n",
      "Validation set: Average loss: 0.9965, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 141 [0/2335 (0%)]\tLoss: 0.390508\n",
      "Validation set: Average loss: 0.7932, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 142 [0/2335 (0%)]\tLoss: 0.390876\n",
      "Validation set: Average loss: 0.6488, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 143 [0/2335 (0%)]\tLoss: 0.390478\n",
      "Validation set: Average loss: 0.8714, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 144 [0/2335 (0%)]\tLoss: 0.390924\n",
      "Validation set: Average loss: 0.8752, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 145 [0/2335 (0%)]\tLoss: 0.390956\n",
      "Validation set: Average loss: 0.7790, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 146 [0/2335 (0%)]\tLoss: 0.390620\n",
      "Validation set: Average loss: 0.7436, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 147 [0/2335 (0%)]\tLoss: 0.390794\n",
      "Validation set: Average loss: 0.6626, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 148 [0/2335 (0%)]\tLoss: 0.390947\n",
      "Validation set: Average loss: 0.7322, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 149 [0/2335 (0%)]\tLoss: 0.390404\n",
      "Validation set: Average loss: 0.6724, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 150 [0/2335 (0%)]\tLoss: 0.390674\n",
      "Validation set: Average loss: 0.6638, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 151 [0/2335 (0%)]\tLoss: 0.391497\n",
      "Validation set: Average loss: 1.0126, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 152 [0/2335 (0%)]\tLoss: 0.391041\n",
      "Validation set: Average loss: 1.4614, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 153 [0/2335 (0%)]\tLoss: 0.397710\n",
      "Validation set: Average loss: 1.3890, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 154 [0/2335 (0%)]\tLoss: 0.392126\n",
      "Validation set: Average loss: 0.6941, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 155 [0/2335 (0%)]\tLoss: 0.392352\n",
      "Validation set: Average loss: 0.9162, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 156 [0/2335 (0%)]\tLoss: 0.400369\n",
      "Validation set: Average loss: 1.0156, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 157 [0/2335 (0%)]\tLoss: 0.402811\n",
      "Validation set: Average loss: 1.0908, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 158 [0/2335 (0%)]\tLoss: 0.402550\n",
      "Validation set: Average loss: 0.7304, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 159 [0/2335 (0%)]\tLoss: 0.391673\n",
      "Validation set: Average loss: 1.1386, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 160 [0/2335 (0%)]\tLoss: 0.391763\n",
      "Validation set: Average loss: 0.8779, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 161 [0/2335 (0%)]\tLoss: 0.406052\n",
      "Validation set: Average loss: 0.8539, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 162 [0/2335 (0%)]\tLoss: 0.391870\n",
      "Validation set: Average loss: 1.0855, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 163 [0/2335 (0%)]\tLoss: 0.392024\n",
      "Validation set: Average loss: 0.7168, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 164 [0/2335 (0%)]\tLoss: 0.390894\n",
      "Validation set: Average loss: 1.1217, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 165 [0/2335 (0%)]\tLoss: 0.390801\n",
      "Validation set: Average loss: 0.7849, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 166 [0/2335 (0%)]\tLoss: 0.391420\n",
      "Validation set: Average loss: 1.4559, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 167 [0/2335 (0%)]\tLoss: 0.390507\n",
      "Validation set: Average loss: 1.0524, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 168 [0/2335 (0%)]\tLoss: 0.390614\n",
      "Validation set: Average loss: 2.2159, Accuracy: 32/107 (0.30%)\n",
      "Train Epoch: 169 [0/2335 (0%)]\tLoss: 0.391215\n",
      "Validation set: Average loss: 1.3541, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 170 [0/2335 (0%)]\tLoss: 0.391074\n",
      "Validation set: Average loss: 1.1968, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 171 [0/2335 (0%)]\tLoss: 0.390555\n",
      "Validation set: Average loss: 1.2860, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 172 [0/2335 (0%)]\tLoss: 0.390751\n",
      "Validation set: Average loss: 0.9885, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 173 [0/2335 (0%)]\tLoss: 0.390829\n",
      "Validation set: Average loss: 1.4833, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 174 [0/2335 (0%)]\tLoss: 0.391104\n",
      "Validation set: Average loss: 1.1729, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 175 [0/2335 (0%)]\tLoss: 0.391152\n",
      "Validation set: Average loss: 0.8867, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 176 [0/2335 (0%)]\tLoss: 0.390967\n",
      "Validation set: Average loss: 1.5465, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 177 [0/2335 (0%)]\tLoss: 0.391036\n",
      "Validation set: Average loss: 1.0376, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 178 [0/2335 (0%)]\tLoss: 0.391004\n",
      "Validation set: Average loss: 0.8070, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 179 [0/2335 (0%)]\tLoss: 0.390543\n",
      "Validation set: Average loss: 1.6504, Accuracy: 62/107 (0.58%)\n",
      "Train Epoch: 180 [0/2335 (0%)]\tLoss: 0.399065\n",
      "Validation set: Average loss: 0.8442, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 181 [0/2335 (0%)]\tLoss: 0.390989\n",
      "Validation set: Average loss: 1.4269, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 182 [0/2335 (0%)]\tLoss: 0.394765\n",
      "Validation set: Average loss: 1.4998, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 183 [0/2335 (0%)]\tLoss: 0.393221\n",
      "Validation set: Average loss: 0.8668, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 184 [0/2335 (0%)]\tLoss: 0.391245\n",
      "Validation set: Average loss: 0.7611, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 185 [0/2335 (0%)]\tLoss: 0.390934\n",
      "Validation set: Average loss: 0.9610, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 186 [0/2335 (0%)]\tLoss: 0.391304\n",
      "Validation set: Average loss: 0.9030, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 187 [0/2335 (0%)]\tLoss: 0.391191\n",
      "Validation set: Average loss: 0.8733, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 188 [0/2335 (0%)]\tLoss: 0.391025\n",
      "Validation set: Average loss: 0.9556, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 189 [0/2335 (0%)]\tLoss: 0.390814\n",
      "Validation set: Average loss: 0.9686, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 190 [0/2335 (0%)]\tLoss: 0.391228\n",
      "Validation set: Average loss: 0.7268, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 191 [0/2335 (0%)]\tLoss: 0.391306\n",
      "Validation set: Average loss: 0.6684, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 192 [0/2335 (0%)]\tLoss: 0.391284\n",
      "Validation set: Average loss: 0.8707, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 193 [0/2335 (0%)]\tLoss: 0.390912\n",
      "Validation set: Average loss: 0.8846, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 194 [0/2335 (0%)]\tLoss: 0.391082\n",
      "Validation set: Average loss: 0.7187, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 195 [0/2335 (0%)]\tLoss: 0.391239\n",
      "Validation set: Average loss: 0.9866, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 196 [0/2335 (0%)]\tLoss: 0.391105\n",
      "Validation set: Average loss: 0.7978, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 197 [0/2335 (0%)]\tLoss: 0.390660\n",
      "Validation set: Average loss: 0.7618, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 198 [0/2335 (0%)]\tLoss: 0.390704\n",
      "Validation set: Average loss: 1.0811, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 199 [0/2335 (0%)]\tLoss: 0.390550\n",
      "Validation set: Average loss: 1.0073, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 200 [0/2335 (0%)]\tLoss: 0.390664\n",
      "Validation set: Average loss: 0.6965, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 201 [0/2335 (0%)]\tLoss: 0.390596\n",
      "Validation set: Average loss: 0.7279, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 202 [0/2335 (0%)]\tLoss: 0.390611\n",
      "Validation set: Average loss: 0.8595, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 203 [0/2335 (0%)]\tLoss: 0.390870\n",
      "Validation set: Average loss: 0.8377, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 204 [0/2335 (0%)]\tLoss: 0.390838\n",
      "Validation set: Average loss: 0.7411, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 205 [0/2335 (0%)]\tLoss: 0.390793\n",
      "Validation set: Average loss: 0.7821, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 206 [0/2335 (0%)]\tLoss: 0.390463\n",
      "Validation set: Average loss: 0.7879, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 207 [0/2335 (0%)]\tLoss: 0.390793\n",
      "Validation set: Average loss: 0.6850, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 208 [0/2335 (0%)]\tLoss: 0.391135\n",
      "Validation set: Average loss: 0.8361, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 209 [0/2335 (0%)]\tLoss: 0.391910\n",
      "Validation set: Average loss: 0.7989, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 210 [0/2335 (0%)]\tLoss: 0.390775\n",
      "Validation set: Average loss: 0.7809, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 211 [0/2335 (0%)]\tLoss: 0.390873\n",
      "Validation set: Average loss: 0.7005, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 212 [0/2335 (0%)]\tLoss: 0.390616\n",
      "Validation set: Average loss: 0.9182, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 213 [0/2335 (0%)]\tLoss: 0.390970\n",
      "Validation set: Average loss: 0.7832, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 214 [0/2335 (0%)]\tLoss: 0.391077\n",
      "Validation set: Average loss: 0.8545, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 215 [0/2335 (0%)]\tLoss: 0.390841\n",
      "Validation set: Average loss: 0.6875, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 216 [0/2335 (0%)]\tLoss: 0.403085\n",
      "Validation set: Average loss: 0.8098, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 217 [0/2335 (0%)]\tLoss: 0.391787\n",
      "Validation set: Average loss: 0.7125, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 218 [0/2335 (0%)]\tLoss: 0.391040\n",
      "Validation set: Average loss: 0.9482, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 219 [0/2335 (0%)]\tLoss: 0.390606\n",
      "Validation set: Average loss: 0.7535, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 220 [0/2335 (0%)]\tLoss: 0.390915\n",
      "Validation set: Average loss: 0.7540, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 221 [0/2335 (0%)]\tLoss: 0.390509\n",
      "Validation set: Average loss: 0.8348, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 222 [0/2335 (0%)]\tLoss: 0.390869\n",
      "Validation set: Average loss: 0.6851, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 223 [0/2335 (0%)]\tLoss: 0.391018\n",
      "Validation set: Average loss: 0.7638, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 224 [0/2335 (0%)]\tLoss: 0.390833\n",
      "Validation set: Average loss: 1.0564, Accuracy: 68/107 (0.64%)\n",
      "Train Epoch: 225 [0/2335 (0%)]\tLoss: 0.390867\n",
      "Validation set: Average loss: 1.0441, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 226 [0/2335 (0%)]\tLoss: 0.390925\n",
      "Validation set: Average loss: 0.8421, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 227 [0/2335 (0%)]\tLoss: 0.390787\n",
      "Validation set: Average loss: 1.0429, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 228 [0/2335 (0%)]\tLoss: 0.390689\n",
      "Validation set: Average loss: 0.8126, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 229 [0/2335 (0%)]\tLoss: 0.390336\n",
      "Validation set: Average loss: 0.9481, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 230 [0/2335 (0%)]\tLoss: 0.390745\n",
      "Validation set: Average loss: 0.6906, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 231 [0/2335 (0%)]\tLoss: 0.391017\n",
      "Validation set: Average loss: 0.9024, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 232 [0/2335 (0%)]\tLoss: 0.390624\n",
      "Validation set: Average loss: 0.7809, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 233 [0/2335 (0%)]\tLoss: 0.390648\n",
      "Validation set: Average loss: 1.0996, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 234 [0/2335 (0%)]\tLoss: 0.390604\n",
      "Validation set: Average loss: 0.8583, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 235 [0/2335 (0%)]\tLoss: 0.390958\n",
      "Validation set: Average loss: 0.7627, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 236 [0/2335 (0%)]\tLoss: 0.390792\n",
      "Validation set: Average loss: 1.0889, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 237 [0/2335 (0%)]\tLoss: 0.391089\n",
      "Validation set: Average loss: 0.9897, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 238 [0/2335 (0%)]\tLoss: 0.390363\n",
      "Validation set: Average loss: 1.0012, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 239 [0/2335 (0%)]\tLoss: 0.390510\n",
      "Validation set: Average loss: 0.7504, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 240 [0/2335 (0%)]\tLoss: 0.390498\n",
      "Validation set: Average loss: 1.0129, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 241 [0/2335 (0%)]\tLoss: 0.390703\n",
      "Validation set: Average loss: 0.8456, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 242 [0/2335 (0%)]\tLoss: 0.390613\n",
      "Validation set: Average loss: 0.9119, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 243 [0/2335 (0%)]\tLoss: 0.390879\n",
      "Validation set: Average loss: 0.9144, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 244 [0/2335 (0%)]\tLoss: 0.390542\n",
      "Validation set: Average loss: 0.7021, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 245 [0/2335 (0%)]\tLoss: 0.391185\n",
      "Validation set: Average loss: 0.9820, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 246 [0/2335 (0%)]\tLoss: 0.391197\n",
      "Validation set: Average loss: 0.8049, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 247 [0/2335 (0%)]\tLoss: 0.390491\n",
      "Validation set: Average loss: 1.0579, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 248 [0/2335 (0%)]\tLoss: 0.390695\n",
      "Validation set: Average loss: 0.9851, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 249 [0/2335 (0%)]\tLoss: 0.390894\n",
      "Validation set: Average loss: 1.0859, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 250 [0/2335 (0%)]\tLoss: 0.390777\n",
      "Validation set: Average loss: 1.0147, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 251 [0/2335 (0%)]\tLoss: 0.390459\n",
      "Validation set: Average loss: 0.8175, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 252 [0/2335 (0%)]\tLoss: 0.390866\n",
      "Validation set: Average loss: 0.7950, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 253 [0/2335 (0%)]\tLoss: 0.390754\n",
      "Validation set: Average loss: 0.9668, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 254 [0/2335 (0%)]\tLoss: 0.390770\n",
      "Validation set: Average loss: 0.7531, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 255 [0/2335 (0%)]\tLoss: 0.390821\n",
      "Validation set: Average loss: 0.8225, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 256 [0/2335 (0%)]\tLoss: 0.390523\n",
      "Validation set: Average loss: 0.8619, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 257 [0/2335 (0%)]\tLoss: 0.390686\n",
      "Validation set: Average loss: 0.7285, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 258 [0/2335 (0%)]\tLoss: 0.390777\n",
      "Validation set: Average loss: 1.2068, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 259 [0/2335 (0%)]\tLoss: 0.390795\n",
      "Validation set: Average loss: 1.3625, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 260 [0/2335 (0%)]\tLoss: 0.390624\n",
      "Validation set: Average loss: 1.5006, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 261 [0/2335 (0%)]\tLoss: 0.390492\n",
      "Validation set: Average loss: 1.0232, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 262 [0/2335 (0%)]\tLoss: 0.390285\n",
      "Validation set: Average loss: 0.8361, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 263 [0/2335 (0%)]\tLoss: 0.390370\n",
      "Validation set: Average loss: 1.4665, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 264 [0/2335 (0%)]\tLoss: 0.390600\n",
      "Validation set: Average loss: 0.7088, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 265 [0/2335 (0%)]\tLoss: 0.390945\n",
      "Validation set: Average loss: 1.1491, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 266 [0/2335 (0%)]\tLoss: 0.390803\n",
      "Validation set: Average loss: 1.2406, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 267 [0/2335 (0%)]\tLoss: 0.390411\n",
      "Validation set: Average loss: 0.7235, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 268 [0/2335 (0%)]\tLoss: 0.390879\n",
      "Validation set: Average loss: 0.8797, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 269 [0/2335 (0%)]\tLoss: 0.390734\n",
      "Validation set: Average loss: 0.7907, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 270 [0/2335 (0%)]\tLoss: 0.390802\n",
      "Validation set: Average loss: 0.7161, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 271 [0/2335 (0%)]\tLoss: 0.390422\n",
      "Validation set: Average loss: 1.0236, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 272 [0/2335 (0%)]\tLoss: 0.390682\n",
      "Validation set: Average loss: 0.7125, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 273 [0/2335 (0%)]\tLoss: 0.390698\n",
      "Validation set: Average loss: 1.3338, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 274 [0/2335 (0%)]\tLoss: 0.390384\n",
      "Validation set: Average loss: 0.7157, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 275 [0/2335 (0%)]\tLoss: 0.390632\n",
      "Validation set: Average loss: 1.5201, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 276 [0/2335 (0%)]\tLoss: 0.390526\n",
      "Validation set: Average loss: 1.6038, Accuracy: 55/107 (0.51%)\n",
      "Train Epoch: 277 [0/2335 (0%)]\tLoss: 0.390780\n",
      "Validation set: Average loss: 1.1367, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 278 [0/2335 (0%)]\tLoss: 0.390796\n",
      "Validation set: Average loss: 1.5405, Accuracy: 54/107 (0.50%)\n",
      "Train Epoch: 279 [0/2335 (0%)]\tLoss: 0.390768\n",
      "Validation set: Average loss: 1.1445, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 280 [0/2335 (0%)]\tLoss: 0.390628\n",
      "Validation set: Average loss: 0.7115, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 281 [0/2335 (0%)]\tLoss: 0.390805\n",
      "Validation set: Average loss: 1.7086, Accuracy: 52/107 (0.49%)\n",
      "Train Epoch: 282 [0/2335 (0%)]\tLoss: 0.390449\n",
      "Validation set: Average loss: 1.7382, Accuracy: 52/107 (0.49%)\n",
      "Train Epoch: 283 [0/2335 (0%)]\tLoss: 0.390554\n",
      "Validation set: Average loss: 1.7655, Accuracy: 49/107 (0.46%)\n",
      "Train Epoch: 284 [0/2335 (0%)]\tLoss: 0.390694\n",
      "Validation set: Average loss: 1.2646, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 285 [0/2335 (0%)]\tLoss: 0.390751\n",
      "Validation set: Average loss: 0.8541, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 286 [0/2335 (0%)]\tLoss: 0.390418\n",
      "Validation set: Average loss: 1.4893, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 287 [0/2335 (0%)]\tLoss: 0.390762\n",
      "Validation set: Average loss: 1.3498, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 288 [0/2335 (0%)]\tLoss: 0.390866\n",
      "Validation set: Average loss: 1.6299, Accuracy: 54/107 (0.50%)\n",
      "Train Epoch: 289 [0/2335 (0%)]\tLoss: 0.390818\n",
      "Validation set: Average loss: 1.1801, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 290 [0/2335 (0%)]\tLoss: 0.390636\n",
      "Validation set: Average loss: 0.7494, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 291 [0/2335 (0%)]\tLoss: 0.390478\n",
      "Validation set: Average loss: 0.7698, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 292 [0/2335 (0%)]\tLoss: 0.390567\n",
      "Validation set: Average loss: 1.0843, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 293 [0/2335 (0%)]\tLoss: 0.390796\n",
      "Validation set: Average loss: 1.3367, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 294 [0/2335 (0%)]\tLoss: 0.390632\n",
      "Validation set: Average loss: 1.4111, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 295 [0/2335 (0%)]\tLoss: 0.390491\n",
      "Validation set: Average loss: 0.7238, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 296 [0/2335 (0%)]\tLoss: 0.390754\n",
      "Validation set: Average loss: 1.8004, Accuracy: 48/107 (0.45%)\n",
      "Train Epoch: 297 [0/2335 (0%)]\tLoss: 0.390388\n",
      "Validation set: Average loss: 0.7090, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 298 [0/2335 (0%)]\tLoss: 0.390455\n",
      "Validation set: Average loss: 1.2596, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 299 [0/2335 (0%)]\tLoss: 0.390448\n",
      "Validation set: Average loss: 1.3954, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 300 [0/2335 (0%)]\tLoss: 0.390307\n",
      "Validation set: Average loss: 1.1549, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 301 [0/2335 (0%)]\tLoss: 0.390331\n",
      "Validation set: Average loss: 1.7242, Accuracy: 51/107 (0.48%)\n",
      "Train Epoch: 302 [0/2335 (0%)]\tLoss: 0.391033\n",
      "Validation set: Average loss: 1.2771, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 303 [0/2335 (0%)]\tLoss: 0.390739\n",
      "Validation set: Average loss: 1.2978, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 304 [0/2335 (0%)]\tLoss: 0.390843\n",
      "Validation set: Average loss: 1.5843, Accuracy: 55/107 (0.51%)\n",
      "Train Epoch: 305 [0/2335 (0%)]\tLoss: 0.390403\n",
      "Validation set: Average loss: 0.9870, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 306 [0/2335 (0%)]\tLoss: 0.390631\n",
      "Validation set: Average loss: 1.4079, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 307 [0/2335 (0%)]\tLoss: 0.390669\n",
      "Validation set: Average loss: 1.7601, Accuracy: 50/107 (0.47%)\n",
      "Train Epoch: 308 [0/2335 (0%)]\tLoss: 0.390502\n",
      "Validation set: Average loss: 0.7385, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 309 [0/2335 (0%)]\tLoss: 0.391092\n",
      "Validation set: Average loss: 2.0056, Accuracy: 46/107 (0.43%)\n",
      "Train Epoch: 310 [0/2335 (0%)]\tLoss: 0.390545\n",
      "Validation set: Average loss: 0.7175, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 311 [0/2335 (0%)]\tLoss: 0.390630\n",
      "Validation set: Average loss: 0.9220, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 312 [0/2335 (0%)]\tLoss: 0.391103\n",
      "Validation set: Average loss: 2.1902, Accuracy: 33/107 (0.31%)\n",
      "Train Epoch: 313 [0/2335 (0%)]\tLoss: 0.393107\n",
      "Validation set: Average loss: 2.2737, Accuracy: 21/107 (0.20%)\n",
      "Train Epoch: 314 [0/2335 (0%)]\tLoss: 0.393754\n",
      "Validation set: Average loss: 1.2446, Accuracy: 55/107 (0.51%)\n",
      "Train Epoch: 315 [0/2335 (0%)]\tLoss: 0.396219\n",
      "Validation set: Average loss: 0.7981, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 316 [0/2335 (0%)]\tLoss: 0.395147\n",
      "Validation set: Average loss: 0.8599, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 317 [0/2335 (0%)]\tLoss: 0.392867\n",
      "Validation set: Average loss: 0.9943, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 318 [0/2335 (0%)]\tLoss: 0.403326\n",
      "Validation set: Average loss: 0.6730, Accuracy: 97/107 (0.91%)\n",
      "Train Epoch: 319 [0/2335 (0%)]\tLoss: 0.391253\n",
      "Validation set: Average loss: 0.8250, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 320 [0/2335 (0%)]\tLoss: 0.390794\n",
      "Validation set: Average loss: 0.8483, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 321 [0/2335 (0%)]\tLoss: 0.390822\n",
      "Validation set: Average loss: 0.7048, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 322 [0/2335 (0%)]\tLoss: 0.391229\n",
      "Validation set: Average loss: 0.9847, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 323 [0/2335 (0%)]\tLoss: 0.391093\n",
      "Validation set: Average loss: 0.9893, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 324 [0/2335 (0%)]\tLoss: 0.391805\n",
      "Validation set: Average loss: 0.9689, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 325 [0/2335 (0%)]\tLoss: 0.390894\n",
      "Validation set: Average loss: 0.9522, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 326 [0/2335 (0%)]\tLoss: 0.391650\n",
      "Validation set: Average loss: 0.7647, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 327 [0/2335 (0%)]\tLoss: 0.390935\n",
      "Validation set: Average loss: 0.8071, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 328 [0/2335 (0%)]\tLoss: 0.390928\n",
      "Validation set: Average loss: 0.7893, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 329 [0/2335 (0%)]\tLoss: 0.390692\n",
      "Validation set: Average loss: 0.7007, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 330 [0/2335 (0%)]\tLoss: 0.390907\n",
      "Validation set: Average loss: 0.9292, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 331 [0/2335 (0%)]\tLoss: 0.390394\n",
      "Validation set: Average loss: 1.0955, Accuracy: 68/107 (0.64%)\n",
      "Train Epoch: 332 [0/2335 (0%)]\tLoss: 0.390892\n",
      "Validation set: Average loss: 1.0316, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 333 [0/2335 (0%)]\tLoss: 0.391336\n",
      "Validation set: Average loss: 0.8307, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 334 [0/2335 (0%)]\tLoss: 0.390595\n",
      "Validation set: Average loss: 0.7042, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 335 [0/2335 (0%)]\tLoss: 0.390594\n",
      "Validation set: Average loss: 0.7594, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 336 [0/2335 (0%)]\tLoss: 0.390796\n",
      "Validation set: Average loss: 0.7828, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 337 [0/2335 (0%)]\tLoss: 0.391009\n",
      "Validation set: Average loss: 0.7491, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 338 [0/2335 (0%)]\tLoss: 0.390456\n",
      "Validation set: Average loss: 0.7333, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 339 [0/2335 (0%)]\tLoss: 0.390769\n",
      "Validation set: Average loss: 0.7787, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 340 [0/2335 (0%)]\tLoss: 0.390850\n",
      "Validation set: Average loss: 0.9025, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 341 [0/2335 (0%)]\tLoss: 0.390618\n",
      "Validation set: Average loss: 0.7872, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 342 [0/2335 (0%)]\tLoss: 0.390492\n",
      "Validation set: Average loss: 0.8561, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 343 [0/2335 (0%)]\tLoss: 0.390635\n",
      "Validation set: Average loss: 0.9403, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 344 [0/2335 (0%)]\tLoss: 0.390966\n",
      "Validation set: Average loss: 0.7196, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 345 [0/2335 (0%)]\tLoss: 0.390646\n",
      "Validation set: Average loss: 0.8948, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 346 [0/2335 (0%)]\tLoss: 0.390667\n",
      "Validation set: Average loss: 0.7573, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 347 [0/2335 (0%)]\tLoss: 0.390897\n",
      "Validation set: Average loss: 0.7645, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 348 [0/2335 (0%)]\tLoss: 0.390999\n",
      "Validation set: Average loss: 0.7347, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 349 [0/2335 (0%)]\tLoss: 0.391083\n",
      "Validation set: Average loss: 0.7857, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 350 [0/2335 (0%)]\tLoss: 0.391035\n",
      "Validation set: Average loss: 0.8415, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 351 [0/2335 (0%)]\tLoss: 0.390726\n",
      "Validation set: Average loss: 0.7906, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 352 [0/2335 (0%)]\tLoss: 0.391900\n",
      "Validation set: Average loss: 0.7108, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 353 [0/2335 (0%)]\tLoss: 0.391637\n",
      "Validation set: Average loss: 0.9392, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 354 [0/2335 (0%)]\tLoss: 0.391376\n",
      "Validation set: Average loss: 0.9239, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 355 [0/2335 (0%)]\tLoss: 0.391714\n",
      "Validation set: Average loss: 0.7379, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 356 [0/2335 (0%)]\tLoss: 0.391775\n",
      "Validation set: Average loss: 1.6365, Accuracy: 35/107 (0.33%)\n",
      "Train Epoch: 357 [0/2335 (0%)]\tLoss: 0.391122\n",
      "Validation set: Average loss: 0.8136, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 358 [0/2335 (0%)]\tLoss: 0.390763\n",
      "Validation set: Average loss: 1.0574, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 359 [0/2335 (0%)]\tLoss: 0.391150\n",
      "Validation set: Average loss: 0.9215, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 360 [0/2335 (0%)]\tLoss: 0.390616\n",
      "Validation set: Average loss: 1.4385, Accuracy: 26/107 (0.24%)\n",
      "Train Epoch: 361 [0/2335 (0%)]\tLoss: 0.390974\n",
      "Validation set: Average loss: 0.8301, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 362 [0/2335 (0%)]\tLoss: 0.391890\n",
      "Validation set: Average loss: 1.1781, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 363 [0/2335 (0%)]\tLoss: 0.390865\n",
      "Validation set: Average loss: 0.7184, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 364 [0/2335 (0%)]\tLoss: 0.391284\n",
      "Validation set: Average loss: 0.7824, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 365 [0/2335 (0%)]\tLoss: 0.390911\n",
      "Validation set: Average loss: 0.7668, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 366 [0/2335 (0%)]\tLoss: 0.391049\n",
      "Validation set: Average loss: 0.7548, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 367 [0/2335 (0%)]\tLoss: 0.392028\n",
      "Validation set: Average loss: 0.7142, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 368 [0/2335 (0%)]\tLoss: 0.390925\n",
      "Validation set: Average loss: 0.7345, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 369 [0/2335 (0%)]\tLoss: 0.391369\n",
      "Validation set: Average loss: 0.7872, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 370 [0/2335 (0%)]\tLoss: 0.392409\n",
      "Validation set: Average loss: 1.1806, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 371 [0/2335 (0%)]\tLoss: 0.391005\n",
      "Validation set: Average loss: 0.7923, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 372 [0/2335 (0%)]\tLoss: 0.390596\n",
      "Validation set: Average loss: 1.0283, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 373 [0/2335 (0%)]\tLoss: 0.390943\n",
      "Validation set: Average loss: 1.3400, Accuracy: 65/107 (0.61%)\n",
      "Train Epoch: 374 [0/2335 (0%)]\tLoss: 0.390424\n",
      "Validation set: Average loss: 1.3095, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 375 [0/2335 (0%)]\tLoss: 0.390956\n",
      "Validation set: Average loss: 1.3988, Accuracy: 65/107 (0.61%)\n",
      "Train Epoch: 376 [0/2335 (0%)]\tLoss: 0.390558\n",
      "Validation set: Average loss: 0.9271, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 377 [0/2335 (0%)]\tLoss: 0.390377\n",
      "Validation set: Average loss: 1.2572, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 378 [0/2335 (0%)]\tLoss: 0.393680\n",
      "Validation set: Average loss: 0.7151, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 379 [0/2335 (0%)]\tLoss: 0.390518\n",
      "Validation set: Average loss: 0.9882, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 380 [0/2335 (0%)]\tLoss: 0.390772\n",
      "Validation set: Average loss: 1.1009, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 381 [0/2335 (0%)]\tLoss: 0.396189\n",
      "Validation set: Average loss: 0.8081, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 382 [0/2335 (0%)]\tLoss: 0.393805\n",
      "Validation set: Average loss: 1.0706, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 383 [0/2335 (0%)]\tLoss: 0.390851\n",
      "Validation set: Average loss: 1.3486, Accuracy: 54/107 (0.50%)\n",
      "Train Epoch: 384 [0/2335 (0%)]\tLoss: 0.391329\n",
      "Validation set: Average loss: 0.9091, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 385 [0/2335 (0%)]\tLoss: 0.392587\n",
      "Validation set: Average loss: 1.2036, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 386 [0/2335 (0%)]\tLoss: 0.390686\n",
      "Validation set: Average loss: 1.1794, Accuracy: 68/107 (0.64%)\n",
      "Train Epoch: 387 [0/2335 (0%)]\tLoss: 0.390651\n",
      "Validation set: Average loss: 1.0086, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 388 [0/2335 (0%)]\tLoss: 0.390933\n",
      "Validation set: Average loss: 0.9530, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 389 [0/2335 (0%)]\tLoss: 0.390536\n",
      "Validation set: Average loss: 1.1495, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 390 [0/2335 (0%)]\tLoss: 0.391329\n",
      "Validation set: Average loss: 0.8468, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 391 [0/2335 (0%)]\tLoss: 0.390641\n",
      "Validation set: Average loss: 0.8278, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 392 [0/2335 (0%)]\tLoss: 0.390679\n",
      "Validation set: Average loss: 0.7100, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 393 [0/2335 (0%)]\tLoss: 0.390743\n",
      "Validation set: Average loss: 0.9399, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 394 [0/2335 (0%)]\tLoss: 0.390651\n",
      "Validation set: Average loss: 0.6941, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 395 [0/2335 (0%)]\tLoss: 0.391222\n",
      "Validation set: Average loss: 0.7317, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 396 [0/2335 (0%)]\tLoss: 0.390854\n",
      "Validation set: Average loss: 0.6890, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 397 [0/2335 (0%)]\tLoss: 0.390978\n",
      "Validation set: Average loss: 0.7580, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 398 [0/2335 (0%)]\tLoss: 0.391498\n",
      "Validation set: Average loss: 0.6804, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 399 [0/2335 (0%)]\tLoss: 0.391010\n",
      "Validation set: Average loss: 0.7684, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 400 [0/2335 (0%)]\tLoss: 0.390777\n",
      "Validation set: Average loss: 0.8146, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 401 [0/2335 (0%)]\tLoss: 0.390824\n",
      "Validation set: Average loss: 0.8643, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 402 [0/2335 (0%)]\tLoss: 0.391009\n",
      "Validation set: Average loss: 0.7146, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 403 [0/2335 (0%)]\tLoss: 0.390908\n",
      "Validation set: Average loss: 0.6746, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 404 [0/2335 (0%)]\tLoss: 0.390953\n",
      "Validation set: Average loss: 0.6680, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 405 [0/2335 (0%)]\tLoss: 0.391064\n",
      "Validation set: Average loss: 0.8726, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 406 [0/2335 (0%)]\tLoss: 0.390931\n",
      "Validation set: Average loss: 0.7108, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 407 [0/2335 (0%)]\tLoss: 0.390720\n",
      "Validation set: Average loss: 0.6864, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 408 [0/2335 (0%)]\tLoss: 0.390869\n",
      "Validation set: Average loss: 0.9292, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 409 [0/2335 (0%)]\tLoss: 0.390444\n",
      "Validation set: Average loss: 1.1907, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 410 [0/2335 (0%)]\tLoss: 0.390929\n",
      "Validation set: Average loss: 0.8665, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 411 [0/2335 (0%)]\tLoss: 0.391069\n",
      "Validation set: Average loss: 0.7082, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 412 [0/2335 (0%)]\tLoss: 0.390695\n",
      "Validation set: Average loss: 0.9169, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 413 [0/2335 (0%)]\tLoss: 0.390588\n",
      "Validation set: Average loss: 0.8780, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 414 [0/2335 (0%)]\tLoss: 0.390869\n",
      "Validation set: Average loss: 1.2297, Accuracy: 65/107 (0.61%)\n",
      "Train Epoch: 415 [0/2335 (0%)]\tLoss: 0.390408\n",
      "Validation set: Average loss: 0.7031, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 416 [0/2335 (0%)]\tLoss: 0.390898\n",
      "Validation set: Average loss: 1.5320, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 417 [0/2335 (0%)]\tLoss: 0.390734\n",
      "Validation set: Average loss: 1.5918, Accuracy: 62/107 (0.58%)\n",
      "Train Epoch: 418 [0/2335 (0%)]\tLoss: 0.390599\n",
      "Validation set: Average loss: 1.2522, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 419 [0/2335 (0%)]\tLoss: 0.390499\n",
      "Validation set: Average loss: 1.7329, Accuracy: 55/107 (0.51%)\n",
      "Train Epoch: 420 [0/2335 (0%)]\tLoss: 0.390935\n",
      "Validation set: Average loss: 1.4773, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 421 [0/2335 (0%)]\tLoss: 0.391026\n",
      "Validation set: Average loss: 0.7149, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 422 [0/2335 (0%)]\tLoss: 0.390799\n",
      "Validation set: Average loss: 0.9869, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 423 [0/2335 (0%)]\tLoss: 0.390589\n",
      "Validation set: Average loss: 1.0503, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 424 [0/2335 (0%)]\tLoss: 0.390665\n",
      "Validation set: Average loss: 0.7132, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 425 [0/2335 (0%)]\tLoss: 0.390714\n",
      "Validation set: Average loss: 1.6826, Accuracy: 56/107 (0.52%)\n",
      "Train Epoch: 426 [0/2335 (0%)]\tLoss: 0.390710\n",
      "Validation set: Average loss: 1.4730, Accuracy: 65/107 (0.61%)\n",
      "Train Epoch: 427 [0/2335 (0%)]\tLoss: 0.390899\n",
      "Validation set: Average loss: 2.2935, Accuracy: 40/107 (0.37%)\n",
      "Train Epoch: 428 [0/2335 (0%)]\tLoss: 0.390714\n",
      "Validation set: Average loss: 0.6690, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 429 [0/2335 (0%)]\tLoss: 0.390981\n",
      "Validation set: Average loss: 0.7064, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 430 [0/2335 (0%)]\tLoss: 0.391029\n",
      "Validation set: Average loss: 1.0740, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 431 [0/2335 (0%)]\tLoss: 0.390657\n",
      "Validation set: Average loss: 1.6000, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 432 [0/2335 (0%)]\tLoss: 0.391052\n",
      "Validation set: Average loss: 0.6875, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 433 [0/2335 (0%)]\tLoss: 0.390520\n",
      "Validation set: Average loss: 0.8050, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 434 [0/2335 (0%)]\tLoss: 0.390698\n",
      "Validation set: Average loss: 0.6917, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 435 [0/2335 (0%)]\tLoss: 0.390799\n",
      "Validation set: Average loss: 0.7897, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 436 [0/2335 (0%)]\tLoss: 0.390452\n",
      "Validation set: Average loss: 1.1646, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 437 [0/2335 (0%)]\tLoss: 0.390340\n",
      "Validation set: Average loss: 0.7359, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 438 [0/2335 (0%)]\tLoss: 0.391106\n",
      "Validation set: Average loss: 0.7935, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 439 [0/2335 (0%)]\tLoss: 0.390986\n",
      "Validation set: Average loss: 0.8530, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 440 [0/2335 (0%)]\tLoss: 0.390749\n",
      "Validation set: Average loss: 0.7196, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 441 [0/2335 (0%)]\tLoss: 0.390664\n",
      "Validation set: Average loss: 0.6661, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 442 [0/2335 (0%)]\tLoss: 0.390862\n",
      "Validation set: Average loss: 0.7048, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 443 [0/2335 (0%)]\tLoss: 0.390470\n",
      "Validation set: Average loss: 0.7467, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 444 [0/2335 (0%)]\tLoss: 0.390945\n",
      "Validation set: Average loss: 0.6841, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 445 [0/2335 (0%)]\tLoss: 0.390351\n",
      "Validation set: Average loss: 0.7397, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 446 [0/2335 (0%)]\tLoss: 0.390861\n",
      "Validation set: Average loss: 0.8324, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 447 [0/2335 (0%)]\tLoss: 0.390528\n",
      "Validation set: Average loss: 0.7487, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 448 [0/2335 (0%)]\tLoss: 0.390871\n",
      "Validation set: Average loss: 0.7338, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 449 [0/2335 (0%)]\tLoss: 0.390766\n",
      "Validation set: Average loss: 0.8824, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 450 [0/2335 (0%)]\tLoss: 0.390504\n",
      "Validation set: Average loss: 0.7315, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 451 [0/2335 (0%)]\tLoss: 0.391549\n",
      "Validation set: Average loss: 1.0342, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 452 [0/2335 (0%)]\tLoss: 0.391213\n",
      "Validation set: Average loss: 0.6717, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 453 [0/2335 (0%)]\tLoss: 0.391070\n",
      "Validation set: Average loss: 0.6803, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 454 [0/2335 (0%)]\tLoss: 0.390512\n",
      "Validation set: Average loss: 0.6929, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 455 [0/2335 (0%)]\tLoss: 0.390731\n",
      "Validation set: Average loss: 0.6829, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 456 [0/2335 (0%)]\tLoss: 0.390544\n",
      "Validation set: Average loss: 0.7548, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 457 [0/2335 (0%)]\tLoss: 0.390719\n",
      "Validation set: Average loss: 0.6784, Accuracy: 97/107 (0.91%)\n",
      "Train Epoch: 458 [0/2335 (0%)]\tLoss: 0.390610\n",
      "Validation set: Average loss: 0.6702, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 459 [0/2335 (0%)]\tLoss: 0.390469\n",
      "Validation set: Average loss: 0.6789, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 460 [0/2335 (0%)]\tLoss: 0.390683\n",
      "Validation set: Average loss: 0.7284, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 461 [0/2335 (0%)]\tLoss: 0.390825\n",
      "Validation set: Average loss: 0.9253, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 462 [0/2335 (0%)]\tLoss: 0.390858\n",
      "Validation set: Average loss: 0.6874, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 463 [0/2335 (0%)]\tLoss: 0.390699\n",
      "Validation set: Average loss: 0.6875, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 464 [0/2335 (0%)]\tLoss: 0.390931\n",
      "Validation set: Average loss: 0.7222, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 465 [0/2335 (0%)]\tLoss: 0.391184\n",
      "Validation set: Average loss: 0.6590, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 466 [0/2335 (0%)]\tLoss: 0.390426\n",
      "Validation set: Average loss: 0.9526, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 467 [0/2335 (0%)]\tLoss: 0.390305\n",
      "Validation set: Average loss: 0.6782, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 468 [0/2335 (0%)]\tLoss: 0.390934\n",
      "Validation set: Average loss: 0.6730, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 469 [0/2335 (0%)]\tLoss: 0.390751\n",
      "Validation set: Average loss: 0.9592, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 470 [0/2335 (0%)]\tLoss: 0.390616\n",
      "Validation set: Average loss: 0.6903, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 471 [0/2335 (0%)]\tLoss: 0.390685\n",
      "Validation set: Average loss: 0.7632, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 472 [0/2335 (0%)]\tLoss: 0.390621\n",
      "Validation set: Average loss: 0.7565, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 473 [0/2335 (0%)]\tLoss: 0.390671\n",
      "Validation set: Average loss: 0.7659, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 474 [0/2335 (0%)]\tLoss: 0.391010\n",
      "Validation set: Average loss: 0.6802, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 475 [0/2335 (0%)]\tLoss: 0.390447\n",
      "Validation set: Average loss: 0.9602, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 476 [0/2335 (0%)]\tLoss: 0.390398\n",
      "Validation set: Average loss: 0.9525, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 477 [0/2335 (0%)]\tLoss: 0.390615\n",
      "Validation set: Average loss: 1.1727, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 478 [0/2335 (0%)]\tLoss: 0.390551\n",
      "Validation set: Average loss: 0.9318, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 479 [0/2335 (0%)]\tLoss: 0.390696\n",
      "Validation set: Average loss: 0.9921, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 480 [0/2335 (0%)]\tLoss: 0.390835\n",
      "Validation set: Average loss: 1.5464, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 481 [0/2335 (0%)]\tLoss: 0.390731\n",
      "Validation set: Average loss: 1.2911, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 482 [0/2335 (0%)]\tLoss: 0.390478\n",
      "Validation set: Average loss: 0.6818, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 483 [0/2335 (0%)]\tLoss: 0.390822\n",
      "Validation set: Average loss: 0.6904, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 484 [0/2335 (0%)]\tLoss: 0.391011\n",
      "Validation set: Average loss: 1.1544, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 485 [0/2335 (0%)]\tLoss: 0.390570\n",
      "Validation set: Average loss: 0.9070, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 486 [0/2335 (0%)]\tLoss: 0.390740\n",
      "Validation set: Average loss: 0.6804, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 487 [0/2335 (0%)]\tLoss: 0.390700\n",
      "Validation set: Average loss: 0.9833, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 488 [0/2335 (0%)]\tLoss: 0.391099\n",
      "Validation set: Average loss: 0.6761, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 489 [0/2335 (0%)]\tLoss: 0.390899\n",
      "Validation set: Average loss: 1.1931, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 490 [0/2335 (0%)]\tLoss: 0.390748\n",
      "Validation set: Average loss: 1.2098, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 491 [0/2335 (0%)]\tLoss: 0.390716\n",
      "Validation set: Average loss: 0.7832, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 492 [0/2335 (0%)]\tLoss: 0.390556\n",
      "Validation set: Average loss: 1.7879, Accuracy: 54/107 (0.50%)\n",
      "Train Epoch: 493 [0/2335 (0%)]\tLoss: 0.390433\n",
      "Validation set: Average loss: 0.6733, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 494 [0/2335 (0%)]\tLoss: 0.390409\n",
      "Validation set: Average loss: 1.7179, Accuracy: 53/107 (0.50%)\n",
      "Train Epoch: 495 [0/2335 (0%)]\tLoss: 0.391157\n",
      "Validation set: Average loss: 0.7752, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 496 [0/2335 (0%)]\tLoss: 0.390584\n",
      "Validation set: Average loss: 1.1031, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 497 [0/2335 (0%)]\tLoss: 0.390510\n",
      "Validation set: Average loss: 0.6815, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 498 [0/2335 (0%)]\tLoss: 0.390526\n",
      "Validation set: Average loss: 0.7826, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 499 [0/2335 (0%)]\tLoss: 0.390825\n",
      "Validation set: Average loss: 0.6920, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 500 [0/2335 (0%)]\tLoss: 0.390923\n",
      "Validation set: Average loss: 1.4350, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 501 [0/2335 (0%)]\tLoss: 0.390275\n",
      "Validation set: Average loss: 0.6686, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 502 [0/2335 (0%)]\tLoss: 0.391406\n",
      "Validation set: Average loss: 1.4392, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 503 [0/2335 (0%)]\tLoss: 0.390554\n",
      "Validation set: Average loss: 0.7038, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 504 [0/2335 (0%)]\tLoss: 0.390706\n",
      "Validation set: Average loss: 0.8544, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 505 [0/2335 (0%)]\tLoss: 0.390758\n",
      "Validation set: Average loss: 1.8695, Accuracy: 53/107 (0.50%)\n",
      "Train Epoch: 506 [0/2335 (0%)]\tLoss: 0.390674\n",
      "Validation set: Average loss: 0.8219, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 507 [0/2335 (0%)]\tLoss: 0.390621\n",
      "Validation set: Average loss: 0.6818, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 508 [0/2335 (0%)]\tLoss: 0.390584\n",
      "Validation set: Average loss: 1.9963, Accuracy: 51/107 (0.48%)\n",
      "Train Epoch: 509 [0/2335 (0%)]\tLoss: 0.390954\n",
      "Validation set: Average loss: 0.9672, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 510 [0/2335 (0%)]\tLoss: 0.390590\n",
      "Validation set: Average loss: 1.9553, Accuracy: 51/107 (0.48%)\n",
      "Train Epoch: 511 [0/2335 (0%)]\tLoss: 0.390516\n",
      "Validation set: Average loss: 1.6272, Accuracy: 62/107 (0.58%)\n",
      "Train Epoch: 512 [0/2335 (0%)]\tLoss: 0.390521\n",
      "Validation set: Average loss: 1.9441, Accuracy: 52/107 (0.49%)\n",
      "Train Epoch: 513 [0/2335 (0%)]\tLoss: 0.390706\n",
      "Validation set: Average loss: 1.1505, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 514 [0/2335 (0%)]\tLoss: 0.390571\n",
      "Validation set: Average loss: 1.6047, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 515 [0/2335 (0%)]\tLoss: 0.390721\n",
      "Validation set: Average loss: 2.1129, Accuracy: 44/107 (0.41%)\n",
      "Train Epoch: 516 [0/2335 (0%)]\tLoss: 0.390995\n",
      "Validation set: Average loss: 2.5389, Accuracy: 33/107 (0.31%)\n",
      "Train Epoch: 517 [0/2335 (0%)]\tLoss: 0.390818\n",
      "Validation set: Average loss: 0.8977, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 518 [0/2335 (0%)]\tLoss: 0.390978\n",
      "Validation set: Average loss: 2.2864, Accuracy: 43/107 (0.40%)\n",
      "Train Epoch: 519 [0/2335 (0%)]\tLoss: 0.390817\n",
      "Validation set: Average loss: 2.5053, Accuracy: 35/107 (0.33%)\n",
      "Train Epoch: 520 [0/2335 (0%)]\tLoss: 0.390495\n",
      "Validation set: Average loss: 2.3703, Accuracy: 39/107 (0.36%)\n",
      "Train Epoch: 521 [0/2335 (0%)]\tLoss: 0.390773\n",
      "Validation set: Average loss: 0.8569, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 522 [0/2335 (0%)]\tLoss: 0.390412\n",
      "Validation set: Average loss: 1.9529, Accuracy: 50/107 (0.47%)\n",
      "Train Epoch: 523 [0/2335 (0%)]\tLoss: 0.390876\n",
      "Validation set: Average loss: 1.0810, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 524 [0/2335 (0%)]\tLoss: 0.390720\n",
      "Validation set: Average loss: 0.8615, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 525 [0/2335 (0%)]\tLoss: 0.390665\n",
      "Validation set: Average loss: 1.9737, Accuracy: 49/107 (0.46%)\n",
      "Train Epoch: 526 [0/2335 (0%)]\tLoss: 0.390629\n",
      "Validation set: Average loss: 0.9877, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 527 [0/2335 (0%)]\tLoss: 0.390349\n",
      "Validation set: Average loss: 2.5717, Accuracy: 34/107 (0.32%)\n",
      "Train Epoch: 528 [0/2335 (0%)]\tLoss: 0.390717\n",
      "Validation set: Average loss: 0.8435, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 529 [0/2335 (0%)]\tLoss: 0.391005\n",
      "Validation set: Average loss: 1.4366, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 530 [0/2335 (0%)]\tLoss: 0.390494\n",
      "Validation set: Average loss: 2.1971, Accuracy: 44/107 (0.41%)\n",
      "Train Epoch: 531 [0/2335 (0%)]\tLoss: 0.391075\n",
      "Validation set: Average loss: 2.2015, Accuracy: 44/107 (0.41%)\n",
      "Train Epoch: 532 [0/2335 (0%)]\tLoss: 0.390711\n",
      "Validation set: Average loss: 2.2690, Accuracy: 43/107 (0.40%)\n",
      "Train Epoch: 533 [0/2335 (0%)]\tLoss: 0.390797\n",
      "Validation set: Average loss: 0.7127, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 534 [0/2335 (0%)]\tLoss: 0.390760\n",
      "Validation set: Average loss: 2.0814, Accuracy: 47/107 (0.44%)\n",
      "Train Epoch: 535 [0/2335 (0%)]\tLoss: 0.390593\n",
      "Validation set: Average loss: 1.6171, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 536 [0/2335 (0%)]\tLoss: 0.390551\n",
      "Validation set: Average loss: 2.3334, Accuracy: 41/107 (0.38%)\n",
      "Train Epoch: 537 [0/2335 (0%)]\tLoss: 0.390660\n",
      "Validation set: Average loss: 1.3237, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 538 [0/2335 (0%)]\tLoss: 0.390702\n",
      "Validation set: Average loss: 1.7573, Accuracy: 54/107 (0.50%)\n",
      "Train Epoch: 539 [0/2335 (0%)]\tLoss: 0.390566\n",
      "Validation set: Average loss: 2.3773, Accuracy: 35/107 (0.33%)\n",
      "Train Epoch: 540 [0/2335 (0%)]\tLoss: 0.390654\n",
      "Validation set: Average loss: 1.3617, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 541 [0/2335 (0%)]\tLoss: 0.390580\n",
      "Validation set: Average loss: 2.3427, Accuracy: 41/107 (0.38%)\n",
      "Train Epoch: 542 [0/2335 (0%)]\tLoss: 0.390605\n",
      "Validation set: Average loss: 2.0012, Accuracy: 48/107 (0.45%)\n",
      "Train Epoch: 543 [0/2335 (0%)]\tLoss: 0.391179\n",
      "Validation set: Average loss: 1.0265, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 544 [0/2335 (0%)]\tLoss: 0.390716\n",
      "Validation set: Average loss: 1.4307, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 545 [0/2335 (0%)]\tLoss: 0.390807\n",
      "Validation set: Average loss: 1.5124, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 546 [0/2335 (0%)]\tLoss: 0.390436\n",
      "Validation set: Average loss: 1.6601, Accuracy: 58/107 (0.54%)\n",
      "Train Epoch: 547 [0/2335 (0%)]\tLoss: 0.390812\n",
      "Validation set: Average loss: 1.8989, Accuracy: 51/107 (0.48%)\n",
      "Train Epoch: 548 [0/2335 (0%)]\tLoss: 0.390304\n",
      "Validation set: Average loss: 1.5121, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 549 [0/2335 (0%)]\tLoss: 0.390713\n",
      "Validation set: Average loss: 1.3781, Accuracy: 65/107 (0.61%)\n",
      "Train Epoch: 550 [0/2335 (0%)]\tLoss: 0.390678\n",
      "Validation set: Average loss: 1.6570, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 551 [0/2335 (0%)]\tLoss: 0.390717\n",
      "Validation set: Average loss: 1.6733, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 552 [0/2335 (0%)]\tLoss: 0.397619\n",
      "Validation set: Average loss: 1.8498, Accuracy: 53/107 (0.50%)\n",
      "Train Epoch: 553 [0/2335 (0%)]\tLoss: 0.390741\n",
      "Validation set: Average loss: 0.8437, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 554 [0/2335 (0%)]\tLoss: 0.390506\n",
      "Validation set: Average loss: 0.6992, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 555 [0/2335 (0%)]\tLoss: 0.390914\n",
      "Validation set: Average loss: 1.0676, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 556 [0/2335 (0%)]\tLoss: 0.390582\n",
      "Validation set: Average loss: 0.8935, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 557 [0/2335 (0%)]\tLoss: 0.390498\n",
      "Validation set: Average loss: 1.8426, Accuracy: 53/107 (0.50%)\n",
      "Train Epoch: 558 [0/2335 (0%)]\tLoss: 0.390280\n",
      "Validation set: Average loss: 1.2938, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 559 [0/2335 (0%)]\tLoss: 0.390489\n",
      "Validation set: Average loss: 1.4829, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 560 [0/2335 (0%)]\tLoss: 0.390813\n",
      "Validation set: Average loss: 0.7062, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 561 [0/2335 (0%)]\tLoss: 0.390547\n",
      "Validation set: Average loss: 1.6435, Accuracy: 61/107 (0.57%)\n",
      "Train Epoch: 562 [0/2335 (0%)]\tLoss: 0.390563\n",
      "Validation set: Average loss: 1.9872, Accuracy: 50/107 (0.47%)\n",
      "Train Epoch: 563 [0/2335 (0%)]\tLoss: 0.390698\n",
      "Validation set: Average loss: 1.4403, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 564 [0/2335 (0%)]\tLoss: 0.390635\n",
      "Validation set: Average loss: 0.7027, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 565 [0/2335 (0%)]\tLoss: 0.390485\n",
      "Validation set: Average loss: 0.9778, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 566 [0/2335 (0%)]\tLoss: 0.390997\n",
      "Validation set: Average loss: 0.8966, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 567 [0/2335 (0%)]\tLoss: 0.390736\n",
      "Validation set: Average loss: 0.6829, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 568 [0/2335 (0%)]\tLoss: 0.391066\n",
      "Validation set: Average loss: 1.3713, Accuracy: 69/107 (0.64%)\n",
      "Train Epoch: 569 [0/2335 (0%)]\tLoss: 0.390343\n",
      "Validation set: Average loss: 1.4739, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 570 [0/2335 (0%)]\tLoss: 0.390856\n",
      "Validation set: Average loss: 1.9805, Accuracy: 50/107 (0.47%)\n",
      "Train Epoch: 571 [0/2335 (0%)]\tLoss: 0.390333\n",
      "Validation set: Average loss: 0.7215, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 572 [0/2335 (0%)]\tLoss: 0.390893\n",
      "Validation set: Average loss: 0.9608, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 573 [0/2335 (0%)]\tLoss: 0.390811\n",
      "Validation set: Average loss: 0.6876, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 574 [0/2335 (0%)]\tLoss: 0.390588\n",
      "Validation set: Average loss: 0.9489, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 575 [0/2335 (0%)]\tLoss: 0.390696\n",
      "Validation set: Average loss: 1.0667, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 576 [0/2335 (0%)]\tLoss: 0.390853\n",
      "Validation set: Average loss: 2.0480, Accuracy: 47/107 (0.44%)\n",
      "Train Epoch: 577 [0/2335 (0%)]\tLoss: 0.390503\n",
      "Validation set: Average loss: 1.9191, Accuracy: 53/107 (0.50%)\n",
      "Train Epoch: 578 [0/2335 (0%)]\tLoss: 0.390699\n",
      "Validation set: Average loss: 1.5215, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 579 [0/2335 (0%)]\tLoss: 0.390569\n",
      "Validation set: Average loss: 0.9136, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 580 [0/2335 (0%)]\tLoss: 0.391160\n",
      "Validation set: Average loss: 1.7684, Accuracy: 58/107 (0.54%)\n",
      "Train Epoch: 581 [0/2335 (0%)]\tLoss: 0.390622\n",
      "Validation set: Average loss: 0.8632, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 582 [0/2335 (0%)]\tLoss: 0.390863\n",
      "Validation set: Average loss: 1.0441, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 583 [0/2335 (0%)]\tLoss: 0.390816\n",
      "Validation set: Average loss: 0.7962, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 584 [0/2335 (0%)]\tLoss: 0.390937\n",
      "Validation set: Average loss: 1.6330, Accuracy: 61/107 (0.57%)\n",
      "Train Epoch: 585 [0/2335 (0%)]\tLoss: 0.390447\n",
      "Validation set: Average loss: 1.8293, Accuracy: 55/107 (0.51%)\n",
      "Train Epoch: 586 [0/2335 (0%)]\tLoss: 0.390708\n",
      "Validation set: Average loss: 0.6999, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 587 [0/2335 (0%)]\tLoss: 0.390594\n",
      "Validation set: Average loss: 1.3154, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 588 [0/2335 (0%)]\tLoss: 0.390455\n",
      "Validation set: Average loss: 0.9372, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 589 [0/2335 (0%)]\tLoss: 0.390639\n",
      "Validation set: Average loss: 1.1184, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 590 [0/2335 (0%)]\tLoss: 0.390873\n",
      "Validation set: Average loss: 1.6510, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 591 [0/2335 (0%)]\tLoss: 0.390900\n",
      "Validation set: Average loss: 2.1536, Accuracy: 46/107 (0.43%)\n",
      "Train Epoch: 592 [0/2335 (0%)]\tLoss: 0.390545\n",
      "Validation set: Average loss: 1.0179, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 593 [0/2335 (0%)]\tLoss: 0.390538\n",
      "Validation set: Average loss: 0.8611, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 594 [0/2335 (0%)]\tLoss: 0.391241\n",
      "Validation set: Average loss: 1.9336, Accuracy: 51/107 (0.48%)\n",
      "Train Epoch: 595 [0/2335 (0%)]\tLoss: 0.390322\n",
      "Validation set: Average loss: 0.9946, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 596 [0/2335 (0%)]\tLoss: 0.390337\n",
      "Validation set: Average loss: 2.1495, Accuracy: 46/107 (0.43%)\n",
      "Train Epoch: 597 [0/2335 (0%)]\tLoss: 0.390484\n",
      "Validation set: Average loss: 1.1038, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 598 [0/2335 (0%)]\tLoss: 0.390770\n",
      "Validation set: Average loss: 1.9367, Accuracy: 51/107 (0.48%)\n",
      "Train Epoch: 599 [0/2335 (0%)]\tLoss: 0.390690\n",
      "Validation set: Average loss: 0.8860, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 600 [0/2335 (0%)]\tLoss: 0.390480\n",
      "Validation set: Average loss: 1.7221, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 601 [0/2335 (0%)]\tLoss: 0.390786\n",
      "Validation set: Average loss: 0.7013, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 602 [0/2335 (0%)]\tLoss: 0.390633\n",
      "Validation set: Average loss: 1.5741, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 603 [0/2335 (0%)]\tLoss: 0.390526\n",
      "Validation set: Average loss: 1.8140, Accuracy: 56/107 (0.52%)\n",
      "Train Epoch: 604 [0/2335 (0%)]\tLoss: 0.390577\n",
      "Validation set: Average loss: 1.3905, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 605 [0/2335 (0%)]\tLoss: 0.390331\n",
      "Validation set: Average loss: 1.4517, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 606 [0/2335 (0%)]\tLoss: 0.390393\n",
      "Validation set: Average loss: 1.7103, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 607 [0/2335 (0%)]\tLoss: 0.390262\n",
      "Validation set: Average loss: 1.3778, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 608 [0/2335 (0%)]\tLoss: 0.390236\n",
      "Validation set: Average loss: 2.1446, Accuracy: 46/107 (0.43%)\n",
      "Train Epoch: 609 [0/2335 (0%)]\tLoss: 0.390601\n",
      "Validation set: Average loss: 1.4614, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 610 [0/2335 (0%)]\tLoss: 0.390535\n",
      "Validation set: Average loss: 1.4082, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 611 [0/2335 (0%)]\tLoss: 0.390789\n",
      "Validation set: Average loss: 1.5753, Accuracy: 62/107 (0.58%)\n",
      "Train Epoch: 612 [0/2335 (0%)]\tLoss: 0.390788\n",
      "Validation set: Average loss: 1.3858, Accuracy: 68/107 (0.64%)\n",
      "Train Epoch: 613 [0/2335 (0%)]\tLoss: 0.390445\n",
      "Validation set: Average loss: 2.0185, Accuracy: 48/107 (0.45%)\n",
      "Train Epoch: 614 [0/2335 (0%)]\tLoss: 0.390894\n",
      "Validation set: Average loss: 1.2960, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 615 [0/2335 (0%)]\tLoss: 0.390926\n",
      "Validation set: Average loss: 0.8046, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 616 [0/2335 (0%)]\tLoss: 0.390609\n",
      "Validation set: Average loss: 1.7074, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 617 [0/2335 (0%)]\tLoss: 0.390607\n",
      "Validation set: Average loss: 1.7953, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 618 [0/2335 (0%)]\tLoss: 0.390450\n",
      "Validation set: Average loss: 0.6812, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 619 [0/2335 (0%)]\tLoss: 0.390412\n",
      "Validation set: Average loss: 2.2238, Accuracy: 44/107 (0.41%)\n",
      "Train Epoch: 620 [0/2335 (0%)]\tLoss: 0.390624\n",
      "Validation set: Average loss: 0.7030, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 621 [0/2335 (0%)]\tLoss: 0.390513\n",
      "Validation set: Average loss: 1.7614, Accuracy: 58/107 (0.54%)\n",
      "Train Epoch: 622 [0/2335 (0%)]\tLoss: 0.390603\n",
      "Validation set: Average loss: 1.1227, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 623 [0/2335 (0%)]\tLoss: 0.391025\n",
      "Validation set: Average loss: 1.9933, Accuracy: 48/107 (0.45%)\n",
      "Train Epoch: 624 [0/2335 (0%)]\tLoss: 0.390979\n",
      "Validation set: Average loss: 1.8975, Accuracy: 51/107 (0.48%)\n",
      "Train Epoch: 625 [0/2335 (0%)]\tLoss: 0.390704\n",
      "Validation set: Average loss: 1.1003, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 626 [0/2335 (0%)]\tLoss: 0.390486\n",
      "Validation set: Average loss: 1.6700, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 627 [0/2335 (0%)]\tLoss: 0.390612\n",
      "Validation set: Average loss: 0.6824, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 628 [0/2335 (0%)]\tLoss: 0.390749\n",
      "Validation set: Average loss: 1.7984, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 629 [0/2335 (0%)]\tLoss: 0.390965\n",
      "Validation set: Average loss: 0.9764, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 630 [0/2335 (0%)]\tLoss: 0.390279\n",
      "Validation set: Average loss: 1.0044, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 631 [0/2335 (0%)]\tLoss: 0.390710\n",
      "Validation set: Average loss: 1.4903, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 632 [0/2335 (0%)]\tLoss: 0.390913\n",
      "Validation set: Average loss: 1.7649, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 633 [0/2335 (0%)]\tLoss: 0.390673\n",
      "Validation set: Average loss: 0.9017, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 634 [0/2335 (0%)]\tLoss: 0.390987\n",
      "Validation set: Average loss: 1.7177, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 635 [0/2335 (0%)]\tLoss: 0.390482\n",
      "Validation set: Average loss: 0.9220, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 636 [0/2335 (0%)]\tLoss: 0.391393\n",
      "Validation set: Average loss: 1.1222, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 637 [0/2335 (0%)]\tLoss: 0.390943\n",
      "Validation set: Average loss: 1.6935, Accuracy: 58/107 (0.54%)\n",
      "Train Epoch: 638 [0/2335 (0%)]\tLoss: 0.390319\n",
      "Validation set: Average loss: 0.9851, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 639 [0/2335 (0%)]\tLoss: 0.390701\n",
      "Validation set: Average loss: 1.3389, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 640 [0/2335 (0%)]\tLoss: 0.391367\n",
      "Validation set: Average loss: 1.6069, Accuracy: 43/107 (0.40%)\n",
      "Train Epoch: 641 [0/2335 (0%)]\tLoss: 0.390850\n",
      "Validation set: Average loss: 0.7457, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 642 [0/2335 (0%)]\tLoss: 0.391171\n",
      "Validation set: Average loss: 1.1519, Accuracy: 55/107 (0.51%)\n",
      "Train Epoch: 643 [0/2335 (0%)]\tLoss: 0.390768\n",
      "Validation set: Average loss: 0.8011, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 644 [0/2335 (0%)]\tLoss: 0.393474\n",
      "Validation set: Average loss: 1.1920, Accuracy: 50/107 (0.47%)\n",
      "Train Epoch: 645 [0/2335 (0%)]\tLoss: 0.391575\n",
      "Validation set: Average loss: 1.7441, Accuracy: 36/107 (0.34%)\n",
      "Train Epoch: 646 [0/2335 (0%)]\tLoss: 0.392308\n",
      "Validation set: Average loss: 1.6386, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 647 [0/2335 (0%)]\tLoss: 0.391542\n",
      "Validation set: Average loss: 0.9522, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 648 [0/2335 (0%)]\tLoss: 0.391940\n",
      "Validation set: Average loss: 0.9845, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 649 [0/2335 (0%)]\tLoss: 0.390972\n",
      "Validation set: Average loss: 0.9363, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 650 [0/2335 (0%)]\tLoss: 0.395829\n",
      "Validation set: Average loss: 1.7523, Accuracy: 48/107 (0.45%)\n",
      "Train Epoch: 651 [0/2335 (0%)]\tLoss: 0.391663\n",
      "Validation set: Average loss: 1.0945, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 652 [0/2335 (0%)]\tLoss: 0.391315\n",
      "Validation set: Average loss: 0.8412, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 653 [0/2335 (0%)]\tLoss: 0.391468\n",
      "Validation set: Average loss: 0.7510, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 654 [0/2335 (0%)]\tLoss: 0.392594\n",
      "Validation set: Average loss: 0.7287, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 655 [0/2335 (0%)]\tLoss: 0.391025\n",
      "Validation set: Average loss: 0.7139, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 656 [0/2335 (0%)]\tLoss: 0.398862\n",
      "Validation set: Average loss: 0.7415, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 657 [0/2335 (0%)]\tLoss: 0.390907\n",
      "Validation set: Average loss: 0.7521, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 658 [0/2335 (0%)]\tLoss: 0.390464\n",
      "Validation set: Average loss: 0.7654, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 659 [0/2335 (0%)]\tLoss: 0.397025\n",
      "Validation set: Average loss: 0.7692, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 660 [0/2335 (0%)]\tLoss: 0.390819\n",
      "Validation set: Average loss: 0.7486, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 661 [0/2335 (0%)]\tLoss: 0.390874\n",
      "Validation set: Average loss: 0.8709, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 662 [0/2335 (0%)]\tLoss: 0.394890\n",
      "Validation set: Average loss: 0.8522, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 663 [0/2335 (0%)]\tLoss: 0.393318\n",
      "Validation set: Average loss: 0.7251, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 664 [0/2335 (0%)]\tLoss: 0.391182\n",
      "Validation set: Average loss: 0.8345, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 665 [0/2335 (0%)]\tLoss: 0.390948\n",
      "Validation set: Average loss: 0.7798, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 666 [0/2335 (0%)]\tLoss: 0.390421\n",
      "Validation set: Average loss: 0.7526, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 667 [0/2335 (0%)]\tLoss: 0.391251\n",
      "Validation set: Average loss: 0.7433, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 668 [0/2335 (0%)]\tLoss: 0.390930\n",
      "Validation set: Average loss: 0.7447, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 669 [0/2335 (0%)]\tLoss: 0.391044\n",
      "Validation set: Average loss: 0.8066, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 670 [0/2335 (0%)]\tLoss: 0.390916\n",
      "Validation set: Average loss: 0.7387, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 671 [0/2335 (0%)]\tLoss: 0.390905\n",
      "Validation set: Average loss: 0.7538, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 672 [0/2335 (0%)]\tLoss: 0.390625\n",
      "Validation set: Average loss: 0.7351, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 673 [0/2335 (0%)]\tLoss: 0.393771\n",
      "Validation set: Average loss: 0.7756, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 674 [0/2335 (0%)]\tLoss: 0.391010\n",
      "Validation set: Average loss: 0.8590, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 675 [0/2335 (0%)]\tLoss: 0.391012\n",
      "Validation set: Average loss: 0.8285, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 676 [0/2335 (0%)]\tLoss: 0.390940\n",
      "Validation set: Average loss: 0.8387, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 677 [0/2335 (0%)]\tLoss: 0.391154\n",
      "Validation set: Average loss: 0.7786, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 678 [0/2335 (0%)]\tLoss: 0.391104\n",
      "Validation set: Average loss: 0.7793, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 679 [0/2335 (0%)]\tLoss: 0.391184\n",
      "Validation set: Average loss: 0.7499, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 680 [0/2335 (0%)]\tLoss: 0.390914\n",
      "Validation set: Average loss: 0.8014, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 681 [0/2335 (0%)]\tLoss: 0.390736\n",
      "Validation set: Average loss: 0.8146, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 682 [0/2335 (0%)]\tLoss: 0.390716\n",
      "Validation set: Average loss: 0.7710, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 683 [0/2335 (0%)]\tLoss: 0.391072\n",
      "Validation set: Average loss: 0.8003, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 684 [0/2335 (0%)]\tLoss: 0.390867\n",
      "Validation set: Average loss: 0.7758, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 685 [0/2335 (0%)]\tLoss: 0.391201\n",
      "Validation set: Average loss: 0.7851, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 686 [0/2335 (0%)]\tLoss: 0.390858\n",
      "Validation set: Average loss: 0.9277, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 687 [0/2335 (0%)]\tLoss: 0.390854\n",
      "Validation set: Average loss: 0.7685, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 688 [0/2335 (0%)]\tLoss: 0.390977\n",
      "Validation set: Average loss: 0.8986, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 689 [0/2335 (0%)]\tLoss: 0.391057\n",
      "Validation set: Average loss: 0.7031, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 690 [0/2335 (0%)]\tLoss: 0.390563\n",
      "Validation set: Average loss: 0.7501, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 691 [0/2335 (0%)]\tLoss: 0.390949\n",
      "Validation set: Average loss: 0.7378, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 692 [0/2335 (0%)]\tLoss: 0.390635\n",
      "Validation set: Average loss: 0.7202, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 693 [0/2335 (0%)]\tLoss: 0.390887\n",
      "Validation set: Average loss: 1.0753, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 694 [0/2335 (0%)]\tLoss: 0.401666\n",
      "Validation set: Average loss: 0.8836, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 695 [0/2335 (0%)]\tLoss: 0.391078\n",
      "Validation set: Average loss: 0.7496, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 696 [0/2335 (0%)]\tLoss: 0.391618\n",
      "Validation set: Average loss: 0.7332, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 697 [0/2335 (0%)]\tLoss: 0.391051\n",
      "Validation set: Average loss: 0.7429, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 698 [0/2335 (0%)]\tLoss: 0.390938\n",
      "Validation set: Average loss: 0.7256, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 699 [0/2335 (0%)]\tLoss: 0.397460\n",
      "Validation set: Average loss: 0.7940, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 700 [0/2335 (0%)]\tLoss: 0.390752\n",
      "Validation set: Average loss: 0.7247, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 701 [0/2335 (0%)]\tLoss: 0.390808\n",
      "Validation set: Average loss: 0.7415, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 702 [0/2335 (0%)]\tLoss: 0.390967\n",
      "Validation set: Average loss: 0.6988, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 703 [0/2335 (0%)]\tLoss: 0.390621\n",
      "Validation set: Average loss: 0.7032, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 704 [0/2335 (0%)]\tLoss: 0.391298\n",
      "Validation set: Average loss: 0.8065, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 705 [0/2335 (0%)]\tLoss: 0.390995\n",
      "Validation set: Average loss: 0.6842, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 706 [0/2335 (0%)]\tLoss: 0.390983\n",
      "Validation set: Average loss: 0.7661, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 707 [0/2335 (0%)]\tLoss: 0.390864\n",
      "Validation set: Average loss: 0.6810, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 708 [0/2335 (0%)]\tLoss: 0.390975\n",
      "Validation set: Average loss: 0.6868, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 709 [0/2335 (0%)]\tLoss: 0.390663\n",
      "Validation set: Average loss: 0.6590, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 710 [0/2335 (0%)]\tLoss: 0.391191\n",
      "Validation set: Average loss: 0.6581, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 711 [0/2335 (0%)]\tLoss: 0.391414\n",
      "Validation set: Average loss: 0.6753, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 712 [0/2335 (0%)]\tLoss: 0.390953\n",
      "Validation set: Average loss: 0.7496, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 713 [0/2335 (0%)]\tLoss: 0.390561\n",
      "Validation set: Average loss: 0.6866, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 714 [0/2335 (0%)]\tLoss: 0.391555\n",
      "Validation set: Average loss: 0.7893, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 715 [0/2335 (0%)]\tLoss: 0.391009\n",
      "Validation set: Average loss: 0.7394, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 716 [0/2335 (0%)]\tLoss: 0.390411\n",
      "Validation set: Average loss: 0.7396, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 717 [0/2335 (0%)]\tLoss: 0.390601\n",
      "Validation set: Average loss: 0.7198, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 718 [0/2335 (0%)]\tLoss: 0.391040\n",
      "Validation set: Average loss: 0.7104, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 719 [0/2335 (0%)]\tLoss: 0.390416\n",
      "Validation set: Average loss: 0.7217, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 720 [0/2335 (0%)]\tLoss: 0.391109\n",
      "Validation set: Average loss: 0.9378, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 721 [0/2335 (0%)]\tLoss: 0.390698\n",
      "Validation set: Average loss: 0.7263, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 722 [0/2335 (0%)]\tLoss: 0.391173\n",
      "Validation set: Average loss: 0.7915, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 723 [0/2335 (0%)]\tLoss: 0.391011\n",
      "Validation set: Average loss: 0.7323, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 724 [0/2335 (0%)]\tLoss: 0.390979\n",
      "Validation set: Average loss: 0.7771, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 725 [0/2335 (0%)]\tLoss: 0.390494\n",
      "Validation set: Average loss: 0.9068, Accuracy: 78/107 (0.73%)\n",
      "Train Epoch: 726 [0/2335 (0%)]\tLoss: 0.390523\n",
      "Validation set: Average loss: 0.8104, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 727 [0/2335 (0%)]\tLoss: 0.390844\n",
      "Validation set: Average loss: 0.8758, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 728 [0/2335 (0%)]\tLoss: 0.391264\n",
      "Validation set: Average loss: 0.8710, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 729 [0/2335 (0%)]\tLoss: 0.390960\n",
      "Validation set: Average loss: 0.8952, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 730 [0/2335 (0%)]\tLoss: 0.390486\n",
      "Validation set: Average loss: 0.8382, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 731 [0/2335 (0%)]\tLoss: 0.390467\n",
      "Validation set: Average loss: 0.7260, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 732 [0/2335 (0%)]\tLoss: 0.392768\n",
      "Validation set: Average loss: 0.7053, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 733 [0/2335 (0%)]\tLoss: 0.390772\n",
      "Validation set: Average loss: 0.7101, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 734 [0/2335 (0%)]\tLoss: 0.390565\n",
      "Validation set: Average loss: 0.7458, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 735 [0/2335 (0%)]\tLoss: 0.390468\n",
      "Validation set: Average loss: 0.7444, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 736 [0/2335 (0%)]\tLoss: 0.390874\n",
      "Validation set: Average loss: 0.7360, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 737 [0/2335 (0%)]\tLoss: 0.391061\n",
      "Validation set: Average loss: 0.7150, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 738 [0/2335 (0%)]\tLoss: 0.390676\n",
      "Validation set: Average loss: 0.7883, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 739 [0/2335 (0%)]\tLoss: 0.391635\n",
      "Validation set: Average loss: 0.7276, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 740 [0/2335 (0%)]\tLoss: 0.391485\n",
      "Validation set: Average loss: 0.7384, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 741 [0/2335 (0%)]\tLoss: 0.390960\n",
      "Validation set: Average loss: 1.0301, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 742 [0/2335 (0%)]\tLoss: 0.391075\n",
      "Validation set: Average loss: 0.7190, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 743 [0/2335 (0%)]\tLoss: 0.391289\n",
      "Validation set: Average loss: 0.7890, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 744 [0/2335 (0%)]\tLoss: 0.390818\n",
      "Validation set: Average loss: 0.7322, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 745 [0/2335 (0%)]\tLoss: 0.390706\n",
      "Validation set: Average loss: 0.6812, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 746 [0/2335 (0%)]\tLoss: 0.390850\n",
      "Validation set: Average loss: 0.7064, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 747 [0/2335 (0%)]\tLoss: 0.390765\n",
      "Validation set: Average loss: 0.6942, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 748 [0/2335 (0%)]\tLoss: 0.390428\n",
      "Validation set: Average loss: 0.7383, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 749 [0/2335 (0%)]\tLoss: 0.391185\n",
      "Validation set: Average loss: 0.7374, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 750 [0/2335 (0%)]\tLoss: 0.391032\n",
      "Validation set: Average loss: 0.8843, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 751 [0/2335 (0%)]\tLoss: 0.390606\n",
      "Validation set: Average loss: 0.7348, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 752 [0/2335 (0%)]\tLoss: 0.391237\n",
      "Validation set: Average loss: 0.7303, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 753 [0/2335 (0%)]\tLoss: 0.390979\n",
      "Validation set: Average loss: 0.7141, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 754 [0/2335 (0%)]\tLoss: 0.390795\n",
      "Validation set: Average loss: 0.7072, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 755 [0/2335 (0%)]\tLoss: 0.391131\n",
      "Validation set: Average loss: 0.6934, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 756 [0/2335 (0%)]\tLoss: 0.391216\n",
      "Validation set: Average loss: 0.7115, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 757 [0/2335 (0%)]\tLoss: 0.391072\n",
      "Validation set: Average loss: 0.6950, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 758 [0/2335 (0%)]\tLoss: 0.390884\n",
      "Validation set: Average loss: 0.7176, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 759 [0/2335 (0%)]\tLoss: 0.390649\n",
      "Validation set: Average loss: 0.7310, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 760 [0/2335 (0%)]\tLoss: 0.390939\n",
      "Validation set: Average loss: 0.7719, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 761 [0/2335 (0%)]\tLoss: 0.390919\n",
      "Validation set: Average loss: 0.7660, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 762 [0/2335 (0%)]\tLoss: 0.391215\n",
      "Validation set: Average loss: 0.6945, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 763 [0/2335 (0%)]\tLoss: 0.390845\n",
      "Validation set: Average loss: 0.7303, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 764 [0/2335 (0%)]\tLoss: 0.390733\n",
      "Validation set: Average loss: 0.6908, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 765 [0/2335 (0%)]\tLoss: 0.390994\n",
      "Validation set: Average loss: 0.7609, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 766 [0/2335 (0%)]\tLoss: 0.390634\n",
      "Validation set: Average loss: 0.6910, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 767 [0/2335 (0%)]\tLoss: 0.390501\n",
      "Validation set: Average loss: 0.7554, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 768 [0/2335 (0%)]\tLoss: 0.390533\n",
      "Validation set: Average loss: 0.7100, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 769 [0/2335 (0%)]\tLoss: 0.390803\n",
      "Validation set: Average loss: 0.7259, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 770 [0/2335 (0%)]\tLoss: 0.390987\n",
      "Validation set: Average loss: 0.7054, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 771 [0/2335 (0%)]\tLoss: 0.390733\n",
      "Validation set: Average loss: 0.7242, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 772 [0/2335 (0%)]\tLoss: 0.390730\n",
      "Validation set: Average loss: 0.7658, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 773 [0/2335 (0%)]\tLoss: 0.390512\n",
      "Validation set: Average loss: 0.6995, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 774 [0/2335 (0%)]\tLoss: 0.392004\n",
      "Validation set: Average loss: 0.7726, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 775 [0/2335 (0%)]\tLoss: 0.391291\n",
      "Validation set: Average loss: 0.6817, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 776 [0/2335 (0%)]\tLoss: 0.390982\n",
      "Validation set: Average loss: 0.7191, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 777 [0/2335 (0%)]\tLoss: 0.390573\n",
      "Validation set: Average loss: 0.7338, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 778 [0/2335 (0%)]\tLoss: 0.391190\n",
      "Validation set: Average loss: 2.0394, Accuracy: 46/107 (0.43%)\n",
      "Train Epoch: 779 [0/2335 (0%)]\tLoss: 0.391457\n",
      "Validation set: Average loss: 1.9817, Accuracy: 54/107 (0.50%)\n",
      "Train Epoch: 780 [0/2335 (0%)]\tLoss: 0.391190\n",
      "Validation set: Average loss: 1.8441, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 781 [0/2335 (0%)]\tLoss: 0.390480\n",
      "Validation set: Average loss: 1.9426, Accuracy: 56/107 (0.52%)\n",
      "Train Epoch: 782 [0/2335 (0%)]\tLoss: 0.390878\n",
      "Validation set: Average loss: 1.1737, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 783 [0/2335 (0%)]\tLoss: 0.390396\n",
      "Validation set: Average loss: 0.7596, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 784 [0/2335 (0%)]\tLoss: 0.390388\n",
      "Validation set: Average loss: 0.8036, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 785 [0/2335 (0%)]\tLoss: 0.391081\n",
      "Validation set: Average loss: 2.0008, Accuracy: 54/107 (0.50%)\n",
      "Train Epoch: 786 [0/2335 (0%)]\tLoss: 0.391270\n",
      "Validation set: Average loss: 1.7645, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 787 [0/2335 (0%)]\tLoss: 0.390511\n",
      "Validation set: Average loss: 2.1063, Accuracy: 47/107 (0.44%)\n",
      "Train Epoch: 788 [0/2335 (0%)]\tLoss: 0.391371\n",
      "Validation set: Average loss: 1.0259, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 789 [0/2335 (0%)]\tLoss: 0.391630\n",
      "Validation set: Average loss: 1.2995, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 790 [0/2335 (0%)]\tLoss: 0.391003\n",
      "Validation set: Average loss: 2.1660, Accuracy: 46/107 (0.43%)\n",
      "Train Epoch: 791 [0/2335 (0%)]\tLoss: 0.390862\n",
      "Validation set: Average loss: 1.7445, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 792 [0/2335 (0%)]\tLoss: 0.390857\n",
      "Validation set: Average loss: 1.3015, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 793 [0/2335 (0%)]\tLoss: 0.391215\n",
      "Validation set: Average loss: 1.3806, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 794 [0/2335 (0%)]\tLoss: 0.390523\n",
      "Validation set: Average loss: 1.7268, Accuracy: 59/107 (0.55%)\n",
      "Train Epoch: 795 [0/2335 (0%)]\tLoss: 0.391257\n",
      "Validation set: Average loss: 0.7671, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 796 [0/2335 (0%)]\tLoss: 0.392249\n",
      "Validation set: Average loss: 0.9743, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 797 [0/2335 (0%)]\tLoss: 0.402044\n",
      "Validation set: Average loss: 1.5905, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 798 [0/2335 (0%)]\tLoss: 0.391151\n",
      "Validation set: Average loss: 0.9803, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 799 [0/2335 (0%)]\tLoss: 0.391288\n",
      "Validation set: Average loss: 0.8065, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 800 [0/2335 (0%)]\tLoss: 0.391431\n",
      "Validation set: Average loss: 0.9992, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 801 [0/2335 (0%)]\tLoss: 0.392016\n",
      "Validation set: Average loss: 0.9890, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 802 [0/2335 (0%)]\tLoss: 0.391759\n",
      "Validation set: Average loss: 0.9222, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 803 [0/2335 (0%)]\tLoss: 0.391096\n",
      "Validation set: Average loss: 1.1381, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 804 [0/2335 (0%)]\tLoss: 0.390869\n",
      "Validation set: Average loss: 0.7355, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 805 [0/2335 (0%)]\tLoss: 0.391067\n",
      "Validation set: Average loss: 1.0389, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 806 [0/2335 (0%)]\tLoss: 0.390832\n",
      "Validation set: Average loss: 0.7909, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 807 [0/2335 (0%)]\tLoss: 0.391526\n",
      "Validation set: Average loss: 0.8114, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 808 [0/2335 (0%)]\tLoss: 0.390770\n",
      "Validation set: Average loss: 0.7317, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 809 [0/2335 (0%)]\tLoss: 0.391214\n",
      "Validation set: Average loss: 0.7187, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 810 [0/2335 (0%)]\tLoss: 0.390864\n",
      "Validation set: Average loss: 0.7376, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 811 [0/2335 (0%)]\tLoss: 0.391004\n",
      "Validation set: Average loss: 0.9685, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 812 [0/2335 (0%)]\tLoss: 0.391197\n",
      "Validation set: Average loss: 0.9408, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 813 [0/2335 (0%)]\tLoss: 0.391143\n",
      "Validation set: Average loss: 1.3020, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 814 [0/2335 (0%)]\tLoss: 0.392253\n",
      "Validation set: Average loss: 1.3663, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 815 [0/2335 (0%)]\tLoss: 0.390506\n",
      "Validation set: Average loss: 0.9376, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 816 [0/2335 (0%)]\tLoss: 0.391419\n",
      "Validation set: Average loss: 1.5753, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 817 [0/2335 (0%)]\tLoss: 0.390846\n",
      "Validation set: Average loss: 1.7424, Accuracy: 61/107 (0.57%)\n",
      "Train Epoch: 818 [0/2335 (0%)]\tLoss: 0.391370\n",
      "Validation set: Average loss: 1.6360, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 819 [0/2335 (0%)]\tLoss: 0.391450\n",
      "Validation set: Average loss: 0.7085, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 820 [0/2335 (0%)]\tLoss: 0.391106\n",
      "Validation set: Average loss: 1.5759, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 821 [0/2335 (0%)]\tLoss: 0.390585\n",
      "Validation set: Average loss: 1.5946, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 822 [0/2335 (0%)]\tLoss: 0.390963\n",
      "Validation set: Average loss: 0.8110, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 823 [0/2335 (0%)]\tLoss: 0.390558\n",
      "Validation set: Average loss: 0.9346, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 824 [0/2335 (0%)]\tLoss: 0.390589\n",
      "Validation set: Average loss: 0.7258, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 825 [0/2335 (0%)]\tLoss: 0.391135\n",
      "Validation set: Average loss: 0.7591, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 826 [0/2335 (0%)]\tLoss: 0.390760\n",
      "Validation set: Average loss: 1.2683, Accuracy: 72/107 (0.67%)\n",
      "Train Epoch: 827 [0/2335 (0%)]\tLoss: 0.390926\n",
      "Validation set: Average loss: 1.5874, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 828 [0/2335 (0%)]\tLoss: 0.390513\n",
      "Validation set: Average loss: 1.5876, Accuracy: 67/107 (0.63%)\n",
      "Train Epoch: 829 [0/2335 (0%)]\tLoss: 0.390853\n",
      "Validation set: Average loss: 1.4934, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 830 [0/2335 (0%)]\tLoss: 0.390945\n",
      "Validation set: Average loss: 1.2570, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 831 [0/2335 (0%)]\tLoss: 0.390457\n",
      "Validation set: Average loss: 0.9600, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 832 [0/2335 (0%)]\tLoss: 0.390418\n",
      "Validation set: Average loss: 1.8507, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 833 [0/2335 (0%)]\tLoss: 0.390591\n",
      "Validation set: Average loss: 1.7382, Accuracy: 61/107 (0.57%)\n",
      "Train Epoch: 834 [0/2335 (0%)]\tLoss: 0.390676\n",
      "Validation set: Average loss: 0.9393, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 835 [0/2335 (0%)]\tLoss: 0.390889\n",
      "Validation set: Average loss: 1.7962, Accuracy: 58/107 (0.54%)\n",
      "Train Epoch: 836 [0/2335 (0%)]\tLoss: 0.390498\n",
      "Validation set: Average loss: 1.5662, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 837 [0/2335 (0%)]\tLoss: 0.391055\n",
      "Validation set: Average loss: 1.0793, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 838 [0/2335 (0%)]\tLoss: 0.390868\n",
      "Validation set: Average loss: 0.9444, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 839 [0/2335 (0%)]\tLoss: 0.390912\n",
      "Validation set: Average loss: 0.9717, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 840 [0/2335 (0%)]\tLoss: 0.390631\n",
      "Validation set: Average loss: 1.6946, Accuracy: 60/107 (0.56%)\n",
      "Train Epoch: 841 [0/2335 (0%)]\tLoss: 0.390831\n",
      "Validation set: Average loss: 0.7491, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 842 [0/2335 (0%)]\tLoss: 0.390593\n",
      "Validation set: Average loss: 0.9212, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 843 [0/2335 (0%)]\tLoss: 0.390425\n",
      "Validation set: Average loss: 0.9368, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 844 [0/2335 (0%)]\tLoss: 0.391269\n",
      "Validation set: Average loss: 0.9338, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 845 [0/2335 (0%)]\tLoss: 0.390761\n",
      "Validation set: Average loss: 1.7562, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 846 [0/2335 (0%)]\tLoss: 0.390303\n",
      "Validation set: Average loss: 0.7540, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 847 [0/2335 (0%)]\tLoss: 0.390765\n",
      "Validation set: Average loss: 0.9273, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 848 [0/2335 (0%)]\tLoss: 0.390808\n",
      "Validation set: Average loss: 0.9932, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 849 [0/2335 (0%)]\tLoss: 0.390822\n",
      "Validation set: Average loss: 0.9407, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 850 [0/2335 (0%)]\tLoss: 0.390426\n",
      "Validation set: Average loss: 2.0207, Accuracy: 46/107 (0.43%)\n",
      "Train Epoch: 851 [0/2335 (0%)]\tLoss: 0.390803\n",
      "Validation set: Average loss: 1.4289, Accuracy: 70/107 (0.65%)\n",
      "Train Epoch: 852 [0/2335 (0%)]\tLoss: 0.390580\n",
      "Validation set: Average loss: 1.1735, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 853 [0/2335 (0%)]\tLoss: 0.391063\n",
      "Validation set: Average loss: 0.9175, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 854 [0/2335 (0%)]\tLoss: 0.390843\n",
      "Validation set: Average loss: 1.2303, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 855 [0/2335 (0%)]\tLoss: 0.391401\n",
      "Validation set: Average loss: 0.9154, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 856 [0/2335 (0%)]\tLoss: 0.390762\n",
      "Validation set: Average loss: 0.9997, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 857 [0/2335 (0%)]\tLoss: 0.390845\n",
      "Validation set: Average loss: 2.0261, Accuracy: 49/107 (0.46%)\n",
      "Train Epoch: 858 [0/2335 (0%)]\tLoss: 0.391091\n",
      "Validation set: Average loss: 1.7471, Accuracy: 57/107 (0.53%)\n",
      "Train Epoch: 859 [0/2335 (0%)]\tLoss: 0.390740\n",
      "Validation set: Average loss: 1.5861, Accuracy: 65/107 (0.61%)\n",
      "Train Epoch: 860 [0/2335 (0%)]\tLoss: 0.391143\n",
      "Validation set: Average loss: 0.6631, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 861 [0/2335 (0%)]\tLoss: 0.392752\n",
      "Validation set: Average loss: 0.9771, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 862 [0/2335 (0%)]\tLoss: 0.390917\n",
      "Validation set: Average loss: 0.6815, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 863 [0/2335 (0%)]\tLoss: 0.390777\n",
      "Validation set: Average loss: 0.9457, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 864 [0/2335 (0%)]\tLoss: 0.390892\n",
      "Validation set: Average loss: 0.9764, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 865 [0/2335 (0%)]\tLoss: 0.390759\n",
      "Validation set: Average loss: 0.7919, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 866 [0/2335 (0%)]\tLoss: 0.390565\n",
      "Validation set: Average loss: 0.7931, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 867 [0/2335 (0%)]\tLoss: 0.390980\n",
      "Validation set: Average loss: 1.0980, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 868 [0/2335 (0%)]\tLoss: 0.390655\n",
      "Validation set: Average loss: 0.9041, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 869 [0/2335 (0%)]\tLoss: 0.390862\n",
      "Validation set: Average loss: 0.8089, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 870 [0/2335 (0%)]\tLoss: 0.390882\n",
      "Validation set: Average loss: 1.5725, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 871 [0/2335 (0%)]\tLoss: 0.390722\n",
      "Validation set: Average loss: 1.6011, Accuracy: 64/107 (0.60%)\n",
      "Train Epoch: 872 [0/2335 (0%)]\tLoss: 0.390684\n",
      "Validation set: Average loss: 1.5397, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 873 [0/2335 (0%)]\tLoss: 0.390758\n",
      "Validation set: Average loss: 1.2678, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 874 [0/2335 (0%)]\tLoss: 0.391050\n",
      "Validation set: Average loss: 1.2558, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 875 [0/2335 (0%)]\tLoss: 0.390421\n",
      "Validation set: Average loss: 0.7921, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 876 [0/2335 (0%)]\tLoss: 0.391114\n",
      "Validation set: Average loss: 0.7060, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 877 [0/2335 (0%)]\tLoss: 0.393630\n",
      "Validation set: Average loss: 0.7870, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 878 [0/2335 (0%)]\tLoss: 0.391201\n",
      "Validation set: Average loss: 0.7448, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 879 [0/2335 (0%)]\tLoss: 0.390477\n",
      "Validation set: Average loss: 0.8446, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 880 [0/2335 (0%)]\tLoss: 0.391640\n",
      "Validation set: Average loss: 0.8238, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 881 [0/2335 (0%)]\tLoss: 0.390803\n",
      "Validation set: Average loss: 0.7319, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 882 [0/2335 (0%)]\tLoss: 0.390868\n",
      "Validation set: Average loss: 0.7554, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 883 [0/2335 (0%)]\tLoss: 0.390471\n",
      "Validation set: Average loss: 0.9156, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 884 [0/2335 (0%)]\tLoss: 0.390568\n",
      "Validation set: Average loss: 0.9014, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 885 [0/2335 (0%)]\tLoss: 0.390501\n",
      "Validation set: Average loss: 0.7406, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 886 [0/2335 (0%)]\tLoss: 0.391136\n",
      "Validation set: Average loss: 0.9674, Accuracy: 79/107 (0.74%)\n",
      "Train Epoch: 887 [0/2335 (0%)]\tLoss: 0.390588\n",
      "Validation set: Average loss: 0.7686, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 888 [0/2335 (0%)]\tLoss: 0.390571\n",
      "Validation set: Average loss: 0.7316, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 889 [0/2335 (0%)]\tLoss: 0.390912\n",
      "Validation set: Average loss: 0.7381, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 890 [0/2335 (0%)]\tLoss: 0.390867\n",
      "Validation set: Average loss: 0.8936, Accuracy: 84/107 (0.79%)\n",
      "Train Epoch: 891 [0/2335 (0%)]\tLoss: 0.390603\n",
      "Validation set: Average loss: 0.6704, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 892 [0/2335 (0%)]\tLoss: 0.390906\n",
      "Validation set: Average loss: 1.0876, Accuracy: 66/107 (0.62%)\n",
      "Train Epoch: 893 [0/2335 (0%)]\tLoss: 0.390730\n",
      "Validation set: Average loss: 0.7353, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 894 [0/2335 (0%)]\tLoss: 0.390949\n",
      "Validation set: Average loss: 0.7780, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 895 [0/2335 (0%)]\tLoss: 0.390555\n",
      "Validation set: Average loss: 0.7109, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 896 [0/2335 (0%)]\tLoss: 0.390977\n",
      "Validation set: Average loss: 1.0186, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 897 [0/2335 (0%)]\tLoss: 0.390689\n",
      "Validation set: Average loss: 1.0556, Accuracy: 77/107 (0.72%)\n",
      "Train Epoch: 898 [0/2335 (0%)]\tLoss: 0.391033\n",
      "Validation set: Average loss: 0.6833, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 899 [0/2335 (0%)]\tLoss: 0.390643\n",
      "Validation set: Average loss: 0.7168, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 900 [0/2335 (0%)]\tLoss: 0.390698\n",
      "Validation set: Average loss: 0.6893, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 901 [0/2335 (0%)]\tLoss: 0.390811\n",
      "Validation set: Average loss: 0.8339, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 902 [0/2335 (0%)]\tLoss: 0.390899\n",
      "Validation set: Average loss: 0.6918, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 903 [0/2335 (0%)]\tLoss: 0.390531\n",
      "Validation set: Average loss: 0.9496, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 904 [0/2335 (0%)]\tLoss: 0.390568\n",
      "Validation set: Average loss: 1.3720, Accuracy: 62/107 (0.58%)\n",
      "Train Epoch: 905 [0/2335 (0%)]\tLoss: 0.390946\n",
      "Validation set: Average loss: 0.9506, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 906 [0/2335 (0%)]\tLoss: 0.390565\n",
      "Validation set: Average loss: 0.9693, Accuracy: 82/107 (0.77%)\n",
      "Train Epoch: 907 [0/2335 (0%)]\tLoss: 0.390860\n",
      "Validation set: Average loss: 1.2743, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 908 [0/2335 (0%)]\tLoss: 0.391144\n",
      "Validation set: Average loss: 0.9052, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 909 [0/2335 (0%)]\tLoss: 0.390781\n",
      "Validation set: Average loss: 0.8929, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 910 [0/2335 (0%)]\tLoss: 0.391092\n",
      "Validation set: Average loss: 1.3111, Accuracy: 73/107 (0.68%)\n",
      "Train Epoch: 911 [0/2335 (0%)]\tLoss: 0.390900\n",
      "Validation set: Average loss: 1.1621, Accuracy: 75/107 (0.70%)\n",
      "Train Epoch: 912 [0/2335 (0%)]\tLoss: 0.390809\n",
      "Validation set: Average loss: 1.2376, Accuracy: 71/107 (0.66%)\n",
      "Train Epoch: 913 [0/2335 (0%)]\tLoss: 0.390891\n",
      "Validation set: Average loss: 1.0025, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 914 [0/2335 (0%)]\tLoss: 0.390539\n",
      "Validation set: Average loss: 0.6967, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 915 [0/2335 (0%)]\tLoss: 0.390674\n",
      "Validation set: Average loss: 1.2352, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 916 [0/2335 (0%)]\tLoss: 0.391063\n",
      "Validation set: Average loss: 0.7006, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 917 [0/2335 (0%)]\tLoss: 0.390706\n",
      "Validation set: Average loss: 0.8391, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 918 [0/2335 (0%)]\tLoss: 0.391206\n",
      "Validation set: Average loss: 1.0526, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 919 [0/2335 (0%)]\tLoss: 0.390940\n",
      "Validation set: Average loss: 0.8191, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 920 [0/2335 (0%)]\tLoss: 0.390611\n",
      "Validation set: Average loss: 0.8472, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 921 [0/2335 (0%)]\tLoss: 0.390764\n",
      "Validation set: Average loss: 0.6988, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 922 [0/2335 (0%)]\tLoss: 0.390718\n",
      "Validation set: Average loss: 1.1327, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 923 [0/2335 (0%)]\tLoss: 0.390660\n",
      "Validation set: Average loss: 0.8337, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 924 [0/2335 (0%)]\tLoss: 0.390545\n",
      "Validation set: Average loss: 0.7176, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 925 [0/2335 (0%)]\tLoss: 0.390578\n",
      "Validation set: Average loss: 1.2290, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 926 [0/2335 (0%)]\tLoss: 0.390870\n",
      "Validation set: Average loss: 1.2328, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 927 [0/2335 (0%)]\tLoss: 0.390697\n",
      "Validation set: Average loss: 0.7187, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 928 [0/2335 (0%)]\tLoss: 0.390933\n",
      "Validation set: Average loss: 1.0281, Accuracy: 83/107 (0.78%)\n",
      "Train Epoch: 929 [0/2335 (0%)]\tLoss: 0.390683\n",
      "Validation set: Average loss: 0.7623, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 930 [0/2335 (0%)]\tLoss: 0.390655\n",
      "Validation set: Average loss: 0.7248, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 931 [0/2335 (0%)]\tLoss: 0.390608\n",
      "Validation set: Average loss: 0.7695, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 932 [0/2335 (0%)]\tLoss: 0.390712\n",
      "Validation set: Average loss: 0.7187, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 933 [0/2335 (0%)]\tLoss: 0.390981\n",
      "Validation set: Average loss: 0.7115, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 934 [0/2335 (0%)]\tLoss: 0.390810\n",
      "Validation set: Average loss: 0.7142, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 935 [0/2335 (0%)]\tLoss: 0.390781\n",
      "Validation set: Average loss: 0.7155, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 936 [0/2335 (0%)]\tLoss: 0.390512\n",
      "Validation set: Average loss: 0.7053, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 937 [0/2335 (0%)]\tLoss: 0.390839\n",
      "Validation set: Average loss: 0.8664, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 938 [0/2335 (0%)]\tLoss: 0.390755\n",
      "Validation set: Average loss: 1.0788, Accuracy: 76/107 (0.71%)\n",
      "Train Epoch: 939 [0/2335 (0%)]\tLoss: 0.390442\n",
      "Validation set: Average loss: 0.7412, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 940 [0/2335 (0%)]\tLoss: 0.390937\n",
      "Validation set: Average loss: 0.7281, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 941 [0/2335 (0%)]\tLoss: 0.390915\n",
      "Validation set: Average loss: 0.7090, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 942 [0/2335 (0%)]\tLoss: 0.390766\n",
      "Validation set: Average loss: 0.8718, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 943 [0/2335 (0%)]\tLoss: 0.390414\n",
      "Validation set: Average loss: 0.9588, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 944 [0/2335 (0%)]\tLoss: 0.390933\n",
      "Validation set: Average loss: 0.7206, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 945 [0/2335 (0%)]\tLoss: 0.390614\n",
      "Validation set: Average loss: 0.7291, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 946 [0/2335 (0%)]\tLoss: 0.390230\n",
      "Validation set: Average loss: 0.8927, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 947 [0/2335 (0%)]\tLoss: 0.390967\n",
      "Validation set: Average loss: 0.7286, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 948 [0/2335 (0%)]\tLoss: 0.390684\n",
      "Validation set: Average loss: 0.9966, Accuracy: 81/107 (0.76%)\n",
      "Train Epoch: 949 [0/2335 (0%)]\tLoss: 0.390478\n",
      "Validation set: Average loss: 0.8298, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 950 [0/2335 (0%)]\tLoss: 0.390648\n",
      "Validation set: Average loss: 0.7062, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 951 [0/2335 (0%)]\tLoss: 0.390890\n",
      "Validation set: Average loss: 0.9100, Accuracy: 87/107 (0.81%)\n",
      "Train Epoch: 952 [0/2335 (0%)]\tLoss: 0.390543\n",
      "Validation set: Average loss: 0.6888, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 953 [0/2335 (0%)]\tLoss: 0.390230\n",
      "Validation set: Average loss: 0.9412, Accuracy: 86/107 (0.80%)\n",
      "Train Epoch: 954 [0/2335 (0%)]\tLoss: 0.390612\n",
      "Validation set: Average loss: 0.8296, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 955 [0/2335 (0%)]\tLoss: 0.390580\n",
      "Validation set: Average loss: 0.7290, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 956 [0/2335 (0%)]\tLoss: 0.390527\n",
      "Validation set: Average loss: 0.8220, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 957 [0/2335 (0%)]\tLoss: 0.390537\n",
      "Validation set: Average loss: 0.6762, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 958 [0/2335 (0%)]\tLoss: 0.390847\n",
      "Validation set: Average loss: 0.6804, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 959 [0/2335 (0%)]\tLoss: 0.390507\n",
      "Validation set: Average loss: 1.2438, Accuracy: 63/107 (0.59%)\n",
      "Train Epoch: 960 [0/2335 (0%)]\tLoss: 0.390360\n",
      "Validation set: Average loss: 0.8542, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 961 [0/2335 (0%)]\tLoss: 0.390702\n",
      "Validation set: Average loss: 0.6875, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 962 [0/2335 (0%)]\tLoss: 0.390750\n",
      "Validation set: Average loss: 0.9199, Accuracy: 85/107 (0.79%)\n",
      "Train Epoch: 963 [0/2335 (0%)]\tLoss: 0.390477\n",
      "Validation set: Average loss: 0.7937, Accuracy: 89/107 (0.83%)\n",
      "Train Epoch: 964 [0/2335 (0%)]\tLoss: 0.390696\n",
      "Validation set: Average loss: 0.7252, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 965 [0/2335 (0%)]\tLoss: 0.390937\n",
      "Validation set: Average loss: 0.8405, Accuracy: 88/107 (0.82%)\n",
      "Train Epoch: 966 [0/2335 (0%)]\tLoss: 0.390454\n",
      "Validation set: Average loss: 0.7792, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 967 [0/2335 (0%)]\tLoss: 0.390869\n",
      "Validation set: Average loss: 0.7546, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 968 [0/2335 (0%)]\tLoss: 0.390564\n",
      "Validation set: Average loss: 1.0337, Accuracy: 74/107 (0.69%)\n",
      "Train Epoch: 969 [0/2335 (0%)]\tLoss: 0.390702\n",
      "Validation set: Average loss: 0.7019, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 970 [0/2335 (0%)]\tLoss: 0.390521\n",
      "Validation set: Average loss: 0.7057, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 971 [0/2335 (0%)]\tLoss: 0.390561\n",
      "Validation set: Average loss: 0.6957, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 972 [0/2335 (0%)]\tLoss: 0.390716\n",
      "Validation set: Average loss: 0.7925, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 973 [0/2335 (0%)]\tLoss: 0.390606\n",
      "Validation set: Average loss: 0.9465, Accuracy: 80/107 (0.75%)\n",
      "Train Epoch: 974 [0/2335 (0%)]\tLoss: 0.390374\n",
      "Validation set: Average loss: 0.7033, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 975 [0/2335 (0%)]\tLoss: 0.390870\n",
      "Validation set: Average loss: 0.6928, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 976 [0/2335 (0%)]\tLoss: 0.390546\n",
      "Validation set: Average loss: 0.7071, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 977 [0/2335 (0%)]\tLoss: 0.390862\n",
      "Validation set: Average loss: 0.6750, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 978 [0/2335 (0%)]\tLoss: 0.391175\n",
      "Validation set: Average loss: 0.6873, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 979 [0/2335 (0%)]\tLoss: 0.390643\n",
      "Validation set: Average loss: 0.6501, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 980 [0/2335 (0%)]\tLoss: 0.390800\n",
      "Validation set: Average loss: 0.6967, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 981 [0/2335 (0%)]\tLoss: 0.391018\n",
      "Validation set: Average loss: 0.6676, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 982 [0/2335 (0%)]\tLoss: 0.390642\n",
      "Validation set: Average loss: 0.6493, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 983 [0/2335 (0%)]\tLoss: 0.390502\n",
      "Validation set: Average loss: 0.6853, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 984 [0/2335 (0%)]\tLoss: 0.390472\n",
      "Validation set: Average loss: 0.7020, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 985 [0/2335 (0%)]\tLoss: 0.390640\n",
      "Validation set: Average loss: 0.7464, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 986 [0/2335 (0%)]\tLoss: 0.390837\n",
      "Validation set: Average loss: 0.6743, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 987 [0/2335 (0%)]\tLoss: 0.390658\n",
      "Validation set: Average loss: 0.8170, Accuracy: 91/107 (0.85%)\n",
      "Train Epoch: 988 [0/2335 (0%)]\tLoss: 0.390777\n",
      "Validation set: Average loss: 0.6701, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 989 [0/2335 (0%)]\tLoss: 0.391124\n",
      "Validation set: Average loss: 0.6686, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 990 [0/2335 (0%)]\tLoss: 0.390538\n",
      "Validation set: Average loss: 0.6670, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 991 [0/2335 (0%)]\tLoss: 0.390910\n",
      "Validation set: Average loss: 0.6675, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 992 [0/2335 (0%)]\tLoss: 0.390513\n",
      "Validation set: Average loss: 0.7465, Accuracy: 90/107 (0.84%)\n",
      "Train Epoch: 993 [0/2335 (0%)]\tLoss: 0.390408\n",
      "Validation set: Average loss: 0.7261, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 994 [0/2335 (0%)]\tLoss: 0.390917\n",
      "Validation set: Average loss: 0.7936, Accuracy: 92/107 (0.86%)\n",
      "Train Epoch: 995 [0/2335 (0%)]\tLoss: 0.390577\n",
      "Validation set: Average loss: 0.7192, Accuracy: 94/107 (0.88%)\n",
      "Train Epoch: 996 [0/2335 (0%)]\tLoss: 0.390829\n",
      "Validation set: Average loss: 0.6792, Accuracy: 95/107 (0.89%)\n",
      "Train Epoch: 997 [0/2335 (0%)]\tLoss: 0.390867\n",
      "Validation set: Average loss: 0.7368, Accuracy: 93/107 (0.87%)\n",
      "Train Epoch: 998 [0/2335 (0%)]\tLoss: 0.390603\n",
      "Validation set: Average loss: 0.7043, Accuracy: 96/107 (0.90%)\n",
      "Train Epoch: 999 [0/2335 (0%)]\tLoss: 0.390703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 16:58:35,878 - INFO - Diverse ensemble training completed. Best accuracy: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: Average loss: 0.7012, Accuracy: 97/107 (0.91%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 16:58:36,251 - INFO - Diverse Ensemble Model - Final Test Accuracy: 0.8692\n",
      "2024-10-10 16:58:36,995 - INFO - Diverse Ensemble Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.94      0.94      0.94       134\n",
      "           2       0.67      0.17      0.27        12\n",
      "           3       0.71      0.89      0.79        38\n",
      "           4       0.86      0.83      0.84        29\n",
      "\n",
      "    accuracy                           0.87       214\n",
      "   macro avg       0.63      0.57      0.57       214\n",
      "weighted avg       0.87      0.87      0.86       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modify the diverse ensemble training section\n",
    "diverse_ensemble = DiverseEnsembleModel(CONFIG['initial_params']['model_params']).to(device)\n",
    "diverse_optimizer = optim.AdamW(diverse_ensemble.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "diverse_scheduler = CosineAnnealingWarmRestarts(diverse_optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Set up TensorBoard\n",
    "writer = TorchSummaryWriter(log_dir=os.path.join(CONFIG['new_model_path'], 'tensorboard_logs2'))\n",
    "\n",
    "logging.info(\"Training diverse ensemble model...\")\n",
    "for epoch in range(train_params['num_epochs']):\n",
    "    diverse_ensemble.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (data, spectral_features, target) in enumerate(train_loader):\n",
    "        data, spectral_features, target = data.to(device), spectral_features.to(device), target.to(device)\n",
    "        diverse_optimizer.zero_grad()\n",
    "        output = diverse_ensemble(data, spectral_features)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(diverse_ensemble.parameters(), max_norm=1.0)\n",
    "        \n",
    "        diverse_optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "    \n",
    "    # Calculate average training loss for the epoch\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    \n",
    "    # Validation\n",
    "    diverse_ensemble.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, spectral_features, target in val_loader:  # Use val_loader instead of zipping X_val, X_val_spectral, y_val\n",
    "            data, spectral_features, target = data.to(device), spectral_features.to(device), target.to(device)\n",
    "            output = diverse_ensemble(data, spectral_features)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f'Validation set: Average loss: {val_loss:.4f}, Accuracy: {correct}/{len(val_loader.dataset)} ({accuracy:.2f}%)')\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/validation', val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/validation', accuracy, epoch)\n",
    "    writer.add_scalar('Learning Rate', diverse_optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "    diverse_scheduler.step()\n",
    "\n",
    "    # Check for improvement and save the best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        diverse_best_state = diverse_ensemble.state_dict()\n",
    "        save_model(diverse_ensemble, os.path.join(CONFIG['new_model_path'], CONFIG['model_names']['diverse2']))\n",
    "        logging.info(f\"New best diverse ensemble model saved. Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Close TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "logging.info(f\"Diverse ensemble training completed. Best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the best diverse ensemble model on the test set\n",
    "diverse_ensemble.load_state_dict(diverse_best_state)\n",
    "test_loss, test_accuracy, test_predictions = evaluate_model(diverse_ensemble, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "logging.info(f\"Diverse Ensemble Model - Final Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Generate and save confusion matrix for diverse ensemble\n",
    "cm = confusion_matrix(y_test.cpu().numpy(), test_predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Diverse Ensemble')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(os.path.join(CONFIG['new_model_path'], 'diverse_ensemble_confusion_matrix2.png'))\n",
    "plt.close()\n",
    "\n",
    "# Generate classification report for diverse ensemble\n",
    "report = classification_report(y_test.cpu().numpy(), test_predictions)\n",
    "logging.info(f\"Diverse Ensemble Classification Report:\\n{report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 16:58:37,542 - INFO - Performing knowledge distillation...\n",
      "Overall Distillation Progress:   8%|▊         | 4/50 [00:33<06:27,  8.42s/it]2024-10-10 16:59:19,898 - INFO - Distillation Epoch 5/50 - Loss: 1.3472, Accuracy: 0.1402, LR: 1.00e-05\n",
      "Overall Distillation Progress:  18%|█▊        | 9/50 [01:15<05:39,  8.27s/it]2024-10-10 17:00:01,403 - INFO - Distillation Epoch 10/50 - Loss: 0.5650, Accuracy: 0.7570, LR: 8.89e-06\n",
      "Overall Distillation Progress:  28%|██▊       | 14/50 [01:57<05:00,  8.35s/it]2024-10-10 17:00:43,133 - INFO - Distillation Epoch 15/50 - Loss: 0.1576, Accuracy: 0.8224, LR: 7.78e-06\n",
      "Overall Distillation Progress:  38%|███▊      | 19/50 [02:37<04:11,  8.13s/it]2024-10-10 17:01:23,865 - INFO - Distillation Epoch 20/50 - Loss: 0.1195, Accuracy: 0.8505, LR: 6.67e-06\n",
      "Overall Distillation Progress:  48%|████▊     | 24/50 [03:19<03:34,  8.26s/it]2024-10-10 17:02:05,368 - INFO - Distillation Epoch 25/50 - Loss: 0.1096, Accuracy: 0.6262, LR: 5.56e-06\n",
      "Overall Distillation Progress:  58%|█████▊    | 29/50 [04:00<02:51,  8.19s/it]2024-10-10 17:02:46,232 - INFO - Distillation Epoch 30/50 - Loss: 0.1042, Accuracy: 0.6355, LR: 4.44e-06\n",
      "Overall Distillation Progress:  68%|██████▊   | 34/50 [04:42<02:15,  8.49s/it]2024-10-10 17:03:28,834 - INFO - Distillation Epoch 35/50 - Loss: 0.1029, Accuracy: 0.5514, LR: 3.33e-06\n",
      "Overall Distillation Progress:  78%|███████▊  | 39/50 [05:24<01:32,  8.40s/it]2024-10-10 17:04:10,742 - INFO - Distillation Epoch 40/50 - Loss: 0.1009, Accuracy: 0.8692, LR: 2.22e-06\n",
      "Overall Distillation Progress:  88%|████████▊ | 44/50 [06:08<00:51,  8.62s/it]2024-10-10 17:04:54,453 - INFO - Distillation Epoch 45/50 - Loss: 0.1011, Accuracy: 0.5794, LR: 1.11e-06\n",
      "Overall Distillation Progress:  98%|█████████▊| 49/50 [06:50<00:08,  8.43s/it]2024-10-10 17:05:36,146 - INFO - Distillation Epoch 50/50 - Loss: 0.0998, Accuracy: 0.8505, LR: 1.00e-11\n",
      "Overall Distillation Progress: 100%|██████████| 50/50 [06:58<00:00,  8.37s/it]\n",
      "2024-10-10 17:05:36,749 - INFO - Training completed.\n",
      "2024-10-10 17:05:36,750 - INFO - Ensemble Model - Final Test Accuracy: 0.8879\n",
      "2024-10-10 17:05:36,752 - INFO - Diverse Ensemble Model - Final Test Accuracy: 0.8692\n",
      "2024-10-10 17:05:36,753 - INFO - Distilled Model - Final Test Accuracy: 0.8318\n"
     ]
    }
   ],
   "source": [
    "# # Train diverse ensemble\n",
    "# diverse_ensemble = DiverseEnsembleModel(CONFIG['initial_params']['model_params']).to(device)\n",
    "# diverse_optimizer = optim.AdamW(diverse_ensemble.parameters(), lr=train_params['lr'], weight_decay=1e-2)\n",
    "# diverse_scheduler = get_scheduler(diverse_optimizer, num_warmup_steps=len(train_loader)*5, num_training_steps=len(train_loader)*train_params['num_epochs'])\n",
    "\n",
    "# logging.info(\"Training diverse ensemble model...\")\n",
    "# diverse_best_state, diverse_accuracy = train_model(\n",
    "#     diverse_ensemble, train_loader, (X_val, X_val_spectral, y_val),\n",
    "#     diverse_optimizer, diverse_scheduler, criterion, device, epochs=train_params['num_epochs']\n",
    "# )\n",
    "\n",
    "# # save_model(diverse_ensemble, os.path.join(CONFIG['new_model_path'], CONFIG['model_names']['diverse']))\n",
    "# logging.info(f\"Best diverse ensemble model saved. Final accuracy: {diverse_accuracy:.4f}\")\n",
    "\n",
    "# Distill knowledge\n",
    "single_model = ImprovedSleepdetector(**CONFIG['initial_params']['model_params']).to(device)\n",
    "\n",
    "logging.info(\"Performing knowledge distillation...\")\n",
    "distilled_model = distill_knowledge(ensemble_model, single_model, train_loader, (X_val, X_val_spectral, y_val), device)\n",
    "\n",
    "save_model(distilled_model, os.path.join(CONFIG['new_model_path'], CONFIG['model_names']['distilled2']))\n",
    "\n",
    "# Final evaluation\n",
    "_, ensemble_accuracy, _ = evaluate_model(ensemble_model, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "_, diverse_accuracy, _ = evaluate_model(diverse_ensemble, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "_, distilled_accuracy, _ = evaluate_model(distilled_model, (X_test, X_test_spectral, y_test), criterion, device)\n",
    "\n",
    "logging.info(f\"Training completed.\")\n",
    "logging.info(f\"Ensemble Model - Final Test Accuracy: {ensemble_accuracy:.4f}\")\n",
    "logging.info(f\"Diverse Ensemble Model - Final Test Accuracy: {diverse_accuracy:.4f}\")\n",
    "logging.info(f\"Distilled Model - Final Test Accuracy: {distilled_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
